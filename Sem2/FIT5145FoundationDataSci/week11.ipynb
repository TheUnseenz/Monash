{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9dea04f",
   "metadata": {},
   "source": [
    "# Week 11 - Issues in data science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83a60fd",
   "metadata": {},
   "source": [
    "## Learning Outcomes (Week 11)\n",
    "By the end of this week, you should be able to  \n",
    "- Explain linked data  \n",
    "- Understand some of the legal and social issues that arise in a Data Society  \n",
    "- Understand some of the legal and ethical issues due to the use of AI and ML  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e4630",
   "metadata": {},
   "source": [
    "## 1. Ethics of linking data\n",
    "- Connecting elements within multiple structured data sets  \n",
    "- Allows data relating an element to be collected from multiple data sets  \n",
    "- Expands the knowledge base of a single data set  \n",
    "- Linked Open Data (LOD) allows the links and data to be freely shared and accessed  \n",
    "    - Used by companies but don’t tend to contribute their own data  \n",
    "\n",
    "### Ethics\n",
    "- Ethics - the moral handling of data, e.g., not selling on other’s private data to scammers  \n",
    "- People have rights  \n",
    "    - privacy  \n",
    "    - access  \n",
    "    - erasure  \n",
    "    - … etc.  \n",
    "- Companies have rights  \n",
    "    - ownership of data  \n",
    "    - intellectual property  \n",
    "    - copyright  \n",
    "    - confidentiality  \n",
    "\n",
    "### Companies using linked data\n",
    "- Business models  \n",
    "    - Data has become a valuable asset  \n",
    "    - Data has become a valuable product  \n",
    "- Data from different services can be linked by companies by buying out other companies or establishing new services for other companies to use.  \n",
    "\n",
    "### Governments using linked data\n",
    "- Business models  \n",
    "    - Multiple departments have separate systems  \n",
    "    - Departments interact, so why can’t their data  \n",
    "    - Law enforcement needs to know what everyone else knows!  \n",
    "- Problems  \n",
    "    - Who should know what?  \n",
    "    - How do you manage who should know what?  \n",
    "    - What priorities do you give to the rights of people?  \n",
    "\n",
    "What can you do?  \n",
    "What should you do?  \n",
    "How do you make sure the right thing is done?  \n",
    "\n",
    "### Confidentiality\n",
    "See: “The curly fry conundrum: Why social media ‘likes’ say more than you might think” by Jennifer Golbeck  \n",
    "e.g. Target ® predicting which women are pregnant based on their purchases  \n",
    "- Many things can be predicted from Facebook “likes”  \n",
    "- Homophily (tendency to associate with similar individuals) is important for enabling prediction  \n",
    "- We often don’t own or manage corporate/internet/app data about ourselves  \n",
    "- The source data critical for advertisers so we cannot expect companies to be banned/excluded from using it  \n",
    "- So how can we manage confidentiality?  \n",
    "- for many apps/websites, you must accept their privacy data sharing policies to use their services fully;  \n",
    "- the interface for selecting privacy preferences should move away from individual Internet platforms and be put into the hands of individual consumers;  \n",
    "- user could have an open source agent that broker their confidentiality preferences  \n",
    "- but would that be feasible and would businesses ever agree?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53a1f6b",
   "metadata": {},
   "source": [
    "## 3. AI veracity\n",
    "Can you trust the analysis?  \n",
    "- Various factors can affect the “accuracy” of any analysis  \n",
    "    - Data quality  \n",
    "    - Choice of analysis  \n",
    "    - Design of analysis  \n",
    "    - Choice of data  \n",
    "- It is easy for the modelling to misrepresent what the data is supposed to reflect.  \n",
    "    - Even statistical analysis can be biased!  \n",
    "\n",
    "### Data Provenance and LLM Training\n",
    "- What is Data Provenance?  \n",
    "    - The origin, lineage, and history of data used to train AI models  \n",
    "    - Key for assessing the credibility, fairness, and compliance of AI systems  \n",
    "- Why It Matters for LLMs  \n",
    "    - LLMs are trained on massive, web-scale datasets (e.g., Reddit, Wikipedia)  \n",
    "    - Often lack transparency: unclear what data was included or excluded  \n",
    "    - Impacts veracity: biased, outdated, or low-quality data → unreliable outputs  \n",
    "- Risks of Poor Provenance\n",
    "    - Legal & ethical concerns: copyright infringement, data consent violations  \n",
    "    - Bias propagation: inherited from skewed or unbalanced training sources  \n",
    "    - Hallucinations: generating false facts due to poor source grounding  \n",
    "\n",
    "### Bias of data\n",
    "- Sometimes the data used to train a ML system is biased, regardless of its volume\n",
    "    - Narrow  \n",
    "    - Regional  \n",
    "    - Undertested in varied contexts  \n",
    "- Biased system may discriminate in its results, for instance by\n",
    "    - gender  \n",
    "    - ethnic associations  \n",
    "- Biased system may not be as accurate in its results for unfamiliar contexts and subjects\n",
    "\n",
    "- What is Bias in LLMs?\n",
    "    - Systematic skew in LLM outputs  \n",
    "    - Can reflect and amplify social, cultural, or political stereotypes  \n",
    "- Sources of Bias\n",
    "    - Training data bias: Overrepresentation of certain groups/languages/views  \n",
    "    - Modeling bias: Architectural choices may reinforce patterns  \n",
    "\n",
    "- Not all bias is in the numbers  \n",
    "- Bias can also be in how you have designed the research  \n",
    "    - Are the variables appropriate for all situations being modelled?  \n",
    "    - Are assumptions made about the stakeholders who the data relates to?  \n",
    "    - Are assumptions being made about the context of the data?  \n",
    "- What is Bias in LLMs?\n",
    "    - Systematic skew in model outputs  \n",
    "    - Can reflect and amplify social, cultural, or political stereotypes  \n",
    "- Sources of Bias\n",
    "    - Training data bias: Overrepresentation of certain groups/languages/views  \n",
    "    - Modeling bias: Architectural choices may reinforce patterns  \n",
    "    - User prompt bias: How questions are framed affects results  \n",
    "- Gender Bias\n",
    "    - Definition: Stereotyping based on gender in language generation or representation.\n",
    "- Racial or Ethnic Bias\n",
    "    - Definition: Bias where the model generates outputs that reflect stereotypes or disproportionate associations based on race or ethnicity.\n",
    "- Cultural or Geographical Bias\n",
    "    - Definition: The tendency of LLMs to prioritize perspectives, norms, or knowledge from dominant (usually Western) cultures.\n",
    "- Other types of bias\n",
    "    - Political or Ideological Bias  \n",
    "    - Occupational Stereotyping  \n",
    "    - Religious Bias  \n",
    "    - …."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16354709",
   "metadata": {},
   "source": [
    "## 4. Sampling\n",
    "- When collecting data for processing, it has to be relevant  \n",
    "    - Can you get all data relating to the scenario you are modelling?  \n",
    "    - Can you only get a random sample of data? The sample data has to be representative of the population being modelled  \n",
    "    - How large a sample do you need?  \n",
    "    - What known variables are included in the data?  \n",
    "    - Is the sample data distributed to match the required strata/categories  \n",
    "- Observe the population before you make any unqualified assumptions  \n",
    "\n",
    "### A/B Testing\n",
    "- Blind experiments or A/B testing may be used to show if relationship between various variables\n",
    "- The experimental scenario needs to be divided into:  \n",
    "    - A: Sample is subjected to the known variable  \n",
    "    - B: Sample is not subjected to the known variable (the Control set)  \n",
    "- The validity of the the hypothesis is based on whether A has a different response compared to B, where the response is the target variable.   \n",
    "\n",
    "### Significance testing\n",
    "How much of a difference in results is enough?  \n",
    "- Must test the statistical significance  \n",
    "    - p value: units of chance of your “surprise” (0 to 1)  \n",
    "Considering how likely you could get the same results regardless of the hypothesis  \n",
    "- Hypothesis: Aspirin reduces heart attack  \n",
    "    - Sample: studied 100 men for 5 years  \n",
    "        Group HA: 50 men take aspirin daily  \n",
    "        Group HP: 50 men take placebo daily (control)  \n",
    "    - Results:  \n",
    "        - High p: HA 4 heart attacks, HP 5 heart attacks so both around 1 in 10 men  \n",
    "        - Low p: HP 10, HA 1, so very different and significant!  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be115e5",
   "metadata": {},
   "source": [
    "## Tutorial\n",
    "What's used in Amazon web page?   \n",
    "What's tracked?   \n",
    "Location to change  \n",
    "Reviews and ratings to add/read  \n",
    "Links to related products  \n",
    "\n",
    "What's it used for?  \n",
    "Clustering: book recommendations  \n",
    "Text analysis: contextualize reviews  \n",
    "Location specific pricing  \n",
    "\n",
    "Who owns the data?  \n",
    "Not us  \n",
    "\n",
    "Do we have a say?  \n",
    "No  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
