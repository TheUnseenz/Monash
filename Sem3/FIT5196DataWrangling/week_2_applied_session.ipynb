{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Week 2 Applied Session: Introduction to DataWrangling with Pandas**\n",
        "\n",
        "![](https://media.licdn.com/dms/image/D5612AQEdvrs4ha4KAQ/article-cover_image-shrink_600_2000/0/1693676526923?e=2147483647&v=beta&t=aegFlNZu0P_4UKcfh4ZTol_MmcIQzqoZx5tOKKMkI1E)"
      ],
      "metadata": {
        "id": "eYmhzN7z8B3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas is a strange name, kind of an acronym: Python, Numerical, Data Analysis?\n",
        "\n",
        "Because pandas is an external library you need to import it. There are several ways that you will see imports done:\n",
        "- import pandas\n",
        "- from pandas import tools\n",
        "- import pandas as `pd`\n",
        "\n",
        "The first is the same as `from pandas import *` where star means all (that's right, the same as SQL)\n",
        "\n",
        "The second imports a part of pandas only, a sublibrary called *tools*\n",
        "\n",
        "The third is a renaming, or alias, `pd` is common (you could call pandas `xyz` but you'd be on your own).\n",
        "\n",
        "You could leave out the `import as` and just type `pandas` every time but it becomes more useful for longer names e.g. `import matplotlib.pyplot as plt`\n",
        "\n",
        "So, for any code following (if the above imports work), `plt` would mean `matplotlib.pyplot`\n",
        "\n",
        "This, by the way, is a Python Notebook, select cells (this one is text, below is code) then `SHIFT-ENTER` to run sequentially\n",
        "\n",
        "The following scripts should work with both Python2 and Python 3!"
      ],
      "metadata": {
        "id": "T3xZv0hJ9Joe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries first\n",
        "import pandas as pd\n",
        "import numpy as np # Numberical Python"
      ],
      "metadata": {
        "id": "ugmiATcg_kJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. The Pandas DataFrame**"
      ],
      "metadata": {
        "id": "hgpe1tY4N0Iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# and make one of these dataframes...\n",
        "dataframe()"
      ],
      "metadata": {
        "id": "2jZu7uOKAChJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# oops, try another spelling\n",
        "Dataframe()"
      ],
      "metadata": {
        "id": "T_axiDfyACde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# no good? Try the library\n",
        "pd.dataframe()"
      ],
      "metadata": {
        "id": "rBb5MoqeACVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Errors\n",
        "<font color = \"green\">`module` object has no attribute `dataframe`<br></font>\n",
        "is better than<br>\n",
        "<font color = \"green\">name `Dataframe` is not defined<br></font>\n",
        "but neither are working...\n"
      ],
      "metadata": {
        "id": "AVh1DnvLALI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# so try pandas.DataFrame()\n",
        "pd.DataFrame()"
      ],
      "metadata": {
        "id": "A3T5-q3yACMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So.. no errors, seems to have worked, but what's in the DataFrame? (nothing)\n",
        "\n",
        "**note**: Python is case sensitive: `DataFrame` is not the same as `Dataframe` or `dataframe`"
      ],
      "metadata": {
        "id": "TxD9MQe09Jf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame([2,4,6,8])"
      ],
      "metadata": {
        "id": "2tjFQDp_YnyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aha, better but this is temporary, if you want to use the data you need to save it, so create a variable\n",
        "df = pd.DataFrame([2,4,6,8])"
      ],
      "metadata": {
        "id": "xNosDoxGYntM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# but now there's no output... can't win\n",
        "# use the variable to see the data\n",
        "df"
      ],
      "metadata": {
        "id": "ab8Q6OcNYnm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: the column titles are ` ` and `0`\n",
        "\n",
        "And another note: Python is one of those `0` index languages, we have 4 items `(2,4,6,8)` but they are found at `0,1,2,3` viz:"
      ],
      "metadata": {
        "id": "IoOJNPk79JXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# you can get the values with its index:\n",
        "df[0][1] # column 0, item 1"
      ],
      "metadata": {
        "id": "pYSJilPCZR6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename the column\n",
        "df.columns.name = \"Index\"\n",
        "df"
      ],
      "metadata": {
        "id": "6fzugzwsYm_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can also use pandas to create an series of datetime objects. Let's make one for the week beginning January 25th, 2015:\n",
        "dates = pd.date_range('20150125', periods=7)\n",
        "\n",
        "dates"
      ],
      "metadata": {
        "id": "d_O6SDH0ZRyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll create a DataFrame using the dates array as our index, fill it with some random values using numpy, and give the columns some labels.\n",
        "\n",
        "Note that `randn(7,5)` below matches the 7 dates (rows) and 5 names (columns)\n",
        "\n",
        "(Otherwise it wouldn't work, try changing 5 to 6...)"
      ],
      "metadata": {
        "id": "GzrmmX71a9Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(np.random.randn(7,5), index=dates, columns=['Adam','Bob','Carla','Dave','Eve'])\n",
        "df"
      ],
      "metadata": {
        "id": "EZ8_qy13ZRr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataFrames are more flexible than that, both in terms of what you can store in them and what you can do with them.\n",
        "\n",
        "It can also be useful to know how to create a DataFrame from a dict of objects.\n",
        "\n",
        "This comes in particularly handy when working with JSON-like structures."
      ],
      "metadata": {
        "id": "HeJWlbPA9JGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame({ 'A' : np.random.random_sample(4), # 4 random numbers\n",
        "                     'B' : pd.Timestamp('20130102'), # 4 dates, note pandas autofills\n",
        "                     'C' : pd.date_range('20150125',periods = 4), # 4 dates in a range\n",
        "                     'D' : ['a','b','c','d'], # letters\n",
        "                     'E' : [\"cat\",\"dog\",\"mouse\",\"parrot\"], # text/string\n",
        "                     'F' : 'copy'}) # note pandas autofills\n",
        "\n",
        "df2"
      ],
      "metadata": {
        "id": "FJTGxB4vax7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Br47ps9Q9I7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Exploring the data in a DataFrame**"
      ],
      "metadata": {
        "id": "KzeAocdi9Ir0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's import the UFO sightings dataset via URL. We can access the data types of each column in a DataFrame as follows:"
      ],
      "metadata": {
        "id": "VQOs_fmcbpTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo = pd.read_csv('http://bit.ly/uforeports')"
      ],
      "metadata": {
        "id": "jFEfyxYQcMVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can display the index, columns and the underlyinig numpy data separately:"
      ],
      "metadata": {
        "id": "tKhgqzvLhpii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo.index"
      ],
      "metadata": {
        "id": "GhK5fh2_hFh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ufo.columns"
      ],
      "metadata": {
        "id": "yzPXQ9UJhFdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can accesss the data types of each column:"
      ],
      "metadata": {
        "id": "ziid51aJinBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo.dtypes"
      ],
      "metadata": {
        "id": "N06W4aqwhFPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ufo.values"
      ],
      "metadata": {
        "id": "gFyEroOzhFXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can get the size of the data using `shape`:"
      ],
      "metadata": {
        "id": "3pcXypuByYFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo.shape"
      ],
      "metadata": {
        "id": "vKVN7Uy-x6Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can get a quick statistical summary of the data using `describe()` function:"
      ],
      "metadata": {
        "id": "gqHgDbt5hTbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo.describe()"
      ],
      "metadata": {
        "id": "DA7s2AZZhFTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can have a look at the data in first five rows using `head()` function:"
      ],
      "metadata": {
        "id": "4PSlODohjihD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo.head()"
      ],
      "metadata": {
        "id": "3WSRHf0yhFLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can indicate how many row to return by specifying an integer:"
      ],
      "metadata": {
        "id": "ny6AvOKakmQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo.head(20)"
      ],
      "metadata": {
        "id": "WAG_oqmVk2Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also have the last five rows using `tail()` function, check the index numbers:"
      ],
      "metadata": {
        "id": "p_WJUlt4kBlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo.tail()"
      ],
      "metadata": {
        "id": "IpvRA3xbhFHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can focus on a specific column:"
      ],
      "metadata": {
        "id": "Lq7K6SxmlAXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo['City']"
      ],
      "metadata": {
        "id": "9N2OIcG0hFCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can select a subset of rows by integer indexing:"
      ],
      "metadata": {
        "id": "b3Ixhf9_ltr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo[1:3]"
      ],
      "metadata": {
        "id": "TwrLPSO0hE0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**：Only the rows wiht index 1 and 2 returned."
      ],
      "metadata": {
        "id": "KfC7E88Fltcg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also select rows by specific values:"
      ],
      "metadata": {
        "id": "HFCO2RJtltHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo[['City','State']][ufo.State == 'NJ']"
      ],
      "metadata": {
        "id": "cUde07YYlsEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: `ufo.State == 'NJ'` is an example of using conditional indexing. We can also have other conditions like `<`, `>`, `<=`, `>=` or `!=` (not equal)."
      ],
      "metadata": {
        "id": "2zgtP_PixWNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo[['City','State']][ufo.State != 'NJ']"
      ],
      "metadata": {
        "id": "ENl6rLzGlr-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the difference between the following two functions `loc` and `iloc`?"
      ],
      "metadata": {
        "id": "7q1M1w5lmnhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo.loc[:,'City':'State'].head()"
      ],
      "metadata": {
        "id": "imAgHAUnmWw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ufo.iloc[1:6,2:6]"
      ],
      "metadata": {
        "id": "Ra6xvELGmk3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enter your answer here...."
      ],
      "metadata": {
        "id": "VnPAH5fmik7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KHldkgrM1zBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 1: Load data and get the basic information**\n",
        "\n",
        "In this task, you are asked to load a data file from Google Drive with your Monash account. Open the file to create a Pandas dataframe and explore it using the functions introduced above and see what information you can get from the data."
      ],
      "metadata": {
        "id": "zk8mHehr2PCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Connect with your Google Drive to access files**"
      ],
      "metadata": {
        "id": "RVfNqkf810MR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vNh5iVGJlr4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After you run the cell, then it asks you to click on a url and login in order to give premissions to Colab. If you successfully followed the steps, you should now see a drive folder in the left pane of this notebook. see below figure.\n",
        "\n",
        "![](https://drive.google.com/uc?export=download&id=1B2sooICEr_QDLEyFHOSwIQO89LODLfAq)\n",
        "\n",
        "If you click on it, you should be able to see the \"FIT5196_S1_2025\" shared drive. If you are unable to see that, let us know ASAP. But if you can see it, then it means that now this notebook have access to everything on that shared drive. Let's read the `xmart` data from there."
      ],
      "metadata": {
        "id": "E6nZvDJe2MLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xmart = pd.read_csv('/content/drive/Shareddrives/FIT5196_S1_2025/week2/xmart.csv',skiprows=1)\n"
      ],
      "metadata": {
        "id": "fWZbSp0Mlrxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, it is your turn to write Python codes and try to find out:\n",
        "1. How many records in the dataset?\n",
        "2. How many attributes in the dataset? What are they?\n",
        "3. What is the data type for each of the attribute?\n",
        "4. Without any description provided, can you summarize what information contains in this dataset?\n",
        "\n",
        "**Note**: Don't forget to use markdown to explain your findings."
      ],
      "metadata": {
        "id": "tOWN5LeGfaiy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RNWI_xxUgxd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oUPnr3DdgxWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AaKVr5OjgxNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u9CMPklngw-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3vucRQe1gvg4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Editing data in DataFrame**\n",
        "\n",
        "We can apply basic editing operations to DataFrame objects, such as updating, deleting, duplication, adding new columns, insert new rows, and etc."
      ],
      "metadata": {
        "id": "3IqrxPZ4lMdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.1 Dealing with missing values (simplest ways)**\n",
        "\n",
        "Continue with ufo data, we are looking for the data rows having missing city data and simply remove them."
      ],
      "metadata": {
        "id": "bgstYz0Ao7cP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo[10:20]"
      ],
      "metadata": {
        "id": "YOQEYFkRoEi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check whether the values is NaN or not\n",
        "ufo.isna()"
      ],
      "metadata": {
        "id": "I28foA_jqYjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find out how many missing values in each attribute\n",
        "ufo.isna().sum()"
      ],
      "metadata": {
        "id": "BTAUlj9Hqul5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list all the rows with missing values\n",
        "ufo[ufo.isna().any(axis=1)]"
      ],
      "metadata": {
        "id": "cLiEB8uIrzXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: The ufo dataset has 18,241 rows in total, but 15,755  of them have at least one missing value. We can simply remove all of them to keep the rows with complete data for next step analysis. To keep the original data, we create a new data frame to store the subset of data rows with complete values."
      ],
      "metadata": {
        "id": "dzstqH6Znhmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove data rows with missing values\n",
        "ufo1 = ufo.dropna()\n",
        "ufo1.head(20)"
      ],
      "metadata": {
        "id": "RUpyh_MGs5GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ufo1.isna().sum()"
      ],
      "metadata": {
        "id": "SeNO3t-JtdwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this way, only a very small part of the data is kept and we may not have enough data to work out any useful knowledge. Instead of removing all the missing values, we can replace missing parts with some specific values. For example, set them all to zero."
      ],
      "metadata": {
        "id": "bz-jdRelng1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo2 = ufo.fillna(value=0)\n",
        "ufo2.head(20)"
      ],
      "metadata": {
        "id": "eQzLoCyWubKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oops... we have nominal attributes, not numeric. Zeros do not work!!!\n",
        "\n",
        "First, let's copy the DataFrame to have a new one to work on."
      ],
      "metadata": {
        "id": "bWpawenSuvsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo3 = ufo.copy()\n",
        "ufo3[10:20]"
      ],
      "metadata": {
        "id": "b7jAbXYtvehz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ufo3['Colors Reported'].fillna('BLUE')\n",
        "ufo3[10:20]"
      ],
      "metadata": {
        "id": "UXgryAqTMKte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why do we stil have the missing values? Nothing happened?\n",
        "\n",
        "Let's try it again:"
      ],
      "metadata": {
        "id": "D3E-dhiJMPWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the null values with 'BLUE' in 'Colors Reported'\n",
        "ufo3['Colors Reported'].fillna('BLUE', inplace=True)\n",
        "ufo3[10:20]"
      ],
      "metadata": {
        "id": "h9URtPjuwFqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2 Create a new column**\n",
        "\n",
        "Let's create a new column with the combined City and State place names, called `place` with an empty string in every row. This isn't absolutely necessary when using proper Pandas methods but for the demonstration it will make it more straight forward."
      ],
      "metadata": {
        "id": "e_aujfJJ5wX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo4 = ufo.copy()\n",
        "ufo4['place']=''\n",
        "ufo4"
      ],
      "metadata": {
        "id": "Utuji0welrk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: By default, the new column is always added at the end"
      ],
      "metadata": {
        "id": "bx7a1xgl7okY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we combine the city and state, we need to check whether there are missing values in these two columns. From above, we know the `City` column has 26 rows with missing values and the `State` is complete. So we need to fill the `City` column before merging."
      ],
      "metadata": {
        "id": "u3lmjJ4KE6tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo4['City'].fillna('No city', inplace=True)"
      ],
      "metadata": {
        "id": "lCDMtASK_1g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ufo4['place'] = ufo4['City'] + ', ' + ufo4['State']\n",
        "ufo4"
      ],
      "metadata": {
        "id": "8elkltMW8gR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use a `for` loop to achieve the same result.\n",
        "\n",
        "Before we apply any operations that take use of index, remember to check the valid index range to avoid any errors."
      ],
      "metadata": {
        "id": "XE22IwYU9lmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo4.index"
      ],
      "metadata": {
        "id": "Z69MOQBO9mR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ufo4['address']=''\n",
        "ufo4"
      ],
      "metadata": {
        "id": "X1bLl9v5-c6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using a for loop to create each entry in turn\n",
        "\n",
        "for i in ufo4.index:\n",
        "    ufo4.iloc[i,6] = ufo4.iloc[i,0] + ', ' + ufo4.iloc[i,3]"
      ],
      "metadata": {
        "id": "BNRxBgMn-osA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ufo4\n"
      ],
      "metadata": {
        "id": "PnZonJtAAWTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have the same values in both `place` and `address`. But, which way is better?"
      ],
      "metadata": {
        "id": "bRgJYKRTF5q1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.3 Timing it**\n",
        "\n",
        "The notebook's magic `%%timeit` will run the cell 1000 times and get the 3 quickest times. We can use it to record the time and then do the comparison."
      ],
      "metadata": {
        "id": "4fUB3C8DIIY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo5 = ufo.copy()\n",
        "ufo5['City'].fillna('No city', inplace=True)\n",
        "ufo5"
      ],
      "metadata": {
        "id": "39hVOZ2qIrnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ufo5['place']=''\n",
        "ufo5['address']=''\n",
        "ufo5.head()"
      ],
      "metadata": {
        "id": "-zjU5mvEI3FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "\n",
        "ufo5['place'] = ufo5['City'] + ', ' + ufo5['State']"
      ],
      "metadata": {
        "id": "GcCsBN7fJCOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "\n",
        "for i in ufo5.index:\n",
        "    ufo5.iloc[i,6] = ufo5.iloc[i,0] + ', ' + ufo5.iloc[i,3]"
      ],
      "metadata": {
        "id": "LF7wGrNwJcYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can run the above codes many times, they may give different time, but using `for` loop is a much slower method.\n",
        "\n",
        "**Note**: Pandas is based on numpy arrays, so try everything you can to aviod iterating over rows."
      ],
      "metadata": {
        "id": "z5pqi0YCKRpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.4 Delete columns**\n",
        "\n",
        "We only need to keep one column for merged place, we can easily drop one."
      ],
      "metadata": {
        "id": "fKrlj8tkK2bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo5.drop(columns=['address'], inplace=True)\n",
        "ufo5.head()"
      ],
      "metadata": {
        "id": "mhVewlwDLo5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dLAxnukEPLim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 2: Reproducing the data wrangling process**\n",
        "\n",
        "Load an `Air Crashes` data, and try to answer the following questions:\n",
        "1. Give a summary of the data, including size, attributes, data types\n",
        "2. Does the dataset contain missing value? What are you going to deal with them?\n",
        "3. Check if there are any columns can be merged together? Apply the merging operation.\n",
        "4. Remove the column(s) that contains duplicated information after merging.\n",
        "5. Find out a subset that records air crashes with survivors."
      ],
      "metadata": {
        "id": "oduUIiTTPMgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aircrash = pd.read_csv('/content/drive/Shareddrives/FIT5196_S1_2025/week2/AirCrashes.csv')\n",
        "aircrash.head()"
      ],
      "metadata": {
        "id": "WZPPTGtAPKi_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}