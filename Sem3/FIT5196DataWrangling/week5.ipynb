{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04659866",
   "metadata": {},
   "source": [
    "# Week 5: Data Discovery and Collection\n",
    "\n",
    "## I. Introduction to Data in Decision-Making\n",
    "\n",
    "### A. Data Wrangling Recap\n",
    "Data wrangling involves a series of tasks to transform raw data into a usable format for analysis. Key stages include:\n",
    "-   Data Discovery\n",
    "-   Data Collection\n",
    "-   Data Cleaning\n",
    "-   Data Storing\n",
    "-   Data Pre-processing\n",
    "-   Data Transformation\n",
    "-   Data Enrichment\n",
    "-   Data Validation\n",
    "\n",
    "### B. Importance of Data\n",
    "Data is foundational for both modern business and scientific inquiry.\n",
    "\n",
    "**In Business Decision-Making**:\n",
    "-   **Evidence-based Decision-making**: Enables objective analysis and insight generation.\n",
    "-   **Customer Insights**: Helps in understanding customer behavior and offering personalized services.\n",
    "-   **Performance Optimization**: Improves operational efficiency and allows for benchmarking.\n",
    "-   **Risk Management**: Aids in identifying risks and forming mitigation strategies.\n",
    "-   **Innovation**: Identifies market needs and creates feedback loops for product development.\n",
    "\n",
    "**In Scientific Inquiry**:\n",
    "-   Enables quantitative and qualitative analysis.\n",
    "-   Facilitates hypothesis testing and theory development.\n",
    "-   Drives innovation and discovery.\n",
    "-   Improves research design.\n",
    "\n",
    "---\n",
    "\n",
    "## II. Data Discovery\n",
    "\n",
    "### A. Definition\n",
    "Data discovery is the process of **identifying and understanding data sources** that can be used for analytical purposes. Its primary goal is to gain actionable insights into available data and understand its potential for supporting research or business objectives.\n",
    "\n",
    "### B. Challenges in Data Discovery\n",
    "-   **Volume and Complexity**: The sheer amount of data can be overwhelming.\n",
    "-   **Data Quality and Silos**: Data can be inconsistent, inaccurate, or isolated in different departments.\n",
    "-   **Dynamic Data**: Data is constantly evolving and changing.\n",
    "-   **Privacy and Security**: Concerns about protecting sensitive information.\n",
    "-   **Lack of Metadata**: Poor documentation makes data hard to understand and use.\n",
    "-   **Integration Issues**: Difficulties in combining data from different systems.\n",
    "\n",
    "### C. The Data Discovery Process\n",
    "This is a series of tasks to identify, understand, and prepare data for analysis.\n",
    "\n",
    "1.  **Identification of Data Sources**:\n",
    "    -   Inventory existing data, also known as **secondary data**, which has already been collected for other purposes.\n",
    "    -   Sources can be **internal** (e.g., business records, transactional data) or **external** (e.g., government publications, social media, industry reports).\n",
    "    -   **Advantages of Existing Data**: Cost/time efficiency, access to broad data, and good for trend analysis.\n",
    "    -   **Limitations of Existing Data**: May not be relevant, quality can be poor, and access might be difficult.\n",
    "\n",
    "2.  **Data Profiling and Assessment**:\n",
    "    -   **Understand Data Structure**:\n",
    "        -   **Structured**: Highly organized, easily understood by machines (e.g., relational databases).\n",
    "        -   **Unstructured**: No pre-defined model, harder to analyze (e.g., text, multimedia).\n",
    "        -   **Time-Series**: Data points indexed in time order (e.g., sensor data, financial data).\n",
    "        -   **Graph Data**: Represents relationships between entities (e.g., social networks).\n",
    "        -   **Big Data**: Extremely voluminous data that requires advanced tools to process.\n",
    "    -   **Content Exploration**: Delve into the data to understand the types of information it holds (categorical, numerical, etc.).\n",
    "    -   **Quality Assessment**: Evaluate data for issues like missing values, duplicates, and inconsistencies.\n",
    "\n",
    "3.  **Data Cataloging and Metadata Management**:\n",
    "    -   Gather metadata (data about data) to understand its origin, format, and characteristics.\n",
    "    -   Create a searchable catalog of data assets.\n",
    "    -   Document data lineage to trace its path from source to current state.\n",
    "\n",
    "4.  **Data Cleaning and Preparation**:\n",
    "    -   **Cleansing**: Address quality issues by correcting errors, filling missing values, or removing duplicates.\n",
    "    -   **Transformation**: Convert data into a suitable format for analysis (e.g., normalization, aggregation).\n",
    "\n",
    "5.  **Data Integration and Consolidation**:\n",
    "    -   Combine data from multiple sources to create a unified dataset.\n",
    "    -   Harmonize formats and units to ensure consistency.\n",
    "\n",
    "6.  **Security and Compliance**:\n",
    "    -   Implement measures to protect sensitive data and ensure compliance with regulations like GDPR.\n",
    "    -   Establish access controls for authorized users only.\n",
    "\n",
    "7.  **Data Exploration and Visualization**:\n",
    "    -   Conduct Exploratory Data Analysis (EDA) to find initial patterns, trends, and anomalies.\n",
    "    -   Use visualization to represent data graphically for easier interpretation.\n",
    "\n",
    "8.  **Documentation and Sharing**:\n",
    "    -   Document all findings, challenges, and insights.\n",
    "    -   Share findings with stakeholders to support decision-making.\n",
    "\n",
    "---\n",
    "\n",
    "## III. Data Collection\n",
    "\n",
    "### A. Definition\n",
    "Data collection is the **systematic process of gathering and measuring information** on variables of interest to answer research questions, test hypotheses, and evaluate outcomes.\n",
    "\n",
    "### B. Key Data Distinctions\n",
    "\n",
    "**1. Primary vs. Secondary Data**\n",
    "-   **Primary Data**: Original data collected firsthand by the researcher for a specific purpose. The researcher controls the methodology and scope.\n",
    "-   **Secondary Data**: Information that was previously collected by someone else for a different purpose.\n",
    "\n",
    "**2. Quantitative vs. Qualitative Data**\n",
    "-   **Quantitative Data**: Data that can be measured numerically. It focuses on *quantity* and is suitable for statistical analysis. Often collected via surveys and experiments.\n",
    "-   **Qualitative Data**: Descriptive and conceptual data that can be observed but not measured with numbers. It is often textual or visual and helps in understanding concepts, thoughts, or experiences.\n",
    "\n",
    "### C. Data Collection Methods\n",
    "\n",
    "**1. For Structured Data**\n",
    "-   **Surveys and Questionnaires**: Requires clear objectives, good question design, proper sampling, and pilot testing.\n",
    "-   **Web Scraping**: Involves legal and ethical considerations, technical challenges, and ensuring data quality.\n",
    "-   **Relational Databases**: Requires good database design, ensuring data integrity, and planning for scalability and security.\n",
    "-   **APIs (Application Programming Interfaces)**: Involves reviewing documentation, handling authentication, and respecting rate limits.\n",
    "\n",
    "**2. For Unstructured Data**\n",
    "-   **Text Mining & NLP**: Requires significant data preparation, choosing the right models, and understanding context.\n",
    "-   **Image and Video Collection**: Key considerations include ensuring consistent quality, diversity, accurate annotations, and managing large file sizes.\n",
    "-   **Social Media and Web Content**: Must adhere to API terms of use, handle \"noisy\" and dynamic content, and consider sampling bias.\n",
    "\n",
    "**3. For Semi-structured Data**\n",
    "-   **JSON and XML Extraction**: Requires understanding the hierarchical structure and using appropriate parsing libraries.\n",
    "-   **Logs and Sensor Data**: Must handle high volume and velocity, diverse formats, and time-sensitivity.\n",
    "-   **Email and Communication Data**: Presents challenges related to privacy compliance, complex structures, and filtering noise.\n",
    "\n",
    "---\n",
    "\n",
    "## IV. Ethical Considerations and Privacy\n",
    "\n",
    "Ethical principles are paramount in data collection to protect individuals' rights and maintain trust.\n",
    "\n",
    "-   **Informed Consent**: Participants should be fully informed about the data collection in a transparent way and participate voluntarily.\n",
    "-   **Privacy and Anonymity**: Personal information must be protected, often through anonymization techniques.\n",
    "-   **Data Security**: Implement secure storage, transmission, and access controls.\n",
    "-   **Compliance**: Adhere to all relevant laws and regulations (e.g., GDPR).\n",
    "-   **Data Minimization**: Collect only the data that is necessary for the specific purpose.\n",
    "-   **Equity and Fairness**: Ensure data collection is inclusive and avoids bias.\n",
    "-   **Data Retention and Disposal**: Have clear policies for how long data is stored and how it is securely destroyed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d1d825",
   "metadata": {},
   "source": [
    "# Data Discovery and Collection\n",
    "Data preprocessing pipeline, in order:  \n",
    "- Data discovery  \n",
    "- Collection  \n",
    "- Storing  \n",
    "  \n",
    "- Cleaning  \n",
    "- Preprocessing  \n",
    "- Validation  \n",
    "  \n",
    "- Transformation  \n",
    "- Enrichment  \n",
    "\n",
    "In reality, we usually collect the data we need for the question/problem we have.  \n",
    "In assignment, it's reversed - we find the questions/problems our data can solve.  \n",
    "Insights are deep, you need something that's not immediately obvious  \n",
    "Don't include just every plot. Include the most important ones  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002dd978",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "Is big data structured data, unstructured data or semi-structured data?  \n",
    "All 3 of them - some structured, some unstructured, some semi-structured data.  \n",
    "\n",
    "Question 2:\n",
    "Can you give 4 examples of primary data and secondary data respectively?\n",
    "Primary data:\n",
    "1. Surveys\n",
    "2. Interviews\n",
    "3. Sensor data\n",
    "4. Lab experiments\n",
    "\n",
    "Secondary data:\n",
    "1. Web articles\n",
    "2. Scientific papers\n",
    "3. Online databases\n",
    "4. Customer reviews\n",
    "\n",
    "Question 3:\n",
    "When you join a project in your final year, do you need to submit an ethics application? why?\n",
    "As long as your project involves any kind of data collection or experiment, you will need an ethics application.\n",
    "This is to ensure your data collection or experiment respects the participants and their data, and takes only as little and as anonymously as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7da7090",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
