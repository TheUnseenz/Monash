{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d1d825",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "- Exploratory Data Analysis (EDA) is a crucial step in the data analysis process, enabling data scientists\n",
    "and analysts to understand the patterns, anomalies, and relationships in their data.  \n",
    "- The goal of EDA is to use statistical graphics, plots, and information tables to explore and summarize\n",
    "the main characteristics of the data, often visually, without making any assumptions about its\n",
    "contents.  \n",
    "- This approach helps in identifying the underlying structure, detecting outliers or anomalies, testing\n",
    "assumptions, and developing initial ideas for models.  \n",
    "\n",
    "Common Data Types  \n",
    "- Numerical  \n",
    "- Categorical  \n",
    "- Text  \n",
    "- Image  \n",
    "\n",
    "You need to know the data type to tell what to do with it  \n",
    "- Analysis  \n",
    "- Visualization  \n",
    "- Methods for cleaning and pre-processing  \n",
    "- Feature engineering   \n",
    "- Suitable algorithms and models    \n",
    "- Ensuring data integrity  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e3e16c",
   "metadata": {},
   "source": [
    "## Descriptive statistics\n",
    "Summarizing organizing, presenting data meaningfully and concisely.  \n",
    "- Describes the main features and characteristics without making any generalizations or inferences about a larger population.  \n",
    "- Gives insights and understanding of patterns, trends and distributions within the dataset  \n",
    "- Can also be graphical representation of data through charts/tables/graphs/etc  \n",
    "- Examples:\n",
    "    - Central tendency (mean/mode/median)  \n",
    "    - Dispersion (range/variance/std deviation)  \n",
    "    - Shape of distribution (skewness, kurtosis)  \n",
    "\n",
    "Text data:  \n",
    "- Semantics -> sentiment analysis\n",
    "- Preprocessing techniques:\n",
    "    - One-hot encoding  \n",
    "    - Label encoding   \n",
    "    - Count vectorizer -> can do euclidean/cosine distance  \n",
    "    - Tokenization: Important preprocessing for NLP models and text analysis    \n",
    "        - Word  \n",
    "        - Sentence  \n",
    "        - Subword  \n",
    "        - Character  \n",
    "    - Case normalization  \n",
    "        - Is not always helpful, helps readers differentiate  \n",
    "    - Removing stop words: has little value on analysis\n",
    "        - Articles (a, the, an)  \n",
    "        - Pronouns (he, him)  \n",
    "        - Particles (well, however, thus)  \n",
    "    - Stemming/Lemmatization: removing prefixes, suffixes, etc\n",
    "        - Stemming is the naive way that just looks at the shorter base forms of words  \n",
    "        - Lemmatization is more robust and grammatically correct and looks at different ways words are spelt in their base form, but takes more computing  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edee717",
   "metadata": {},
   "source": [
    "Q1: Among these 3 central tendency indicators, which one is the best to use when doing EDA for a new dataset?\n",
    "A: Use all 3, as they describe the shape of the distribution better when combined together. You need to look at the nature of the data to determine which single one is best.\n",
    "\n",
    "Q2: How to visualize data in high dimensionality?\n",
    "A: Select the dimensions you need, and use other attributes to encode more dimensions like colour, size, shape to create creative graphs and visualizations to visualize your high-dimension data.\n",
    "\n",
    "Q3: how to calculate the similarity between these two phrases?\n",
    "1. \"The cat sat on the mat.\"\n",
    "2. \"The dog sat on the log.\"\n",
    "A: Tokenize and normalize the text, build a count vector of the vocabulary used, and calculate the euclidean and cosine distance of the words."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
