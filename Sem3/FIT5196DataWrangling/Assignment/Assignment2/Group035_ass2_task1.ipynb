{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoekGA7GOds1"
      },
      "source": [
        "# FIT5196 Assessment 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBQqEv75OmOr"
      },
      "source": [
        "## Task 1. Data Cleansing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsqdMLFMv5PQ"
      },
      "source": [
        "### 1.1 Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY6ZwHgw8C-a",
        "outputId": "80022cdd-6e6e-44fb-c632-7bf46a507389"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/drive')\n",
        "# base = \"/content/drive/MyDrive/FIT5196Assignment2/\" # for colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u4k1Nb-39jM5"
      },
      "outputs": [],
      "source": [
        "# Begin here if running locally\n",
        "\n",
        "# for local drive\n",
        "base = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YnlBww44vcHC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\adria\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "from math import radians, cos, sin, asin, sqrt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# --- Prepare Sentiment analyzer ---\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Warehouse data\n",
        "warehouse_data = pd.read_csv(base + 'warehouses.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "knnTQ100A0dl"
      },
      "outputs": [],
      "source": [
        "# Dirty data\n",
        "dirty_data = pd.read_csv(base + 'Group_035_dirty_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r7kPAHhdBARv"
      },
      "outputs": [],
      "source": [
        "# Missing data\n",
        "missing_data = pd.read_csv(base + 'Group_035_missing_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iRC-X7KrBAYl"
      },
      "outputs": [],
      "source": [
        "# Outlier data\n",
        "outlier_data = pd.read_csv(base + 'Group_035_outlier_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CqxvIYv_DZxN"
      },
      "outputs": [],
      "source": [
        "# --- Haversine helper ---\n",
        "def haversine_dist(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"\n",
        "    Calculate the Haversine distance between two points on the Earth's surface.\n",
        "    \"\"\"\n",
        "    R = 6378  # Earth radius in KM\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    return R * c\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAqJ1zv_OTIo"
      },
      "source": [
        "### 1.2 Dirty Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn2zyrGvZdum"
      },
      "source": [
        "#### 1.2.1 Dirty Data EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJfsoooPncBx",
        "outputId": "33ea9b6d-8a01-4f63-ccba-cc0b5d714923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "order_id                          object\n",
            "customer_id                       object\n",
            "date                              object\n",
            "nearest_warehouse                 object\n",
            "shopping_cart                     object\n",
            "order_price                        int64\n",
            "delivery_charges                 float64\n",
            "customer_lat                     float64\n",
            "customer_long                    float64\n",
            "coupon_discount                    int64\n",
            "order_total                      float64\n",
            "season                            object\n",
            "is_expedited_delivery               bool\n",
            "distance_to_nearest_warehouse    float64\n",
            "latest_customer_review            object\n",
            "is_happy_customer                   bool\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Check all the data type\n",
        "print(dirty_data.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "o8RvXGgb44FI",
        "outputId": "23641a8a-16d0-4906-b0af-8d6ac31e745a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_id</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>date</th>\n",
              "      <th>nearest_warehouse</th>\n",
              "      <th>shopping_cart</th>\n",
              "      <th>order_price</th>\n",
              "      <th>delivery_charges</th>\n",
              "      <th>customer_lat</th>\n",
              "      <th>customer_long</th>\n",
              "      <th>coupon_discount</th>\n",
              "      <th>order_total</th>\n",
              "      <th>season</th>\n",
              "      <th>is_expedited_delivery</th>\n",
              "      <th>distance_to_nearest_warehouse</th>\n",
              "      <th>latest_customer_review</th>\n",
              "      <th>is_happy_customer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>499</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>500</td>\n",
              "      <td>493</td>\n",
              "      <td>304</td>\n",
              "      <td>6</td>\n",
              "      <td>460</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>499</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>ORD089659</td>\n",
              "      <td>ID0443530293</td>\n",
              "      <td>2019-05-25</td>\n",
              "      <td>Thompson</td>\n",
              "      <td>[('Lucent 330S', 1), ('iAssist Line', 1)]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Summer</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>great value hard to beat for the price.</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>201</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>128</td>\n",
              "      <td>258</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13864.580000</td>\n",
              "      <td>78.031120</td>\n",
              "      <td>-27.942558</td>\n",
              "      <td>135.095643</td>\n",
              "      <td>10.740000</td>\n",
              "      <td>12598.740340</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.064670</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7781.162606</td>\n",
              "      <td>14.400599</td>\n",
              "      <td>41.353147</td>\n",
              "      <td>41.351948</td>\n",
              "      <td>8.449567</td>\n",
              "      <td>6961.477582</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.492255</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1375.000000</td>\n",
              "      <td>46.400000</td>\n",
              "      <td>-37.831769</td>\n",
              "      <td>-37.827219</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1450.550000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.031900</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7900.000000</td>\n",
              "      <td>66.695000</td>\n",
              "      <td>-37.818620</td>\n",
              "      <td>144.948830</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>7405.700000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.727350</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12260.000000</td>\n",
              "      <td>76.820000</td>\n",
              "      <td>-37.812261</td>\n",
              "      <td>144.962138</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>11111.125000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.025750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19260.000000</td>\n",
              "      <td>85.802500</td>\n",
              "      <td>-37.805632</td>\n",
              "      <td>144.978927</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16934.422500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.359200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>39330.000000</td>\n",
              "      <td>112.430000</td>\n",
              "      <td>145.009445</td>\n",
              "      <td>145.018319</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>34318.220000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.829200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         order_id   customer_id        date nearest_warehouse  \\\n",
              "count         500           500         500               500   \n",
              "unique        500           493         304                 6   \n",
              "top     ORD089659  ID0443530293  2019-05-25          Thompson   \n",
              "freq            1             2           6               201   \n",
              "mean          NaN           NaN         NaN               NaN   \n",
              "std           NaN           NaN         NaN               NaN   \n",
              "min           NaN           NaN         NaN               NaN   \n",
              "25%           NaN           NaN         NaN               NaN   \n",
              "50%           NaN           NaN         NaN               NaN   \n",
              "75%           NaN           NaN         NaN               NaN   \n",
              "max           NaN           NaN         NaN               NaN   \n",
              "\n",
              "                                    shopping_cart   order_price  \\\n",
              "count                                         500    500.000000   \n",
              "unique                                        460           NaN   \n",
              "top     [('Lucent 330S', 1), ('iAssist Line', 1)]           NaN   \n",
              "freq                                            4           NaN   \n",
              "mean                                          NaN  13864.580000   \n",
              "std                                           NaN   7781.162606   \n",
              "min                                           NaN   1375.000000   \n",
              "25%                                           NaN   7900.000000   \n",
              "50%                                           NaN  12260.000000   \n",
              "75%                                           NaN  19260.000000   \n",
              "max                                           NaN  39330.000000   \n",
              "\n",
              "        delivery_charges  customer_lat  customer_long  coupon_discount  \\\n",
              "count         500.000000    500.000000     500.000000       500.000000   \n",
              "unique               NaN           NaN            NaN              NaN   \n",
              "top                  NaN           NaN            NaN              NaN   \n",
              "freq                 NaN           NaN            NaN              NaN   \n",
              "mean           78.031120    -27.942558     135.095643        10.740000   \n",
              "std            14.400599     41.353147      41.351948         8.449567   \n",
              "min            46.400000    -37.831769     -37.827219         0.000000   \n",
              "25%            66.695000    -37.818620     144.948830         5.000000   \n",
              "50%            76.820000    -37.812261     144.962138        10.000000   \n",
              "75%            85.802500    -37.805632     144.978927        15.000000   \n",
              "max           112.430000    145.009445     145.018319        25.000000   \n",
              "\n",
              "         order_total  season is_expedited_delivery  \\\n",
              "count     500.000000     500                   500   \n",
              "unique           NaN       8                     2   \n",
              "top              NaN  Summer                  True   \n",
              "freq             NaN     128                   258   \n",
              "mean    12598.740340     NaN                   NaN   \n",
              "std      6961.477582     NaN                   NaN   \n",
              "min      1450.550000     NaN                   NaN   \n",
              "25%      7405.700000     NaN                   NaN   \n",
              "50%     11111.125000     NaN                   NaN   \n",
              "75%     16934.422500     NaN                   NaN   \n",
              "max     34318.220000     NaN                   NaN   \n",
              "\n",
              "        distance_to_nearest_warehouse  \\\n",
              "count                      500.000000   \n",
              "unique                            NaN   \n",
              "top                               NaN   \n",
              "freq                              NaN   \n",
              "mean                         1.064670   \n",
              "std                          0.492255   \n",
              "min                          0.031900   \n",
              "25%                          0.727350   \n",
              "50%                          1.025750   \n",
              "75%                          1.359200   \n",
              "max                          2.829200   \n",
              "\n",
              "                         latest_customer_review is_happy_customer  \n",
              "count                                       499               500  \n",
              "unique                                      499                 2  \n",
              "top     great value hard to beat for the price.              True  \n",
              "freq                                          1               372  \n",
              "mean                                        NaN               NaN  \n",
              "std                                         NaN               NaN  \n",
              "min                                         NaN               NaN  \n",
              "25%                                         NaN               NaN  \n",
              "50%                                         NaN               NaN  \n",
              "75%                                         NaN               NaN  \n",
              "max                                         NaN               NaN  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Summary of dirty data\n",
        "dirty_data.describe(include = \"all\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXOgSN4zb1qI"
      },
      "source": [
        "#### 1.2.1.1 Individual Column EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZWfGwuhORVN",
        "outputId": "7b67f278-bd3c-408d-a9d4-76f9162193c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invalid date: 27\n",
            " order_id  customer_id date season\n",
            "ORD164387 ID0289597227  NaT Summer\n",
            "ORD066446 ID0145235264  NaT Winter\n",
            "ORD312565 ID0638050574  NaT Summer\n",
            "ORD181051 ID0709970691  NaT Summer\n",
            "ORD046408 ID5402876538  NaT Spring\n",
            "ORD219265 ID0055722470  NaT Winter\n",
            "ORD006455 ID0634777174  NaT Spring\n",
            "ORD084861 ID3094966833  NaT Winter\n",
            "ORD438655 ID2705184152  NaT Summer\n",
            "ORD234563 ID2383211199  NaT Spring\n",
            "ORD199817 ID0650275823  NaT Summer\n",
            "ORD113549 ID0634780047  NaT Autumn\n",
            "ORD489756 ID0846548135  NaT Spring\n",
            "ORD273300 ID0052599838  NaT Spring\n",
            "ORD194653 ID0575428932  NaT Summer\n",
            "ORD480775 ID4655129040  NaT Spring\n",
            "ORD160619 ID0746917821  NaT Winter\n",
            "ORD402436 ID2621587173  NaT Autumn\n",
            "ORD311888 ID1463620717  NaT Autumn\n",
            "ORD491911 ID2237521759  NaT Winter\n",
            "ORD265708 ID1889073821  NaT Summer\n",
            "ORD060082 ID0576834725  NaT Summer\n",
            "ORD469475 ID0767665017  NaT Summer\n",
            "ORD461231 ID0126934555  NaT Winter\n",
            "ORD047863 ID0638044384  NaT Autumn\n",
            "ORD499923 ID6197211200  NaT Spring\n",
            "ORD036565 ID0616939377  NaT Spring\n",
            "Min date: 2019-01-01 00:00:00\n",
            "Max date: 2019-12-30 00:00:00\n",
            "Number of valid dates: 473\n",
            "Number of unique dates: 278\n"
          ]
        }
      ],
      "source": [
        "# date\n",
        "dirty_data[\"date\"] = pd.to_datetime(dirty_data[\"date\"], errors=\"coerce\")\n",
        "\n",
        "# Invalid date\n",
        "print(f\"Invalid date: {dirty_data['date'].isna().sum()}\")\n",
        "invalid_date = dirty_data[dirty_data[\"date\"].isna()]\n",
        "print(invalid_date[[\"order_id\", \"customer_id\", \"date\", \"season\"]].to_string(index=False))\n",
        "\n",
        "# Date distribution\n",
        "valid_dates = dirty_data[\"date\"].dropna()\n",
        "print(f\"Min date: {valid_dates.min()}\")\n",
        "print(f\"Max date: {valid_dates.max()}\")\n",
        "print(f\"Number of valid dates: {valid_dates.count()}\")\n",
        "print(f\"Number of unique dates: {valid_dates.nunique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34pnwHsQO0eT",
        "outputId": "dd7e30d3-e2c7-4038-e9bc-577bf32b64ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invalid season found: 0\n",
            "['Thompson' 'Nickolson' 'Bakers' 'thompson' 'nickolson' 'bakers']\n",
            "Number of invalid nearest warehouse names: 20\n",
            "nearest_warehouse\n",
            "Thompson     201\n",
            "Nickolson    180\n",
            "Bakers        99\n",
            "thompson       9\n",
            "nickolson      7\n",
            "bakers         4\n",
            "Name: count, dtype: int64\n",
            " order_id nearest_warehouse\n",
            "ORD256861          thompson\n",
            "ORD014442          thompson\n",
            "ORD052629         nickolson\n",
            "ORD166717          thompson\n",
            "ORD461915         nickolson\n",
            "ORD461426            bakers\n",
            "ORD015774         nickolson\n",
            "ORD169718         nickolson\n",
            "ORD120949            bakers\n",
            "ORD138742            bakers\n",
            "ORD025929            bakers\n",
            "ORD393258          thompson\n",
            "ORD201338         nickolson\n",
            "ORD224300         nickolson\n",
            "ORD016571         nickolson\n",
            "ORD471229          thompson\n",
            "ORD164906          thompson\n",
            "ORD118183          thompson\n",
            "ORD300512          thompson\n",
            "ORD099672          thompson\n"
          ]
        }
      ],
      "source": [
        "# nearest_warehouse\n",
        "# Invalid nearest_warehouse names\n",
        "invalid_warehouse_name = dirty_data[dirty_data[\"nearest_warehouse\"].isna()]\n",
        "print(\"Invalid season found:\", len(invalid_warehouse_name))\n",
        "\n",
        "# Unique values\n",
        "print(dirty_data[\"nearest_warehouse\"].unique())\n",
        "\n",
        "# Invalid nearest_warehouse value\n",
        "invalid_warehouses = dirty_data[~dirty_data[\"nearest_warehouse\"].isin(warehouse_data[\"names\"])]\n",
        "print(\"Number of invalid nearest warehouse names:\", len(invalid_warehouses))\n",
        "print(dirty_data[\"nearest_warehouse\"].value_counts(dropna=False))\n",
        "print(invalid_warehouses[[\"order_id\", \"nearest_warehouse\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px_KfsRLO9eZ",
        "outputId": "c07c245f-eea9-4c82-fa90-e592baf9667e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of invalid values: 0\n",
            "Number of invalid items: 0\n",
            "Number of duplicated items: 0\n",
            "Number of unique branded items: 10\n",
            "Unique branded items: ['iAssist Line' 'Alcon 10' 'Universe Note' 'pearTV' 'Toshika 750'\n",
            " 'Candle Inferno' 'Thunder line' 'iStream' 'Olivia x460' 'Lucent 330S']\n",
            "iAssist Line      169\n",
            "Toshika 750       163\n",
            "Lucent 330S       154\n",
            "Alcon 10          153\n",
            "Thunder line      151\n",
            "pearTV            147\n",
            "Candle Inferno    147\n",
            "Olivia x460       146\n",
            "iStream           141\n",
            "Universe Note     134\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# shopping_cart (item ordered)\n",
        "# Extract the necessary columns\n",
        "shopping_cart_check = dirty_data[[\"order_id\", \"shopping_cart\", \"order_total\"]].copy()\n",
        "\n",
        "# Parses the shopping_cart value to get the item ordered\n",
        "shopping_cart_check[\"shopping_cart_parsed\"] = shopping_cart_check[\"shopping_cart\"].apply(ast.literal_eval)\n",
        "branded_items = [item for cart in shopping_cart_check[\"shopping_cart_parsed\"] for (item, qty) in cart]\n",
        "\n",
        "# Invalid value\n",
        "invalid_cart = shopping_cart_check[shopping_cart_check[\"shopping_cart\"].isna() | shopping_cart_check[\"shopping_cart\"].eq(\"[]\")]\n",
        "print(\"Number of invalid values:\", len(invalid_cart))\n",
        "invalid_items = [item for item in branded_items if pd.isna(item) or item is None]\n",
        "print(\"Number of invalid items:\", len(invalid_items))\n",
        "invalid_duplicates = shopping_cart_check[shopping_cart_check[\"shopping_cart_parsed\"].apply(lambda cart: len({item for item, qty in cart}) != len(cart))]\n",
        "print(\"Number of duplicated items:\", len(invalid_duplicates))\n",
        "\n",
        "# Count and value of unique branded items\n",
        "unique_branded_items = pd.Series(branded_items).unique()\n",
        "print(f\"Number of unique branded items:\", len(unique_branded_items))\n",
        "print(f\"Unique branded items:\", unique_branded_items)\n",
        "\n",
        "# Frequency distribution\n",
        "print(pd.Series(branded_items).value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzv5rTEhPDut",
        "outputId": "81aca727-aaff-4626-8b40-8ea447274c0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invalid coordinates found: 27\n",
            " order_id  customer_id  customer_lat  customer_long\n",
            "ORD091929 ID0145235237    144.959364     -37.815878\n",
            "ORD299508 ID0260907252    145.009445     -37.823816\n",
            "ORD074143 ID6167247310    144.960234     -37.819701\n",
            "ORD392203 ID0588197234    144.973944     -37.812101\n",
            "ORD208957 ID6245731092    144.977354     -37.810785\n",
            "ORD090831 ID1519470918    144.993262     -37.797624\n",
            "ORD062280 ID6167489480    144.961790     -37.816990\n",
            "ORD155978 ID0452381032    144.949411     -37.824991\n",
            "ORD493957 ID0361227457    144.976899     -37.801182\n",
            "ORD083244 ID0577458190    144.977813     -37.818479\n",
            "ORD373348 ID1888340704    144.985178     -37.793879\n",
            "ORD055195 ID2399230968    144.983469     -37.806415\n",
            "ORD125480 ID2190483590    144.961303     -37.810368\n",
            "ORD285476 ID2141904233    144.935968     -37.802954\n",
            "ORD349254 ID0387153047    144.947587     -37.805420\n",
            "ORD048052 ID0207093528    145.004517     -37.801171\n",
            "ORD479919 ID1449297346    144.977507     -37.815613\n",
            "ORD326763 ID0581709069    144.928230     -37.805420\n",
            "ORD442562 ID0846546860    144.968618     -37.820067\n",
            "ORD063341 ID0248266235    144.988143     -37.827219\n",
            "ORD012510 ID1833120524    144.954950     -37.799791\n",
            "ORD070213 ID0054398922    144.946328     -37.801354\n",
            "ORD481618 ID2810279739    144.988204     -37.816652\n",
            "ORD202182 ID0129549424    144.931580     -37.809350\n",
            "ORD396842 ID0589420528    144.972599     -37.809694\n",
            "ORD130131 ID1283671454    144.964657     -37.796916\n",
            "ORD201885 ID0026051952    144.968469     -37.813794\n"
          ]
        }
      ],
      "source": [
        "# Longitude: customer_lat, customer_long\n",
        "invalid_coords = dirty_data[dirty_data[\"customer_lat\"].isna() |\n",
        "                            dirty_data[\"customer_long\"].isna() |\n",
        "                            ~dirty_data[\"customer_lat\"].between(-90, 90) |\n",
        "                            ~dirty_data[\"customer_long\"].between(-180, 180)]\n",
        "print(\"Invalid coordinates found:\", len(invalid_coords))\n",
        "print(invalid_coords[[\"order_id\", \"customer_id\", \"customer_lat\", \"customer_long\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVXATQJSPI2I",
        "outputId": "42bdc2b1-b550-4c71-a76b-10c097f19e2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invalid distance found: 0\n"
          ]
        }
      ],
      "source": [
        "# distance_to_nearest_warehouse\n",
        "invalid_distance = dirty_data[dirty_data[\"distance_to_nearest_warehouse\"].isna() |\n",
        "                              dirty_data[\"distance_to_nearest_warehouse\"] <= 0]\n",
        "print(\"Invalid distance found:\", len(invalid_distance))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiSuMZnCPLSV",
        "outputId": "d2369f27-e76e-43fa-b289-47e15cced860"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invalid order total found: 0\n"
          ]
        }
      ],
      "source": [
        "# order_total\n",
        "invalid_total = dirty_data[dirty_data[\"order_total\"].isna() |\n",
        "                           dirty_data[\"order_total\"] <= 0 |\n",
        "                           (dirty_data[\"order_total\"].apply(lambda x: len(str(x).split('.')[-1]) > 2 if '.' in str(x) else False))]\n",
        "print(\"Invalid order total found:\", len(invalid_total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7bWp26CPMo8",
        "outputId": "4529e106-2e4e-479b-eb27-21a429cdce4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invalid season found: 0\n",
            "['Winter' 'Summer' 'spring' 'Autumn' 'Spring' 'autumn' 'winter' 'summer']\n",
            "Number of seasons not capitalised correctly: 21\n",
            "season\n",
            "Summer    128\n",
            "Winter    124\n",
            "Spring    120\n",
            "Autumn    107\n",
            "spring      9\n",
            "summer      6\n",
            "autumn      3\n",
            "winter      3\n",
            "Name: count, dtype: int64\n",
            " order_id season\n",
            "ORD209240 spring\n",
            "ORD277275 spring\n",
            "ORD123382 autumn\n",
            "ORD209230 winter\n",
            "ORD132264 spring\n",
            "ORD192930 spring\n",
            "ORD172628 spring\n",
            "ORD103002 summer\n",
            "ORD344249 summer\n",
            "ORD222038 summer\n",
            "ORD026633 summer\n",
            "ORD455600 summer\n",
            "ORD468030 spring\n",
            "ORD478782 winter\n",
            "ORD345384 summer\n",
            "ORD493849 spring\n",
            "ORD492808 winter\n",
            "ORD385926 spring\n",
            "ORD462038 autumn\n",
            "ORD434426 spring\n",
            "ORD387883 autumn\n"
          ]
        }
      ],
      "source": [
        "# season\n",
        "# Invalid season names\n",
        "invalid_season = dirty_data[dirty_data[\"season\"].isna()]\n",
        "print(\"Invalid season found:\", len(invalid_season))\n",
        "\n",
        "# Unique values\n",
        "print(dirty_data[\"season\"].unique())\n",
        "\n",
        "# Invalid letter case\n",
        "invalid_case_season = dirty_data[~dirty_data[\"season\"].str.match(r\"^[A-Z][a-z]+$\", na=False)]\n",
        "print(\"Number of seasons not capitalised correctly:\", len(invalid_case_season))\n",
        "print(dirty_data[\"season\"].value_counts(dropna=False))\n",
        "print(invalid_case_season[[\"order_id\", \"season\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO8CchpmPOQy",
        "outputId": "c2d534b9-ae2e-4943-d3e3-cbaea1f910fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invalid expedited delivery found: 0\n",
            "is_expedited_delivery\n",
            "True     258\n",
            "False    242\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# is_expedited_delivery\n",
        "invalid_expedited = dirty_data[dirty_data[\"is_expedited_delivery\"].isna()]\n",
        "print(\"Invalid expedited delivery found:\", len(invalid_expedited))\n",
        "print(dirty_data[\"is_expedited_delivery\"].value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju9kAa7rPRHm",
        "outputId": "f537197a-ec90-44b5-d8fb-7c3ca338aba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invalid positive customer response found: 0\n",
            "is_happy_customer\n",
            "True     372\n",
            "False    128\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# is_happy_customer\n",
        "invalid_happy = dirty_data[dirty_data[\"is_happy_customer\"].isna()]\n",
        "print(\"Invalid positive customer response found:\", len(invalid_happy))\n",
        "print(dirty_data[\"is_happy_customer\"].value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkLcUyjXcDo0"
      },
      "source": [
        "#### 1.2.1.2 Cross-Column EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD8DWmeYTJhz",
        "outputId": "2751bd42-fc1f-4294-9c53-be616cb0da1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mismatched date-season pairs: 21\n",
            "Number of seasons not capitalised correctly in date-season pairs: 15\n",
            " order_id       date  month season\n",
            "ORD209240 2019-02-07      2 spring\n",
            "ORD419503 2019-09-21      9 Autumn\n",
            "ORD277275 2019-12-26     12 spring\n",
            "ORD123382 2019-01-06      1 autumn\n",
            "ORD209230 2019-09-03      9 winter\n",
            "ORD192930 2019-08-30      8 spring\n",
            "ORD172628 2019-03-30      3 spring\n",
            "ORD103002 2019-10-17     10 summer\n",
            "ORD040501 2019-10-17     10 Summer\n",
            "ORD344249 2019-10-23     10 summer\n",
            "ORD222038 2019-11-04     11 summer\n",
            "ORD377228 2019-09-24      9 Autumn\n",
            "ORD468030 2019-05-06      5 spring\n",
            "ORD363647 2019-12-01     12 Winter\n",
            "ORD345384 2019-11-25     11 summer\n",
            "ORD127439 2019-07-25      7 Spring\n",
            "ORD493849 2019-04-24      4 spring\n",
            "ORD495324 2019-07-10      7 Summer\n",
            "ORD462038 2019-07-10      7 autumn\n",
            "ORD434426 2019-06-14      6 spring\n",
            "ORD387883 2019-10-20     10 autumn\n"
          ]
        }
      ],
      "source": [
        "# Check date and season pairing\n",
        "# Extract the necessary columns and exclude NA values\n",
        "date_season = dirty_data[dirty_data[\"date\"].notna()][[\"order_id\", \"date\", \"season\"]].copy()\n",
        "\n",
        "# Standardise season name\n",
        "date_season[\"season_clean\"] = date_season[\"season\"].str.strip().str.lower()\n",
        "\n",
        "# Get the months from date column\n",
        "date_season[\"month\"] = date_season[\"date\"].dt.month\n",
        "\n",
        "# Mapping of months to seasons\n",
        "season_months = {\"summer\": [12, 1, 2],\n",
        "                 \"autumn\": [3, 4, 5],\n",
        "                 \"winter\": [6, 7, 8],\n",
        "                 \"spring\": [9, 10, 11]}\n",
        "\n",
        "# Valid season check\n",
        "def valid_season (row):\n",
        "  season = row[\"season_clean\"]\n",
        "  month = row[\"month\"]\n",
        "  if season in season_months:\n",
        "    return month in season_months[season]\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "# Apply valid season check to the months and season\n",
        "date_season[\"season_match\"] = date_season.apply(valid_season, axis=1)\n",
        "\n",
        "invalid_date_season = date_season[~date_season[\"season_match\"]]\n",
        "invalid_case = invalid_date_season[~invalid_date_season[\"season\"].str.match(r\"^[A-Z][a-z]+$\", na=False)]\n",
        "\n",
        "print(\"Number of mismatched date-season pairs:\", len(invalid_date_season))\n",
        "print(\"Number of seasons not capitalised correctly in date-season pairs:\", len(invalid_case))\n",
        "print(invalid_date_season[[\"order_id\", \"date\", \"month\", \"season\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JIwiB08cX1g",
        "outputId": "62f34c4e-87d5-46c6-df7a-0c261a5c0b46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "names     object\n",
            "lat      float64\n",
            "lon      float64\n",
            "dtype: object\n",
            "Number of mismatched distances: 43\n",
            " order_id nearest_warehouse_clean  customer_lat  customer_long        lat        lon  distance_to_nearest_warehouse  haversine_dist  dist_diff\n",
            "ORD418280               Nickolson    -37.822991     144.976257 -37.818595 144.969551                         1.9037        0.766301   1.137399\n",
            "ORD237879               Nickolson    -37.800113     144.935310 -37.818595 144.969551                         1.7391        3.647097   1.907997\n",
            "ORD020055                  Bakers    -37.817347     145.008734 -37.809996 144.995232                         0.6764        1.442062   0.765662\n",
            "ORD483341                Thompson    -37.820155     144.952118 -37.812673 144.947069                         0.7995        0.943856   0.144356\n",
            "ORD106152               Nickolson    -37.820522     144.982869 -37.818595 144.969551                         0.7663        1.190577   0.424277\n",
            "ORD052629               Nickolson    -37.821635     144.998632 -37.818595 144.969551                         1.3297        2.579471   1.249771\n",
            "ORD461915               Nickolson    -37.814020     144.949193 -37.818595 144.969551                         0.2395        1.861329   1.621829\n",
            "ORD069936                Thompson    -37.807010     144.965764 -37.812673 144.947069                         1.3319        1.760830   0.428930\n",
            "ORD177750                Thompson    -37.799394     144.959286 -37.812673 144.947069                         1.3601        1.827460   0.467360\n",
            "ORD452867                  Bakers    -37.802381     144.991831 -37.809996 144.995232                         0.1950        0.898913   0.703913\n",
            "ORD461426                  Bakers    -37.807495     144.947983 -37.809996 144.995232                         0.5820        4.164774   3.582774\n",
            "ORD393540                  Bakers    -37.800537     145.008953 -37.809996 144.995232                         1.2162        1.601575   0.385375\n",
            "ORD015774               Nickolson    -37.806332     144.959495 -37.818595 144.969551                         1.3010        1.626555   0.325555\n",
            "ORD135624                  Bakers    -37.804381     145.013385 -37.809996 144.995232                         1.9831        1.714587   0.268513\n",
            "ORD471922                  Bakers    -37.823627     145.007563 -37.809996 144.995232                         1.3422        1.865031   0.522831\n",
            "ORD385052                Thompson    -37.814853     144.937806 -37.812673 144.947069                         0.3711        0.849948   0.478848\n",
            "ORD307211               Nickolson    -37.810965     144.978213 -37.818595 144.969551                         0.5429        1.140909   0.598009\n",
            "ORD120949                  Bakers    -37.801549     144.962927 -37.809996 144.995232                         1.8651        2.992820   1.127720\n",
            "ORD227802                Thompson    -37.809084     144.955502 -37.812673 144.947069                         1.1817        0.842408   0.339292\n",
            "ORD216010                Thompson    -37.809813     144.988879 -37.812673 144.947069                         0.5591        3.690696   3.131596\n",
            "ORD138742                  Bakers    -37.805178     144.947622 -37.809996 144.995232                         0.8358        4.221461   3.385661\n",
            "ORD041333                Thompson    -37.815137     144.940339 -37.812673 144.947069                         0.7914        0.652338   0.139062\n",
            "ORD334316                Thompson    -37.824891     144.982106 -37.812673 144.947069                         1.3077        3.367832   2.060132\n",
            "ORD378423               Nickolson    -37.810399     144.972691 -37.818595 144.969551                         0.8424        0.953248   0.110848\n",
            "ORD081635                Thompson    -37.824700     144.984766 -37.812673 144.947069                         1.5006        3.575057   2.074457\n",
            "ORD321986               Nickolson    -37.820637     144.956867 -37.818595 144.969551                         0.8577        1.138328   0.280628\n",
            "ORD025929                  Bakers    -37.810684     144.959848 -37.809996 144.995232                         1.1455        3.112768   1.967268\n",
            "ORD205213               Nickolson    -37.815469     144.968083 -37.818595 144.969551                         1.5693        0.371129   1.198171\n",
            "ORD201338               Nickolson    -37.800090     144.962035 -37.818595 144.969551                         1.9221        2.163375   0.241275\n",
            "ORD436885               Nickolson    -37.802443     144.991522 -37.818595 144.969551                         0.9019        2.639363   1.737463\n",
            "ORD440634                  Bakers    -37.811592     145.003476 -37.809996 144.995232                         1.3297        0.746466   0.583234\n",
            "ORD224300               Nickolson    -37.807837     144.949431 -37.818595 144.969551                         0.5770        2.136543   1.559543\n",
            "ORD416698                Thompson    -37.818765     144.916487 -37.812673 144.947069                         1.2743        2.773467   1.499167\n",
            "ORD471229                Thompson    -37.821629     144.961412 -37.812673 144.947069                         0.7914        1.607719   0.816319\n",
            "ORD049973                  Bakers    -37.810492     144.985019 -37.809996 144.995232                         1.8431        0.899864   0.943236\n",
            "ORD164906                Thompson    -37.809659     144.964064 -37.812673 144.947069                         1.1056        1.531795   0.426195\n",
            "ORD118183                Thompson    -37.812290     144.990362 -37.812673 144.947069                         0.4986        3.807534   3.308934\n",
            "ORD005273               Nickolson    -37.811312     144.973178 -37.818595 144.969551                         1.0157        0.871168   0.144532\n",
            "ORD300512                Thompson    -37.816251     144.987746 -37.812673 144.947069                         0.9582        3.599247   2.641047\n",
            "ORD048269                  Bakers    -37.811024     145.005489 -37.809996 144.995232                         0.7983        0.909235   0.110935\n",
            "ORD175303                  Bakers    -37.821489     145.007448 -37.809996 144.995232                         1.9142        1.670561   0.243639\n",
            "ORD223207                Thompson    -37.819074     144.952082 -37.812673 144.947069                         0.9455        0.837815   0.107685\n",
            "ORD426908                  Bakers    -37.807431     144.934012 -37.809996 144.995232                         1.2880        5.391663   4.103663\n"
          ]
        }
      ],
      "source": [
        "# Check if distance_to_nearest_warehouse is correct using Haversine distance\n",
        "# Extract the necessary columns\n",
        "warehouse_dist = dirty_data[[\"order_id\", \"nearest_warehouse\", \"distance_to_nearest_warehouse\", \"customer_lat\", \"customer_long\"]].copy()\n",
        "\n",
        "# Standardise warehouses name\n",
        "warehouse_dist[\"nearest_warehouse_clean\"] = warehouse_dist[\"nearest_warehouse\"].str.strip().str.title()\n",
        "\n",
        "# Swap the invalid customer_lat and customer_long\n",
        "invalid_coords_tmp = warehouse_dist[\"customer_lat\"].between(-180, 180) & warehouse_dist[\"customer_long\"].between(-90, 90)\n",
        "warehouse_dist.loc[invalid_coords_tmp, [\"customer_lat\", \"customer_long\"]] = warehouse_dist.loc[invalid_coords_tmp, [\"customer_long\", \"customer_lat\"]].values\n",
        "\n",
        "# Check warehouse_data data types\n",
        "print(warehouse_data.dtypes)\n",
        "\n",
        "# Merge both datasets\n",
        "merge_warehouse_dist = warehouse_dist.merge(warehouse_data,\n",
        "                                            left_on=\"nearest_warehouse_clean\",\n",
        "                                            right_on=\"names\",\n",
        "                                            how=\"left\")\n",
        "\n",
        "# Apply Haversine distance function to the coordinates\n",
        "merge_warehouse_dist[\"haversine_dist\"] = merge_warehouse_dist.apply(lambda row:\n",
        "                                                                    haversine_dist(row[\"customer_lat\"],\n",
        "                                                                             row[\"customer_long\"],\n",
        "                                                                             row[\"lat\"],\n",
        "                                                                             row[\"lon\"]),\n",
        "                                                                    axis=1)\n",
        "\n",
        "# Compare the distances\n",
        "merge_warehouse_dist[\"dist_diff\"] = (merge_warehouse_dist[\"haversine_dist\"] - merge_warehouse_dist[\"distance_to_nearest_warehouse\"]).abs()\n",
        "\n",
        "invalid_distance = merge_warehouse_dist[merge_warehouse_dist[\"dist_diff\"] > 0.1]\n",
        "print(\"Number of mismatched distances:\", len(invalid_distance))\n",
        "print(invalid_distance[[\"order_id\", \"nearest_warehouse_clean\", \"customer_lat\", \"customer_long\", \"lat\", \"lon\", \"distance_to_nearest_warehouse\", \"haversine_dist\", \"dist_diff\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsHEvg4HNlgL",
        "outputId": "2281968b-43c6-428e-815f-88cd64ba80fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of invalid nearest warehouse: 20\n",
            " order_id nearest_warehouse_clean  distance_to_nearest_warehouse actual_nearest_warehouse  actual_nearest_distance  haversine_dist_Thompson  haversine_dist_Nickolson  haversine_dist_Bakers\n",
            "ORD237879               Nickolson                         1.7391                 Thompson                   1.7391                   1.7391                    3.6471                 5.3839\n",
            "ORD052629               Nickolson                         1.3297                   Bakers                   1.3297                   4.6427                    2.5795                 1.3297\n",
            "ORD461915               Nickolson                         0.2395                 Thompson                   0.2395                   0.2395                    1.8613                 4.0736\n",
            "ORD069936                Thompson                         1.3319                Nickolson                   1.3319                   1.7608                    1.3319                 2.6129\n",
            "ORD461426                  Bakers                         0.5820                 Thompson                   0.5820                   0.5820                    2.2637                 4.1648\n",
            "ORD015774               Nickolson                         1.3010                 Thompson                   1.3010                   1.3010                    1.6266                 3.1694\n",
            "ORD120949                  Bakers                         1.8651                 Thompson                   1.8651                   1.8651                    1.9849                 2.9928\n",
            "ORD216010                Thompson                         0.5591                   Bakers                   0.5591                   3.6907                    1.9608                 0.5591\n",
            "ORD138742                  Bakers                         0.8358                 Thompson                   0.8358                   0.8358                    2.4393                 4.2215\n",
            "ORD334316                Thompson                         1.3077                Nickolson                   1.3077                   3.3678                    1.3077                 2.0203\n",
            "ORD081635                Thompson                         1.5006                Nickolson                   1.5006                   3.5751                    1.5006                 1.8777\n",
            "ORD025929                  Bakers                         1.1455                 Thompson                   1.1455                   1.1455                    1.2262                 3.1128\n",
            "ORD201338               Nickolson                         1.9221                 Thompson                   1.9221                   1.9221                    2.1634                 3.1210\n",
            "ORD436885               Nickolson                         0.9019                   Bakers                   0.9019                   4.0721                    2.6394                 0.9019\n",
            "ORD224300               Nickolson                         0.5770                 Thompson                   0.5770                   0.5770                    2.1365                 4.0352\n",
            "ORD471229                Thompson                         0.7914                Nickolson                   0.7914                   1.6077                    0.7914                 3.2438\n",
            "ORD164906                Thompson                         1.1056                Nickolson                   1.1056                   1.5318                    1.1056                 2.7414\n",
            "ORD118183                Thompson                         0.4986                   Bakers                   0.4986                   3.8075                    1.9601                 0.4986\n",
            "ORD300512                Thompson                         0.9582                   Bakers                   0.9582                   3.5992                    1.6211                 0.9582\n",
            "ORD426908                  Bakers                         1.2880                 Thompson                   1.2880                   1.2880                    3.3634                 5.3917\n",
            "Number of incorrect nearest warehouse distance: 0\n"
          ]
        }
      ],
      "source": [
        "# Check if nearest_warehouse is correct using Haversine distance\n",
        "# Calculate the distance to all three warehouses\n",
        "for _, row in warehouse_data.iterrows():\n",
        "  wh = row[\"names\"]\n",
        "  lat = row[\"lat\"]\n",
        "  lon = row[\"lon\"]\n",
        "\n",
        "  merge_warehouse_dist[f\"haversine_dist_{wh}\"] = merge_warehouse_dist.apply(lambda row:\n",
        "                                                                    haversine_dist(row[\"customer_lat\"],\n",
        "                                                                             row[\"customer_long\"],\n",
        "                                                                             lat,\n",
        "                                                                             lon),\n",
        "                                                                  axis=1)\n",
        "\n",
        "# Get the nearest warehouse name\n",
        "distance_cols = [f\"haversine_dist_{wh}\" for wh in warehouse_data[\"names\"]]\n",
        "merge_warehouse_dist[distance_cols] = merge_warehouse_dist[distance_cols].apply(lambda x: np.around(x, 4))\n",
        "merge_warehouse_dist[\"actual_nearest_distance\"] = merge_warehouse_dist[distance_cols].min(axis=1)\n",
        "merge_warehouse_dist[\"actual_nearest_warehouse\"] = (merge_warehouse_dist[distance_cols].idxmin(axis=1).str.replace(\"haversine_dist_\", \"\"))\n",
        "\n",
        "# Check if the nearest_warehouse is correct\n",
        "merge_warehouse_dist[\"is_correct\"] = (merge_warehouse_dist[\"nearest_warehouse_clean\"] == merge_warehouse_dist[\"actual_nearest_warehouse\"])\n",
        "\n",
        "invalid_nearest_warehouse = merge_warehouse_dist[~merge_warehouse_dist[\"is_correct\"]]\n",
        "print(\"Number of invalid nearest warehouse:\", len(invalid_nearest_warehouse))\n",
        "print(invalid_nearest_warehouse[[\"order_id\", \"nearest_warehouse_clean\", \"distance_to_nearest_warehouse\", \"actual_nearest_warehouse\", \"actual_nearest_distance\", \"haversine_dist_Thompson\", \"haversine_dist_Nickolson\", \"haversine_dist_Bakers\"]].to_string(index=False))\n",
        "\n",
        "# Check if distance_to_nearest_warehouse is exactly the same as actual_nearest_distance\n",
        "distance_check = invalid_nearest_warehouse[\"distance_to_nearest_warehouse\"] == invalid_nearest_warehouse[\"actual_nearest_distance\"]\n",
        "print(\"Number of incorrect nearest warehouse distance:\", len(distance_check[~distance_check]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoCbDbbhvtgg",
        "outputId": "d95f6daf-9085-4f42-9c59-c47a8a1d4bd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|A|=20  |B|=20  |C|=43\n",
            "\n",
            "Exclusive to A: 7\n",
            "['ORD014442', 'ORD016571', 'ORD099672', 'ORD166717', 'ORD169718', 'ORD256861', 'ORD393258']\n",
            "\n",
            "Exclusive to B: 0\n",
            "[]\n",
            "\n",
            "Exclusive to C: 23\n",
            "['ORD005273', 'ORD020055', 'ORD041333', 'ORD048269', 'ORD049973', 'ORD106152', 'ORD135624', 'ORD175303', 'ORD177750', 'ORD205213', 'ORD223207', 'ORD227802', 'ORD307211', 'ORD321986', 'ORD378423', 'ORD385052', 'ORD393540', 'ORD416698', 'ORD418280', 'ORD440634', 'ORD452867', 'ORD471922', 'ORD483341']\n",
            "\n",
            "Overlap AB only: 0\n",
            "[]\n",
            "\n",
            "Overlap AC only: 0\n",
            "[]\n",
            "\n",
            "Overlap BC only: 7\n",
            "['ORD069936', 'ORD081635', 'ORD216010', 'ORD237879', 'ORD334316', 'ORD426908', 'ORD436885']\n",
            "\n",
            "Overlap ABC: 13\n",
            "['ORD015774', 'ORD025929', 'ORD052629', 'ORD118183', 'ORD120949', 'ORD138742', 'ORD164906', 'ORD201338', 'ORD224300', 'ORD300512', 'ORD461426', 'ORD461915', 'ORD471229']\n"
          ]
        }
      ],
      "source": [
        "# Check the overlapping order_id\n",
        "setA = set(invalid_warehouses[\"order_id\"]) # inconsistent nearest_warehouse naming\n",
        "setB = set(invalid_nearest_warehouse[\"order_id\"]) # incorrect nearest_warehouse\n",
        "setC = set(invalid_distance[\"order_id\"]) # incorrect distance_to_nearest_warehouse\n",
        "\n",
        "# Number of invalid data in A, B, and C\n",
        "print(f\"|A|={len(setA)}  |B|={len(setB)}  |C|={len(setC)}\")\n",
        "\n",
        "# Exclusive\n",
        "onlyA = setA - (setB | setC)\n",
        "onlyB = setB - (setA | setC)\n",
        "onlyC = setC - (setA | setB)\n",
        "\n",
        "print(\"\\nExclusive to A:\", len(onlyA))\n",
        "print(sorted(list(onlyA)))\n",
        "print(\"\\nExclusive to B:\", len(onlyB))\n",
        "print(sorted(list(onlyB)))\n",
        "print(\"\\nExclusive to C:\", len(onlyC))\n",
        "print(sorted(list(onlyC)))\n",
        "\n",
        "# Overlapping\n",
        "overlap_AB = (setA & setB) - setC\n",
        "overlap_AC = (setA & setC) - setB\n",
        "overlap_BC = (setB & setC) - setA\n",
        "overlap_ABC = setA & setB & setC\n",
        "print(\"\\nOverlap AB only:\", len(overlap_AB))\n",
        "print(sorted(list(overlap_AB)))\n",
        "print(\"\\nOverlap AC only:\", len(overlap_AC))\n",
        "print(sorted(list(overlap_AC)))\n",
        "print(\"\\nOverlap BC only:\", len(overlap_BC))\n",
        "print(sorted(list(overlap_BC)))\n",
        "print(\"\\nOverlap ABC:\", len(overlap_ABC))\n",
        "print(sorted(list(overlap_ABC)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U_I_EAEN50v",
        "outputId": "a739a0da-576d-433d-bf17-3e51bc4bf1c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of invalid sentiment labels 27\n",
            " order_id                                                                                                                                                                                                                                                      latest_customer_review  is_happy_customer  compound_score  happy_prediction  is_correct\n",
            "ORD216249                                                                                                          battery runs low fast the phone works fine, although the battery runs out fast and you have to charge it a lot .i like the phone but wish the battery didn't suck.              False          0.8052              True       False\n",
            "ORD412492                                                                                                                                                                                                                                      nice i don't see any problems with it.              False          0.6197              True       False\n",
            "ORD457652                                                                                                                                                                                                                                                            five stars great              False          0.6249              True       False\n",
            "ORD066764                                                                                                                               good phone. i love this phone. toshika is doing a great job. just to be tweaking the next model to have a faster ship and a higher roslution.              False          0.9042              True       False\n",
            "ORD352239                                                                                                                                                                                                                                    four stars my son like it so far so good              False          0.7629              True       False\n",
            "ORD268941                                                                                                                                          great phone i love it, the screen has a great quality and the battery get almost all day, stay charged fast and had a good camera.              False          0.9382              True       False\n",
            "ORD478343                                                                                                                                                                                                                             doesn't have support to sdcard great cell phone              False          0.4295              True       False\n",
            "ORD064373                                                                                                                                         perfect phone, fast shipping other than the packaging, you would think this phone was new! perfect phone, fast shipping, thank you.              False          0.8805              True       False\n",
            "ORD370767             note 8 - 5 stars received a note 8 from this seller in mint condition. not a scratch or dent anywhere. phone works perfectly. was a little nervous about buying a pre owned phone online but so glad i did. saved a lot of money and its practically brand new.              False          0.9116              True       False\n",
            "ORD252102 defective screen phone has black lines across screen. spoke with olivia which referred me to their repair place. i was informed that the screen would need to be replaced with a genuine screen for about $280. my bad for purchasing a used \"certified refurbished\" phone.               True         -0.7506             False       False\n",
            "ORD330702                                                                                                                                                                                                           for the price: amazing. the screen is just great. really fast to.              False          0.8360              True       False\n",
            "ORD408565                                                                                                                                                                                                                     five stars it arrived when promised and work very well.              False          0.5984              True       False\n",
            "ORD480194                                                                                                                                                                                                                                                              its good!              False          0.4926              True       False\n",
            "ORD494528                                                                                                                                                                                                                                                          five stars love it              False          0.6369              True       False\n",
            "ORD083198                                                   phone not so good the phone is nice but i can't use my t-moble data and i also wanted the locked phone witch is what i payed for but it was unlocked so i can't use wifi calling that's another reason i bought the phone               True         -0.5210             False       False\n",
            "ORD241933                                                                                                                                                                                                                                             one star a total waste of money               True         -0.4215             False       False\n",
            "ORD246197                                                                                                                                                                                                      but a good solid phone a little fat and heavy, but a good solid phone.              False          0.8885              True       False\n",
            "ORD208028                                                                                                                                          works great. saved about $300 from new to this refurbished works great. saved about $300 from new to this refurbished. looked new.              False          0.9300              True       False\n",
            "ORD251878                                                                                                                                                                                                                                    works great! fast shipping! works great!              False          0.8772              True       False\n",
            "ORD405488                                                                                                                                                                                four stars excellent phone but the cable does not last.. a better cable would gave been nice              False          0.4480              True       False\n",
            "ORD115461                                                                                                                                          ... what he had to do to make the customer happy awsome really kind did what he had to do to make the customer happy awsome person              False          0.9020              True       False\n",
            "ORD363854                                                                                                                                                                                                              tuve una duda y respondieron muy rpidamente. todo funciona ok              False          0.2960              True       False\n",
            "ORD435481                                                                                                                                                                                                                                              speaker could be better qualty              False          0.4404              True       False\n",
            "ORD256544                                                 great phone. get sim from sprint service store. great phone. came in great shape. don't try to get a sim by calling sprint. goto a sprint store with a service center.now that i have the sim. works great.love this phone.              False          0.9231              True       False\n",
            "ORD319183                                                                                                                                                                                                                        get it! great alcon. love how easy it was to set up.              False          0.9098              True       False\n",
            "ORD102139                                                                                                                                                                                                                                                        five stars excellent              False          0.5719              True       False\n",
            "ORD366292                                                                                                   no longer compatible. i received this phone yesterday. took it to the verizon corporate store today and was advised that this model is no longer compatible with verizon.               True         -0.5267             False       False\n"
          ]
        }
      ],
      "source": [
        "# Extract the necessary columns and replace missing values with empty string\n",
        "is_happy_check = dirty_data[[\"order_id\", \"is_happy_customer\", \"latest_customer_review\"]].copy()\n",
        "is_happy_check[\"latest_customer_review\"] = is_happy_check[\"latest_customer_review\"].fillna(\"\").astype(str)\n",
        "\n",
        "# Apply sentiment analysis to each row of latest_review_customer and return the compound_score but None if it is an empty string\n",
        "is_happy_check[\"compound_score\"] = is_happy_check[\"latest_customer_review\"].apply(lambda row: sia.polarity_scores(row)[\"compound\"]\n",
        "                                                                                  if row.strip() != \"\"\n",
        "                                                                                  else None)\n",
        "\n",
        "# Create a column to store True when compound_score is more than 0.05 or is an empty string\n",
        "is_happy_check[\"happy_prediction\"] = is_happy_check.apply(lambda row: True\n",
        "                                                          if row[\"latest_customer_review\"].strip() == \"\"\n",
        "                                                          else row[\"compound_score\"] >= 0.05,\n",
        "                                                          axis=1)\n",
        "\n",
        "# Check if is_happy_customer aligns with latest_review_customer\n",
        "is_happy_check[\"is_correct\"] = is_happy_check[\"happy_prediction\"] == is_happy_check[\"is_happy_customer\"]\n",
        "\n",
        "invalid_sentiment = is_happy_check[~is_happy_check[\"is_correct\"]]\n",
        "print(\"Number of invalid sentiment labels\", len(invalid_sentiment))\n",
        "print(invalid_sentiment[[\"order_id\", \"latest_customer_review\", \"is_happy_customer\", \"compound_score\", \"happy_prediction\", \"is_correct\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQnfRh3J7Fv9"
      },
      "source": [
        "#### 1.2.1.3 Dirty Data Fix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "W7wX74A9gmnb"
      },
      "outputs": [],
      "source": [
        "# Create a duplicate of dirty_data to clean\n",
        "clean_data = dirty_data.copy()\n",
        "\n",
        "# Create fix log\n",
        "fix_log = pd.DataFrame(columns=[\"order_id\", \"error_type\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsMqticyflF0",
        "outputId": "b8f3a359-e03d-45b9-dcad-0942b56ccdb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mismatched seasons: 27\n",
            "Fixed 27 rows.\n",
            " order_id       date season\n",
            "ORD209240 2019-02-07 Summer\n",
            "ORD419503 2019-09-21 Spring\n",
            "ORD277275 2019-12-26 Summer\n",
            "ORD123382 2019-01-06 Summer\n",
            "ORD209230 2019-09-03 Spring\n",
            "ORD132264 2019-10-14 Spring\n",
            "ORD192930 2019-08-30 Winter\n",
            "ORD172628 2019-03-30 Autumn\n",
            "ORD103002 2019-10-17 Spring\n",
            "ORD040501 2019-10-17 Spring\n",
            "ORD344249 2019-10-23 Spring\n",
            "ORD222038 2019-11-04 Spring\n",
            "ORD026633 2019-01-16 Summer\n",
            "ORD377228 2019-09-24 Spring\n",
            "ORD455600 2019-02-18 Summer\n",
            "ORD468030 2019-05-06 Autumn\n",
            "ORD478782 2019-07-26 Winter\n",
            "ORD363647 2019-12-01 Summer\n",
            "ORD345384 2019-11-25 Spring\n",
            "ORD127439 2019-07-25 Winter\n",
            "ORD493849 2019-04-24 Autumn\n",
            "ORD492808 2019-08-07 Winter\n",
            "ORD495324 2019-07-10 Winter\n",
            "ORD385926 2019-09-10 Spring\n",
            "ORD462038 2019-07-10 Winter\n",
            "ORD434426 2019-06-14 Winter\n",
            "ORD387883 2019-10-20 Spring\n"
          ]
        }
      ],
      "source": [
        "# Fix season and casing based on date\n",
        "# Filter out the unfixed data\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])]\n",
        "\n",
        "unfixed_data[\"date\"] = pd.to_datetime(unfixed_data[\"date\"], errors=\"coerce\")\n",
        "unfixed_data[\"month\"]= unfixed_data[\"date\"].dt.month\n",
        "\n",
        "season_map = {12: \"Summer\", 1: \"Summer\", 2: \"Summer\",\n",
        "              3: \"Autumn\", 4: \"Autumn\", 5: \"Autumn\",\n",
        "              6: \"Winter\", 7: \"Winter\", 8: \"Winter\",\n",
        "              9: \"Spring\", 10: \"Spring\", 11: \"Spring\"}\n",
        "\n",
        "unfixed_data[\"season_clean\"] = unfixed_data[\"month\"].map(season_map)\n",
        "\n",
        "unfixed_data[\"season_clean\"] = np.where(\n",
        "    unfixed_data[\"month\"].isna(),\n",
        "    unfixed_data[\"season\"],\n",
        "    unfixed_data[\"season_clean\"]\n",
        ")\n",
        "\n",
        "season_mismatch = (unfixed_data[\"month\"].notna() &\n",
        "                   (unfixed_data[\"season\"] != unfixed_data[\"season_clean\"]))\n",
        "print(\"Number of mismatched seasons:\", season_mismatch.sum())\n",
        "\n",
        "clean_data.loc[season_mismatch, \"season\"] = unfixed_data.loc[season_mismatch, \"season_clean\"]\n",
        "\n",
        "fixed_ids = unfixed_data.loc[season_mismatch, \"order_id\"]\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Incorrect season\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[unfixed_data.loc[season_mismatch].index, [\"order_id\", \"date\", \"season\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06icfMdpjQ0E",
        "outputId": "d89cc229-0e6f-4085-c5c8-85043bb7c20c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of missing dates: 27\n",
            "Fixed 27 rows.\n",
            " order_id       date season\n",
            "ORD164387 2019-01-15 Summer\n",
            "ORD066446 2019-07-15 Winter\n",
            "ORD312565 2019-01-15 Summer\n",
            "ORD181051 2019-01-15 Summer\n",
            "ORD046408 2019-10-15 Spring\n",
            "ORD219265 2019-07-15 Winter\n",
            "ORD006455 2019-10-15 Spring\n",
            "ORD084861 2019-07-15 Winter\n",
            "ORD438655 2019-01-15 Summer\n",
            "ORD234563 2019-10-15 Spring\n",
            "ORD199817 2019-01-15 Summer\n",
            "ORD113549 2019-04-15 Autumn\n",
            "ORD489756 2019-10-15 Spring\n",
            "ORD273300 2019-10-15 Spring\n",
            "ORD194653 2019-01-15 Summer\n",
            "ORD480775 2019-10-15 Spring\n",
            "ORD160619 2019-07-15 Winter\n",
            "ORD402436 2019-04-15 Autumn\n",
            "ORD311888 2019-04-15 Autumn\n",
            "ORD491911 2019-07-15 Winter\n",
            "ORD265708 2019-01-15 Summer\n",
            "ORD060082 2019-01-15 Summer\n",
            "ORD469475 2019-01-15 Summer\n",
            "ORD461231 2019-07-15 Winter\n",
            "ORD047863 2019-04-15 Autumn\n",
            "ORD499923 2019-10-15 Spring\n",
            "ORD036565 2019-10-15 Spring\n"
          ]
        }
      ],
      "source": [
        "# Fix date\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "\n",
        "date_map = {\n",
        "    \"Summer\": \"2019-01-15\",\n",
        "    \"Autumn\": \"2019-04-15\",\n",
        "    \"Winter\": \"2019-07-15\",\n",
        "    \"Spring\": \"2019-10-15\"\n",
        "}\n",
        "\n",
        "missing_date = unfixed_data[\"date\"].isna()\n",
        "print(\"Number of missing dates:\", missing_date.sum())\n",
        "\n",
        "valid_season = unfixed_data[\"season\"].isin(date_map)\n",
        "\n",
        "date_index = unfixed_data.index[missing_date & valid_season]\n",
        "\n",
        "correct_date = pd.to_datetime(unfixed_data.loc[date_index, \"season\"].map(date_map), errors=\"coerce\")\n",
        "\n",
        "clean_data.loc[date_index, \"date\"] = correct_date\n",
        "\n",
        "fixed_ids = unfixed_data.loc[date_index, \"order_id\"]\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Missing date\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[date_index, [\"order_id\", \"date\", \"season\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJhNodJGmP9I",
        "outputId": "bae1c68e-1021-412e-ec0f-8a7dc0b66529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of swapped coordinates: 27\n",
            "Fixed 27 rows.\n",
            " order_id  customer_lat  customer_long\n",
            "ORD091929    -37.815878     144.959364\n",
            "ORD299508    -37.823816     145.009445\n",
            "ORD074143    -37.819701     144.960234\n",
            "ORD392203    -37.812101     144.973944\n",
            "ORD208957    -37.810785     144.977354\n",
            "ORD090831    -37.797624     144.993262\n",
            "ORD062280    -37.816990     144.961790\n",
            "ORD155978    -37.824991     144.949411\n",
            "ORD493957    -37.801182     144.976899\n",
            "ORD083244    -37.818479     144.977813\n",
            "ORD373348    -37.793879     144.985178\n",
            "ORD055195    -37.806415     144.983469\n",
            "ORD125480    -37.810368     144.961303\n",
            "ORD285476    -37.802954     144.935968\n",
            "ORD349254    -37.805420     144.947587\n",
            "ORD048052    -37.801171     145.004517\n",
            "ORD479919    -37.815613     144.977507\n",
            "ORD326763    -37.805420     144.928230\n",
            "ORD442562    -37.820067     144.968618\n",
            "ORD063341    -37.827219     144.988143\n",
            "ORD012510    -37.799791     144.954950\n",
            "ORD070213    -37.801354     144.946328\n",
            "ORD481618    -37.816652     144.988204\n",
            "ORD202182    -37.809350     144.931580\n",
            "ORD396842    -37.809694     144.972599\n",
            "ORD130131    -37.796916     144.964657\n",
            "ORD201885    -37.813794     144.968469\n"
          ]
        }
      ],
      "source": [
        "# Fix customer_lat and customer_long\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "\n",
        "swapped_coords = (unfixed_data[\"customer_lat\"].between(-180, 180) &\n",
        "                  unfixed_data[\"customer_long\"].between(-90, 90))\n",
        "print(\"Number of swapped coordinates:\", swapped_coords.sum())\n",
        "\n",
        "swapped_coords_index = unfixed_data.index[swapped_coords]\n",
        "\n",
        "clean_data.loc[swapped_coords_index, [\"customer_lat\", \"customer_long\"]] = (clean_data.loc[swapped_coords_index, [\"customer_long\", \"customer_lat\"]].to_numpy())\n",
        "\n",
        "fixed_ids = clean_data.loc[swapped_coords_index, \"order_id\"].tolist()\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Swapped coordinates\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[swapped_coords_index, [\"order_id\", \"customer_lat\", \"customer_long\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XslGFsSolw2_",
        "outputId": "b37bbbc1-ab4d-4295-98ce-7f7d8f0d9bfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of incorrect nearest warehouse name: 20\n",
            "Fixed 20 rows.\n",
            " order_id nearest_warehouse\n",
            "ORD237879          Thompson\n",
            "ORD052629            Bakers\n",
            "ORD461915          Thompson\n",
            "ORD069936         Nickolson\n",
            "ORD461426          Thompson\n",
            "ORD015774          Thompson\n",
            "ORD120949          Thompson\n",
            "ORD216010            Bakers\n",
            "ORD138742          Thompson\n",
            "ORD334316         Nickolson\n",
            "ORD081635         Nickolson\n",
            "ORD025929          Thompson\n",
            "ORD201338          Thompson\n",
            "ORD436885            Bakers\n",
            "ORD224300          Thompson\n",
            "ORD471229         Nickolson\n",
            "ORD164906         Nickolson\n",
            "ORD118183            Bakers\n",
            "ORD300512            Bakers\n",
            "ORD426908          Thompson\n"
          ]
        }
      ],
      "source": [
        "# Fix nearest_warehouse\n",
        "# 1. Actual nearest warehouse\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "unfixed_index = unfixed_data.index\n",
        "\n",
        "ori_wh = merge_warehouse_dist.loc[unfixed_index, \"nearest_warehouse_clean\"].astype(str).str.strip()\n",
        "actual_wh = merge_warehouse_dist.loc[unfixed_index, \"actual_nearest_warehouse\"].astype(str).str.strip()\n",
        "\n",
        "incorrect_wh = (ori_wh != actual_wh)\n",
        "correct_dist = ((merge_warehouse_dist.loc[unfixed_index, \"distance_to_nearest_warehouse\"] -\n",
        "                 merge_warehouse_dist.loc[unfixed_index, \"actual_nearest_distance\"]).abs() <= 0)\n",
        "\n",
        "wh_fix = incorrect_wh & correct_dist\n",
        "incorrect_wh_index = merge_warehouse_dist.loc[unfixed_index].index[wh_fix]\n",
        "print(\"Number of incorrect nearest warehouse name:\", len(incorrect_wh_index))\n",
        "\n",
        "clean_data.loc[incorrect_wh_index, \"nearest_warehouse\"] = (merge_warehouse_dist.loc[incorrect_wh_index, \"actual_nearest_warehouse\"].values)\n",
        "\n",
        "fixed_ids = clean_data.loc[incorrect_wh_index, \"order_id\"].values\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Incorrect nearest_warehouse\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[incorrect_wh_index, [\"order_id\", \"nearest_warehouse\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQKjKRWDpWGr",
        "outputId": "c3ccbb86-13c5-4a4d-bdff-89207d8928b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of incorrect distance to nearest warehouse: 23\n",
            "Fixed 23 rows.\n",
            " order_id  distance_to_nearest_warehouse\n",
            "ORD418280                         0.7663\n",
            "ORD020055                         1.4421\n",
            "ORD483341                         0.9439\n",
            "ORD106152                         1.1906\n",
            "ORD177750                         1.8275\n",
            "ORD452867                         0.8989\n",
            "ORD393540                         1.6016\n",
            "ORD135624                         1.7146\n",
            "ORD471922                         1.8650\n",
            "ORD385052                         0.8499\n",
            "ORD307211                         1.1409\n",
            "ORD227802                         0.8424\n",
            "ORD041333                         0.6523\n",
            "ORD378423                         0.9532\n",
            "ORD321986                         1.1383\n",
            "ORD205213                         0.3711\n",
            "ORD440634                         0.7465\n",
            "ORD416698                         2.7735\n",
            "ORD049973                         0.8999\n",
            "ORD005273                         0.8712\n",
            "ORD048269                         0.9092\n",
            "ORD175303                         1.6706\n",
            "ORD223207                         0.8378\n"
          ]
        }
      ],
      "source": [
        "# Fix distance_to_nearest_warehouse\n",
        "# Haversine distance\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "unfixed_index = unfixed_data.index\n",
        "\n",
        "ori_wh = merge_warehouse_dist.loc[unfixed_index, \"nearest_warehouse_clean\"].astype(str).str.strip()\n",
        "actual_wh = merge_warehouse_dist.loc[unfixed_index, \"actual_nearest_warehouse\"].astype(str).str.strip()\n",
        "\n",
        "correct_wh = (ori_wh == actual_wh)\n",
        "\n",
        "actual_nearest_distance = np.around(merge_warehouse_dist.loc[unfixed_index, \"actual_nearest_distance\"].values, 4)\n",
        "\n",
        "ori_distance = merge_warehouse_dist.loc[unfixed_index, \"distance_to_nearest_warehouse\"].values\n",
        "mismatch_dist = np.abs(ori_distance - actual_nearest_distance) > 0.1\n",
        "\n",
        "dist_fix = correct_wh & mismatch_dist\n",
        "incorrect_dist_index = merge_warehouse_dist.loc[unfixed_index].index[dist_fix]\n",
        "print(\"Number of incorrect distance to nearest warehouse:\", len(incorrect_dist_index))\n",
        "\n",
        "clean_data.loc[incorrect_dist_index, \"distance_to_nearest_warehouse\"] = (merge_warehouse_dist.loc[incorrect_dist_index, \"actual_nearest_distance\"].values)\n",
        "\n",
        "fixed_ids = clean_data.loc[incorrect_dist_index, \"order_id\"].values\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Incorrect distance_to_nearest_warehouse\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[incorrect_dist_index, [\"order_id\", \"distance_to_nearest_warehouse\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsiXdwIMpWvG",
        "outputId": "75103a42-4f8f-4998-da8a-3a57b0aad9e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of invalid warehouse names: 7\n",
            "Fixed 7 rows.\n",
            " order_id nearest_warehouse\n",
            "ORD256861          Thompson\n",
            "ORD014442          Thompson\n",
            "ORD166717          Thompson\n",
            "ORD169718         Nickolson\n",
            "ORD393258          Thompson\n",
            "ORD016571         Nickolson\n",
            "ORD099672          Thompson\n"
          ]
        }
      ],
      "source": [
        "# Fix nearest_warehouse\n",
        "# 2. Naming inconsistency\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "\n",
        "valid_names = warehouse_data[\"names\"].str.strip().str.title()\n",
        "invalid_names = ~unfixed_data[\"nearest_warehouse\"].astype(str).str.strip().isin(valid_names)\n",
        "\n",
        "invalid_name_index = unfixed_data.index[invalid_names]\n",
        "print(\"Number of invalid warehouse names:\", len(invalid_name_index))\n",
        "\n",
        "clean_data.loc[invalid_name_index, \"nearest_warehouse\"] = (clean_data.loc[invalid_name_index, \"nearest_warehouse\"].astype(str).str.strip().str.title())\n",
        "\n",
        "fixed_ids = clean_data.loc[invalid_name_index, \"order_id\"].values\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Inconsistent nearest_warehouse naming\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[invalid_name_index, [\"order_id\", \"nearest_warehouse\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOJhdDpMTfGi",
        "outputId": "caddda8d-f8c0-4c7f-98cd-52999fc5b9a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alcon 10          8950.0\n",
            "Candle Inferno     430.0\n",
            "Lucent 330S       1230.0\n",
            "Olivia x460       1225.0\n",
            "Thunder line      2180.0\n",
            "Toshika 750       4320.0\n",
            "Universe Note     3450.0\n",
            "iAssist Line      2225.0\n",
            "iStream            150.0\n",
            "pearTV            6310.0\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Individual item price\n",
        "fixed_data = clean_data[clean_data[\"order_id\"].isin(set(fix_log[\"order_id\"]))].copy()\n",
        "\n",
        "cart_map = shopping_cart_check.set_index(\"order_id\")[\"shopping_cart_parsed\"]\n",
        "fixed_data[\"cart_parsed\"] = fixed_data[\"order_id\"].map(cart_map)\n",
        "\n",
        "all_items = [item for cart in fixed_data[\"cart_parsed\"] for (item, qty) in cart]\n",
        "item_names = pd.Series(all_items).value_counts().index.tolist()\n",
        "\n",
        "index = {n: i for i, n in enumerate(item_names)}\n",
        "K = len(item_names)\n",
        "\n",
        "rows, targets = [], []\n",
        "for _, r in fixed_data.iterrows():\n",
        "    v = np.zeros(K)\n",
        "    for (name, qty) in r[\"cart_parsed\"]:\n",
        "        if name in index:\n",
        "            v[index[name]] += float(qty)\n",
        "            rows.append(v)\n",
        "            targets.append(float(r[\"order_price\"]))\n",
        "\n",
        "A = np.vstack(rows)\n",
        "b = np.array(targets, dtype=float)\n",
        "\n",
        "unit_prices, *_ = np.linalg.lstsq(A, b, rcond=None)\n",
        "price_map = pd.Series(unit_prices, index=item_names).round(2)\n",
        "\n",
        "print(price_map.sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnDWJJO1otKi",
        "outputId": "02178ec6-d427-4076-ae47-87d2f7aeaa1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows mismatch order: 81\n",
            " order_id                                                                        shopping_cart  order_price  expected_order_price  price_diff  price_match  order_total  expected_order_total  total_diff  total_match\n",
            "ORD012542                                            [('Thunder line', 1), ('Toshika 750', 2)]         6740               10820.0      4080.0        False      9809.79               9809.79        0.00         True\n",
            "ORD136268                                               [('Alcon 10', 2), ('iAssist Line', 2)]         2600               22350.0     19750.0        False     21331.40              21331.40        0.00         True\n",
            "ORD396615                              [('Olivia x460', 1), ('Lucent 330S', 1), ('pearTV', 2)]        14010               15075.0      1065.0        False     15151.80              15151.80        0.00         True\n",
            "ORD038061                               [('Candle Inferno', 2), ('pearTV', 1), ('iStream', 1)]         8920                7320.0      1600.0        False      7644.46               6284.46     1360.00        False\n",
            "ORD276861    [('Toshika 750', 2), ('Alcon 10', 1), ('Candle Inferno', 1), ('Thunder line', 2)]        19820               22380.0      2560.0        False     16885.78              16885.78        0.00         True\n",
            "ORD159650                                            [('Lucent 330S', 1), ('iAssist Line', 1)]         3455                3455.0         0.0         True     31975.46               3028.94    28946.52        False\n",
            "ORD105180                                                [('Universe Note', 2), ('pearTV', 1)]        13210               13210.0         0.0         True     10700.35              11957.17     1256.82        False\n",
            "ORD157781                                                 [('iStream', 2), ('Olivia x460', 2)]         3310                2750.0       560.0        False      3216.20               2684.20      532.00        False\n",
            "ORD390068                      [('Lucent 330S', 2), ('Candle Inferno', 1), ('Toshika 750', 2)]        11530               11530.0         0.0         True     20131.65              11024.52     9107.13        False\n",
            "ORD135183             [('pearTV', 2), ('Olivia x460', 2), ('Alcon 10', 1), ('Lucent 330S', 1)]        26200               25250.0       950.0        False     23659.85              22804.85      855.00        False\n",
            "ORD098805   [('iAssist Line', 2), ('Candle Inferno', 1), ('Thunder line', 1), ('Alcon 10', 1)]        16010               16010.0         0.0         True      7850.39              13718.93     5868.54        False\n",
            "ORD108147                                                [('Universe Note', 2), ('pearTV', 2)]         7760               19520.0     11760.0        False      7438.22              18610.22    11172.00        False\n",
            "ORD097415     [('Olivia x460', 2), ('Candle Inferno', 1), ('Alcon 10', 2), ('Lucent 330S', 1)]        13485               22010.0      8525.0        False     19876.99              19876.99        0.00         True\n",
            "ORD292260            [('Lucent 330S', 2), ('Toshika 750', 2), ('iStream', 1), ('Alcon 10', 2)]        33590               29150.0      4440.0        False     31975.46              27757.46     4218.00        False\n",
            "ORD286146                                           [('Toshika 750', 1), ('Universe Note', 2)]         7330               11220.0      3890.0        False      7414.65              11304.65     3890.00        False\n",
            "ORD371831                        [('Thunder line', 2), ('Toshika 750', 1), ('Olivia x460', 1)]         9905                9905.0         0.0         True     16666.90               7534.92     9131.98        False\n",
            "ORD115991                                           [('Universe Note', 1), ('Toshika 750', 2)]        12090               12090.0         0.0         True      2222.91               9139.41     6916.50        False\n",
            "ORD460642                     [('iAssist Line', 1), ('Lucent 330S', 1), ('Candle Inferno', 2)]         4315                4315.0         0.0         True     15196.80               3745.31    11451.49        False\n",
            "ORD258960                            [('Olivia x460', 2), ('pearTV', 1), ('Universe Note', 2)]        31110               15660.0     15450.0        False     28103.56              14198.56    13905.00        False\n",
            "ORD489080                          [('iAssist Line', 1), ('Candle Inferno', 2), ('pearTV', 1)]        16120                9395.0      6725.0        False     15382.43               8993.68     6388.75        False\n",
            "ORD282385        [('Alcon 10', 1), ('Olivia x460', 1), ('Lucent 330S', 1), ('Toshika 750', 2)]        31110               20045.0     11065.0        False     18133.08              18133.08        0.00         True\n",
            "ORD063030                                               [('Thunder line', 2), ('Alcon 10', 2)]        18760               22260.0      3500.0        False     14135.75              16760.75     2625.00        False\n",
            "ORD368942                       [('Universe Note', 1), ('Lucent 330S', 1), ('Olivia x460', 2)]        15970                7130.0      8840.0        False      6849.09               6849.09        0.00         True\n",
            "ORD035025                       [('Thunder line', 1), ('Olivia x460', 1), ('iAssist Line', 2)]        12940                7855.0      5085.0        False     13012.65               7927.65     5085.00        False\n",
            "ORD181929         [('Candle Inferno', 2), ('iStream', 2), ('Lucent 330S', 2), ('Alcon 10', 2)]        23485               21520.0      1965.0        False     20512.70              20512.70        0.00         True\n",
            "ORD377946                    [('Universe Note', 2), ('Candle Inferno', 2), ('Olivia x460', 2)]         3750               10210.0      6460.0        False      7748.37               7748.37        0.00         True\n",
            "ORD293767                                               [('Thunder line', 1), ('Alcon 10', 1)]        11130               11130.0         0.0         True      9867.52              11196.19     1328.67        False\n",
            "ORD070614                                          [('Universe Note', 1), ('Thunder line', 1)]        11130                5630.0      5500.0        False     10647.86               5422.86     5225.00        False\n",
            "ORD479953         [('iAssist Line', 2), ('Olivia x460', 2), ('Toshika 750', 2), ('pearTV', 2)]        23880               28160.0      4280.0        False     23948.99              28228.99     4280.00        False\n",
            "ORD431838                                [('Alcon 10', 1), ('Olivia x460', 2), ('iStream', 2)]         5630               11700.0      6070.0        False     10587.72              10587.72        0.00         True\n",
            "ORD228598                          [('Olivia x460', 1), ('Universe Note', 2), ('Alcon 10', 1)]        10350               17075.0      6725.0        False      9936.07              16324.82     6388.75        False\n",
            "ORD189464   [('iAssist Line', 2), ('Olivia x460', 1), ('Thunder line', 1), ('Lucent 330S', 2)]         8770               10315.0      1545.0        False      9355.17               9355.17        0.00         True\n",
            "ORD330007                                               [('Alcon 10', 2), ('iAssist Line', 2)]        22350               22350.0         0.0         True      9465.23              22399.00    12933.77        False\n",
            "ORD221277                                [('Olivia x460', 1), ('iStream', 1), ('Alcon 10', 2)]        11060               19275.0      8215.0        False     14513.65              14513.65        0.00         True\n",
            "ORD319958                           [('Universe Note', 2), ('Thunder line', 2), ('pearTV', 2)]        23880               23880.0         0.0         True     20605.07              22753.58     2148.51        False\n",
            "ORD294135                                          [('Candle Inferno', 2), ('Toshika 750', 2)]        33590                9500.0     24090.0        False      9103.68               9103.68        0.00         True\n",
            "ORD225804    [('Lucent 330S', 2), ('iAssist Line', 1), ('Olivia x460', 2), ('Toshika 750', 2)]        13700               15775.0      2075.0        False     10355.63              11911.88     1556.25        False\n",
            "ORD007117                             [('iStream', 2), ('Olivia x460', 1), ('Toshika 750', 2)]         4315               10165.0      5850.0        False     10270.49              10270.49        0.00         True\n",
            "ORD390858                                            [('Thunder line', 2), ('Toshika 750', 2)]        15540               13000.0      2540.0        False     14063.10              11777.10     2286.00        False\n",
            "ORD354953                                                [('iStream', 1), ('Thunder line', 1)]         9810                2330.0      7480.0        False      2174.84               2174.84        0.00         True\n",
            "ORD069151    [('Candle Inferno', 2), ('Alcon 10', 2), ('Olivia x460', 2), ('iAssist Line', 2)]        25660               25660.0         0.0         True     25220.77              24451.51      769.26        False\n",
            "ORD455667          [('Alcon 10', 1), ('iStream', 2), ('Toshika 750', 1), ('Universe Note', 2)]         1375               20470.0     19095.0        False     18494.63              18494.63        0.00         True\n",
            "ORD203938      [('Thunder line', 2), ('iStream', 1), ('Lucent 330S', 2), ('Universe Note', 2)]         5630               13870.0      8240.0        False     11850.81              11850.81        0.00         True\n",
            "ORD394587                      [('Lucent 330S', 1), ('Toshika 750', 2), ('Candle Inferno', 2)]         9650               10730.0      1080.0        False      9234.85              10260.85     1026.00        False\n",
            "ORD120331                                            [('Olivia x460', 2), ('iAssist Line', 1)]         6770                4675.0      2095.0        False      6511.35               4521.10     1990.25        False\n",
            "ORD185952                                             [('Toshika 750', 1), ('Lucent 330S', 2)]         6780                6780.0         0.0         True      2799.92               6195.12     3395.20        False\n",
            "ORD384172                          [('Olivia x460', 2), ('Alcon 10', 1), ('Universe Note', 1)]         8125               14850.0      6725.0        False      7378.09              13430.59     6052.50        False\n",
            "ORD052541                              [('Candle Inferno', 2), ('pearTV', 1), ('Alcon 10', 2)]        25070               25070.0         0.0         True     16144.61              23890.43     7745.82        False\n",
            "ORD267973                             [('iAssist Line', 2), ('Toshika 750', 2), ('pearTV', 2)]        22690               25710.0      3020.0        False     21946.02              21946.02        0.00         True\n",
            "ORD372162                                               [('Alcon 10', 2), ('Thunder line', 2)]        22260               22260.0         0.0         True     14926.57              16792.73     1866.16        False\n",
            "ORD198059                         [('iAssist Line', 2), ('Candle Inferno', 2), ('iStream', 1)]        14260                5460.0      8800.0        False     10804.93               4204.93     6600.00        False\n",
            "ORD200848                         [('Alcon 10', 1), ('Thunder line', 2), ('Universe Note', 2)]        20210               20210.0         0.0         True      7758.14              20273.34    12515.20        False\n",
            "ORD488026                                                     [('pearTV', 1), ('Alcon 10', 1)]        11175               15260.0      4085.0        False     10120.63              13797.13     3676.50        False\n",
            "ORD353697        [('Lucent 330S', 1), ('Toshika 750', 1), ('iAssist Line', 2), ('iStream', 1)]         9280               10150.0       870.0        False      7026.26               7678.76      652.50        False\n",
            "ORD486573         [('Alcon 10', 1), ('Candle Inferno', 1), ('iAssist Line', 1), ('pearTV', 2)]        15970               24225.0      8255.0        False     21901.20              21901.20        0.00         True\n",
            "ORD405673            [('iAssist Line', 1), ('iStream', 1), ('pearTV', 1), ('Thunder line', 1)]        10865               10865.0         0.0         True     30179.11               8228.93    21950.18        False\n",
            "ORD455855                                 [('pearTV', 2), ('Alcon 10', 2), ('Lucent 330S', 1)]        31750               31750.0         0.0         True     13887.67              31816.16    17928.49        False\n",
            "ORD411297                                             [('Toshika 750', 1), ('Lucent 330S', 1)]         3455                5550.0      2095.0        False      4824.72               4824.72        0.00         True\n",
            "ORD470970     [('Thunder line', 1), ('iStream', 1), ('Candle Inferno', 1), ('Toshika 750', 2)]        23880               11400.0     12480.0        False     11464.83              11464.83        0.00         True\n",
            "ORD022783 [('iAssist Line', 1), ('Thunder line', 2), ('Universe Note', 2), ('Toshika 750', 1)]        17805               17805.0         0.0         True     15349.24              13428.47     1920.77        False\n",
            "ORD363756          [('iStream', 1), ('Thunder line', 2), ('Alcon 10', 1), ('iAssist Line', 1)]        15230               15685.0       455.0        False     14999.68              14999.68        0.00         True\n",
            "ORD113541                           [('Candle Inferno', 1), ('pearTV', 1), ('Lucent 330S', 1)]        10295                7970.0      2325.0        False      7645.73               7645.73        0.00         True\n",
            "ORD153936                         [('Candle Inferno', 2), ('Toshika 750', 1), ('Alcon 10', 1)]        14130               14130.0         0.0         True     31816.16              12820.31    18995.85        False\n",
            "ORD291184          [('Olivia x460', 1), ('Candle Inferno', 2), ('Alcon 10', 1), ('pearTV', 2)]         4405               23655.0     19250.0        False     22536.94              22536.94        0.00         True\n",
            "ORD177246         [('Olivia x460', 2), ('pearTV', 2), ('Thunder line', 2), ('Lucent 330S', 1)]        22880               20660.0      2220.0        False     21819.48              19710.48     2109.00        False\n",
            "ORD421787                             [('Toshika 750', 2), ('pearTV', 2), ('iAssist Line', 1)]        23485               23485.0         0.0         True      7886.26              23579.36    15693.10        False\n",
            "ORD435347                            [('Olivia x460', 2), ('Alcon 10', 1), ('Lucent 330S', 2)]         8360               13860.0      5500.0        False      7618.09              12568.09     4950.00        False\n",
            "ORD199032      [('Toshika 750', 1), ('Universe Note', 2), ('iAssist Line', 2), ('iStream', 2)]        11175               15970.0      4795.0        False     15250.28              15250.28        0.00         True\n",
            "ORD034671        [('iStream', 1), ('Olivia x460', 2), ('Thunder line', 1), ('Lucent 330S', 2)]         7240                7240.0         0.0         True      6165.18               5499.14      666.04        False\n",
            "ORD421351                          [('iStream', 2), ('Candle Inferno', 2), ('Lucent 330S', 1)]         2390                2390.0         0.0         True      5997.22               2243.80     3753.42        False\n",
            "ORD187672             [('pearTV', 2), ('Olivia x460', 1), ('iAssist Line', 1), ('iStream', 2)]        16370               16370.0         0.0         True     11519.52              15613.34     4093.82        False\n",
            "ORD400044                    [('Candle Inferno', 2), ('Olivia x460', 1), ('Universe Note', 1)]        22575                5535.0     17040.0        False     22673.84               5633.84    17040.00        False\n",
            "ORD208094                                          [('Thunder line', 2), ('Universe Note', 1)]         6900                7810.0       910.0        False      7094.06               7094.06        0.00         True\n",
            "ORD172961 [('iAssist Line', 2), ('Olivia x460', 2), ('Candle Inferno', 1), ('Lucent 330S', 2)]        12810                9790.0      3020.0        False      9708.53               7443.53     2265.00        False\n",
            "ORD153201                         [('Universe Note', 1), ('pearTV', 2), ('Candle Inferno', 2)]        16930               16930.0         0.0         True     21946.02              14470.76     7475.26        False\n",
            "ORD496180     [('Universe Note', 2), ('Lucent 330S', 1), ('Alcon 10', 1), ('Thunder line', 1)]        19260               19260.0         0.0         True     18950.30              14523.18     4427.12        False\n",
            "ORD314406                                         [('iAssist Line', 1), ('Candle Inferno', 1)]         8535                2655.0      5880.0        False      7758.14               2466.14     5292.00        False\n",
            "ORD230545                     [('Universe Note', 2), ('Thunder line', 2), ('iAssist Line', 1)]        13485               13485.0         0.0         True      5499.14              12202.81     6703.67        False\n",
            "ORD023631 [('Candle Inferno', 2), ('Toshika 750', 1), ('Olivia x460', 2), ('Thunder line', 2)]         6960               11990.0      5030.0        False     11493.52              11493.52        0.00         True\n",
            "ORD000718                                           [('iAssist Line', 2), ('Thunder line', 2)]        22260                8810.0     13450.0        False     18988.47               7555.97    11432.50        False\n",
            "ORD089659                                          [('Lucent 330S', 1), ('Candle Inferno', 2)]         2090                2090.0         0.0         True      9508.96               2051.85     7457.11        False\n"
          ]
        }
      ],
      "source": [
        "# Check shopping_cart, order_price, order_total is correct\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(set(fix_log[\"order_id\"]))].copy()\n",
        "unfixed_data[\"cart_parsed\"] = unfixed_data[\"order_id\"].map(shopping_cart_check.set_index(\"order_id\")[\"shopping_cart_parsed\"])\n",
        "\n",
        "def order_price_check(cart):\n",
        "  '''\n",
        "  Calculates the order_price based on individual item price\n",
        "  '''\n",
        "  return round(sum(price_map[item]*float(qty) for item, qty in cart), 2)\n",
        "\n",
        "# Compute expected values based on individual item price\n",
        "unfixed_data[\"expected_order_price\"] = unfixed_data[\"cart_parsed\"].apply(order_price_check)\n",
        "unfixed_data[\"expected_order_total\"] = (unfixed_data[\"expected_order_price\"] * (1 - unfixed_data[\"coupon_discount\"]/100) + unfixed_data[\"delivery_charges\"]).round(2)\n",
        "\n",
        "# Compute the difference for order_price and order_total\n",
        "unfixed_data[\"price_diff\"] = (unfixed_data[\"expected_order_price\"] - unfixed_data[\"order_price\"]).abs().round(2)\n",
        "unfixed_data[\"total_diff\"] = (unfixed_data[\"expected_order_total\"] - unfixed_data[\"order_total\"]).abs().round(2)\n",
        "\n",
        "# Compare the expected order_price and order_total with the record and check if it matches\n",
        "unfixed_data[\"price_match\"] = unfixed_data[\"price_diff\"] <= 0\n",
        "unfixed_data[\"total_match\"] = unfixed_data[\"total_diff\"] <= 0\n",
        "\n",
        "# Mismatched rows\n",
        "mismatch_order = unfixed_data[(~unfixed_data[\"price_match\"]) | (~unfixed_data[\"total_match\"])].copy()\n",
        "\n",
        "# Output\n",
        "output = [\"order_id\", \"shopping_cart\", \"order_price\",\n",
        "        \"expected_order_price\", \"price_diff\", \"price_match\",\n",
        "        \"order_total\", \"expected_order_total\", \"total_diff\", \"total_match\"]\n",
        "\n",
        "print(f\"Rows mismatch order:\", len(mismatch_order))\n",
        "print(mismatch_order[output].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92sgoLA9ER-g",
        "outputId": "3bb241b5-cdde-49a9-cfd9-bb3ef0b05847"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     error category  rows\n",
            "  order_price_error    27\n",
            "shopping_cart_error    27\n",
            "  order_total_error    27\n",
            "Detected shopping_cart error:\n",
            " order_id                                                                     error_details\n",
            "ORD038061   {'incorrect item': 'Candle Inferno', 'correct item': 'Lucent 330S', 'qty': 2.0}\n",
            "ORD157781       {'incorrect item': 'iStream', 'correct item': 'Candle Inferno', 'qty': 2.0}\n",
            "ORD135183     {'incorrect item': 'Lucent 330S', 'correct item': 'Thunder line', 'qty': 1.0}\n",
            "ORD108147        {'incorrect item': 'pearTV', 'correct item': 'Candle Inferno', 'qty': 2.0}\n",
            "ORD292260    {'incorrect item': 'Lucent 330S', 'correct item': 'Universe Note', 'qty': 2.0}\n",
            "ORD286146   {'incorrect item': 'Toshika 750', 'correct item': 'Candle Inferno', 'qty': 1.0}\n",
            "ORD258960         {'incorrect item': 'Olivia x460', 'correct item': 'Alcon 10', 'qty': 2.0}\n",
            "ORD489080        {'incorrect item': 'iAssist Line', 'correct item': 'Alcon 10', 'qty': 1.0}\n",
            "ORD063030  {'incorrect item': 'Thunder line', 'correct item': 'Candle Inferno', 'qty': 2.0}\n",
            "ORD035025           {'incorrect item': 'Olivia x460', 'correct item': 'pearTV', 'qty': 1.0}\n",
            "ORD070614       {'incorrect item': 'Universe Note', 'correct item': 'Alcon 10', 'qty': 1.0}\n",
            "ORD479953     {'incorrect item': 'Toshika 750', 'correct item': 'Thunder line', 'qty': 2.0}\n",
            "ORD228598        {'incorrect item': 'Alcon 10', 'correct item': 'iAssist Line', 'qty': 1.0}\n",
            "ORD225804         {'incorrect item': 'iAssist Line', 'correct item': 'iStream', 'qty': 1.0}\n",
            "ORD390858   {'incorrect item': 'Thunder line', 'correct item': 'Universe Note', 'qty': 2.0}\n",
            "ORD394587          {'incorrect item': 'Lucent 330S', 'correct item': 'iStream', 'qty': 1.0}\n",
            "ORD120331     {'incorrect item': 'iAssist Line', 'correct item': 'Toshika 750', 'qty': 1.0}\n",
            "ORD384172        {'incorrect item': 'Alcon 10', 'correct item': 'iAssist Line', 'qty': 1.0}\n",
            "ORD198059             {'incorrect item': 'iStream', 'correct item': 'Alcon 10', 'qty': 1.0}\n",
            "ORD488026          {'incorrect item': 'pearTV', 'correct item': 'iAssist Line', 'qty': 1.0}\n",
            "ORD353697    {'incorrect item': 'Toshika 750', 'correct item': 'Universe Note', 'qty': 1.0}\n",
            "ORD177246    {'incorrect item': 'Lucent 330S', 'correct item': 'Universe Note', 'qty': 1.0}\n",
            "ORD435347       {'incorrect item': 'Alcon 10', 'correct item': 'Universe Note', 'qty': 1.0}\n",
            "ORD400044      {'incorrect item': 'Candle Inferno', 'correct item': 'Alcon 10', 'qty': 2.0}\n",
            "ORD172961 {'incorrect item': 'Candle Inferno', 'correct item': 'Universe Note', 'qty': 1.0}\n",
            "ORD314406        {'incorrect item': 'Candle Inferno', 'correct item': 'pearTV', 'qty': 1.0}\n",
            "ORD000718        {'incorrect item': 'iAssist Line', 'correct item': 'Alcon 10', 'qty': 2.0}\n"
          ]
        }
      ],
      "source": [
        "# Classify the mismatched rows into shopping_cart error, order_price error, order_total error\n",
        "# List out the item names\n",
        "item_names = list(price_map.index)\n",
        "\n",
        "# Function to check if row will be correct by swapping item\n",
        "def swap_item(row):\n",
        "  '''\n",
        "  Check if order_price and order_total can be correct by swapping between each item in the cart\n",
        "  '''\n",
        "  cart = row[\"cart_parsed\"]\n",
        "\n",
        "  price_diff = float(row[\"order_price\"]  - row[\"expected_order_price\"])\n",
        "  total_diff = float(row[\"order_total\"]  - row[\"expected_order_total\"])\n",
        "  discount  = 1 - float(row[\"coupon_discount\"])/100\n",
        "\n",
        "  for old_name, qty in cart:\n",
        "    old_p = float(price_map[old_name])\n",
        "    for new_name in item_names:\n",
        "      if new_name == old_name:\n",
        "        continue\n",
        "      new_p = float(price_map[new_name])\n",
        "      delta_price = (new_p - old_p) * float(qty)\n",
        "      if (round(abs(delta_price - price_diff), 2)<= 0 and\n",
        "          round(abs(delta_price * discount - total_diff), 2) <= 0):\n",
        "        return True, {\"incorrect item\": old_name, \"correct item\": new_name, \"qty\": float(qty)}\n",
        "  return False, {}\n",
        "\n",
        "# Classify the mismatched rows to their error type\n",
        "error_cat = []\n",
        "error_details = []\n",
        "\n",
        "for _, r in mismatch_order.iterrows():\n",
        "    # shopping_cart error\n",
        "    can_swap, swap_info = swap_item(r)\n",
        "    if can_swap:\n",
        "        error_cat.append(\"shopping_cart_error\")\n",
        "        error_details.append(swap_info)\n",
        "        continue\n",
        "\n",
        "    # order_price error\n",
        "    incorrect_price = abs(float(r[\"expected_order_price\"] - r[\"order_price\"])) > 0\n",
        "    correct_total = abs(float(r[\"expected_order_total\"] - r[\"order_total\"])) <= 0\n",
        "    if incorrect_price and correct_total:\n",
        "        error_cat.append(\"order_price_error\")\n",
        "        error_details.append({})\n",
        "        continue\n",
        "\n",
        "    # order_total error\n",
        "    correct_price  = not incorrect_price\n",
        "    incorrect_total = not correct_total\n",
        "    if correct_price and incorrect_total:\n",
        "        error_cat.append(\"order_total_error\")\n",
        "        error_details.append({})\n",
        "        continue\n",
        "\n",
        "    # unknown error\n",
        "    error_cat.append(\"unknown_error\")\n",
        "    error_details.append({})\n",
        "\n",
        "# Create new columns to store error_type and error_details\n",
        "mismatch_order[\"error_cat\"] = error_cat\n",
        "mismatch_order[\"error_details\"]  = error_details\n",
        "\n",
        "# Summary for error type\n",
        "error_summary = (mismatch_order[\"error_cat\"]\n",
        "                 .value_counts()\n",
        "                 .rename_axis(\"error category\")\n",
        "                 .reset_index(name=\"rows\"))\n",
        "\n",
        "# Print out the order_id and error_details for shopping_cart error\n",
        "print(error_summary.to_string(index=False))\n",
        "print(\"Detected shopping_cart error:\")\n",
        "print(mismatch_order.loc[mismatch_order[\"error_cat\"]==\"shopping_cart_error\", [\"order_id\",\"error_details\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQTYCH-a5sJ4",
        "outputId": "677d2cb8-46b3-4e9a-9ce2-430af3b8f62c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixed 27 rows.\n",
            " order_id                                                                       shopping_cart\n",
            "ORD038061                                 [('Lucent 330S', 2), ('pearTV', 1), ('iStream', 1)]\n",
            "ORD157781                                         [('Candle Inferno', 2), ('Olivia x460', 2)]\n",
            "ORD135183           [('pearTV', 2), ('Olivia x460', 2), ('Alcon 10', 1), ('Thunder line', 1)]\n",
            "ORD108147                                       [('Universe Note', 2), ('Candle Inferno', 2)]\n",
            "ORD292260         [('Universe Note', 2), ('Toshika 750', 2), ('iStream', 1), ('Alcon 10', 2)]\n",
            "ORD286146                                       [('Candle Inferno', 1), ('Universe Note', 2)]\n",
            "ORD258960                              [('Alcon 10', 2), ('pearTV', 1), ('Universe Note', 2)]\n",
            "ORD489080                             [('Alcon 10', 1), ('Candle Inferno', 2), ('pearTV', 1)]\n",
            "ORD063030                                            [('Candle Inferno', 2), ('Alcon 10', 2)]\n",
            "ORD035025                           [('Thunder line', 1), ('pearTV', 1), ('iAssist Line', 2)]\n",
            "ORD070614                                              [('Alcon 10', 1), ('Thunder line', 1)]\n",
            "ORD479953       [('iAssist Line', 2), ('Olivia x460', 2), ('Thunder line', 2), ('pearTV', 2)]\n",
            "ORD228598                     [('Olivia x460', 1), ('Universe Note', 2), ('iAssist Line', 1)]\n",
            "ORD225804        [('Lucent 330S', 2), ('iStream', 1), ('Olivia x460', 2), ('Toshika 750', 2)]\n",
            "ORD390858                                          [('Universe Note', 2), ('Toshika 750', 2)]\n",
            "ORD394587                         [('iStream', 1), ('Toshika 750', 2), ('Candle Inferno', 2)]\n",
            "ORD120331                                            [('Olivia x460', 2), ('Toshika 750', 1)]\n",
            "ORD384172                     [('Olivia x460', 2), ('iAssist Line', 1), ('Universe Note', 1)]\n",
            "ORD198059                       [('iAssist Line', 2), ('Candle Inferno', 2), ('Alcon 10', 1)]\n",
            "ORD488026                                              [('iAssist Line', 1), ('Alcon 10', 1)]\n",
            "ORD353697     [('Lucent 330S', 1), ('Universe Note', 1), ('iAssist Line', 2), ('iStream', 1)]\n",
            "ORD177246      [('Olivia x460', 2), ('pearTV', 2), ('Thunder line', 2), ('Universe Note', 1)]\n",
            "ORD435347                      [('Olivia x460', 2), ('Universe Note', 1), ('Lucent 330S', 2)]\n",
            "ORD400044                         [('Alcon 10', 2), ('Olivia x460', 1), ('Universe Note', 1)]\n",
            "ORD172961 [('iAssist Line', 2), ('Olivia x460', 2), ('Universe Note', 1), ('Lucent 330S', 2)]\n",
            "ORD314406                                                [('iAssist Line', 1), ('pearTV', 1)]\n",
            "ORD000718                                              [('Alcon 10', 2), ('Thunder line', 2)]\n"
          ]
        }
      ],
      "source": [
        "# Fix shopping_cart error\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "unfixed_index = unfixed_data.index\n",
        "\n",
        "cart_error = (mismatch_order[\"error_cat\"] == \"shopping_cart_error\")\n",
        "cart_error_rows = mismatch_order.loc[cart_error, [\"order_id\", \"error_details\"]].copy()\n",
        "\n",
        "cart_error_swap = dict(zip(cart_error_rows[\"order_id\"], cart_error_rows[\"error_details\"]))\n",
        "\n",
        "def swap_shopping_cart(cart_list, old_name, new_name, qty):\n",
        "  new_list = []\n",
        "  swapped = False\n",
        "  for name, q in cart_list:\n",
        "    if (not swapped) and (name == old_name) and (float(q) == float(qty)):\n",
        "      new_list.append((new_name, q))\n",
        "      swapped = True\n",
        "    else:\n",
        "      new_list.append((name, q))\n",
        "  if not swapped:\n",
        "    for i, (n, q) in enumerate(new_list):\n",
        "      if n == old_name:\n",
        "        new_list[i] == (new_name , q)\n",
        "        swapped = True\n",
        "        break\n",
        "  return new_list, swapped\n",
        "\n",
        "cart_fix = clean_data[\"order_id\"].isin(cart_error_swap.keys())\n",
        "cart_index = clean_data.index[cart_fix & clean_data.index.isin(unfixed_index)]\n",
        "\n",
        "for i in cart_index:\n",
        "  old_id = clean_data.at[i, \"order_id\"]\n",
        "  info = cart_error_swap[old_id]\n",
        "  old_name = info[\"incorrect item\"]\n",
        "  new_name = info[\"correct item\"]\n",
        "  qty = info[\"qty\"]\n",
        "\n",
        "  raw = clean_data.at[i, \"shopping_cart\"]\n",
        "\n",
        "  cart_list = list(ast.literal_eval(raw))\n",
        "\n",
        "  new_cart, did_swap = swap_shopping_cart(cart_list, old_name, new_name, qty)\n",
        "  if did_swap:\n",
        "    clean_data.at[i, \"shopping_cart\"] = repr(new_cart)\n",
        "\n",
        "fixed_ids = clean_data.loc[cart_index, \"order_id\"].values\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Incorrect shopping_cart\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[cart_index, [\"order_id\", \"shopping_cart\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpIvRqbMl3w6",
        "outputId": "21d6a159-8e9d-49d8-d9ab-101f08b93137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixed 27 rows.\n",
            " order_id  order_price\n",
            "ORD012542        10820\n",
            "ORD136268        22350\n",
            "ORD396615        15075\n",
            "ORD276861        22380\n",
            "ORD097415        22010\n",
            "ORD282385        20045\n",
            "ORD368942         7130\n",
            "ORD181929        21520\n",
            "ORD377946        10210\n",
            "ORD431838        11700\n",
            "ORD189464        10315\n",
            "ORD221277        19275\n",
            "ORD294135         9500\n",
            "ORD007117        10165\n",
            "ORD354953         2330\n",
            "ORD455667        20470\n",
            "ORD203938        13870\n",
            "ORD267973        25710\n",
            "ORD486573        24225\n",
            "ORD411297         5550\n",
            "ORD470970        11400\n",
            "ORD363756        15685\n",
            "ORD113541         7970\n",
            "ORD291184        23655\n",
            "ORD199032        15970\n",
            "ORD208094         7810\n",
            "ORD023631        11990\n"
          ]
        }
      ],
      "source": [
        "# Fix order_price\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "\n",
        "price_error = (mismatch_order[\"error_cat\"] == \"order_price_error\")\n",
        "price_error_rows = set(mismatch_order.loc[price_error, \"order_id\"])\n",
        "\n",
        "price_error_unfixed = mismatch_order.loc[mismatch_order[\"order_id\"].isin(price_error_rows), [\"order_id\", \"expected_order_price\"]]\n",
        "expected_price_map = dict(zip(price_error_unfixed[\"order_id\"], price_error_unfixed[\"expected_order_price\"]))\n",
        "\n",
        "price_fix = clean_data[\"order_id\"].isin(expected_price_map.keys())\n",
        "price_index = clean_data.index[price_fix]\n",
        "\n",
        "clean_data.loc[price_index, \"order_price\"] = (clean_data.loc[price_index, \"order_id\"].map(expected_price_map))\n",
        "\n",
        "fixed_ids = clean_data.loc[price_index, \"order_id\"].values\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Incorrect order_price\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[price_index, [\"order_id\", \"order_price\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caoo2RDUvsVl",
        "outputId": "3309b971-0f6c-460c-df10-97d99e35018c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixed 27 rows.\n",
            " order_id  order_total\n",
            "ORD159650      3028.94\n",
            "ORD105180     11957.17\n",
            "ORD390068     11024.52\n",
            "ORD098805     13718.93\n",
            "ORD371831      7534.92\n",
            "ORD115991      9139.41\n",
            "ORD460642      3745.31\n",
            "ORD293767     11196.19\n",
            "ORD330007     22399.00\n",
            "ORD319958     22753.58\n",
            "ORD069151     24451.51\n",
            "ORD185952      6195.12\n",
            "ORD052541     23890.43\n",
            "ORD372162     16792.73\n",
            "ORD200848     20273.34\n",
            "ORD405673      8228.93\n",
            "ORD455855     31816.16\n",
            "ORD022783     13428.47\n",
            "ORD153936     12820.31\n",
            "ORD421787     23579.36\n",
            "ORD034671      5499.14\n",
            "ORD421351      2243.80\n",
            "ORD187672     15613.34\n",
            "ORD153201     14470.76\n",
            "ORD496180     14523.18\n",
            "ORD230545     12202.81\n",
            "ORD089659      2051.85\n"
          ]
        }
      ],
      "source": [
        "# Fix order_total\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "\n",
        "total_error = (mismatch_order[\"error_cat\"] == \"order_total_error\")\n",
        "total_error_rows = set(mismatch_order.loc[total_error, \"order_id\"])\n",
        "\n",
        "total_error_unfixed = mismatch_order.loc[mismatch_order[\"order_id\"].isin(total_error_rows), [\"order_id\", \"expected_order_total\"]]\n",
        "expected_total_map = dict(zip(total_error_unfixed[\"order_id\"], total_error_unfixed[\"expected_order_total\"]))\n",
        "\n",
        "total_fix = clean_data[\"order_id\"].isin(expected_total_map.keys())\n",
        "total_index = clean_data.index[total_fix]\n",
        "\n",
        "clean_data.loc[total_index, \"order_total\"] = (clean_data.loc[total_index, \"order_id\"].map(expected_total_map))\n",
        "\n",
        "fixed_ids = clean_data.loc[total_index, \"order_id\"].values\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Incorrect order_total\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[total_index, [\"order_id\", \"order_total\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_HzL6kKrTWS",
        "outputId": "dbf32b86-dc2c-46f6-b437-13321f500f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixed 27 rows.\n",
            " order_id  is_happy_customer\n",
            "ORD216249               True\n",
            "ORD412492               True\n",
            "ORD457652               True\n",
            "ORD066764               True\n",
            "ORD352239               True\n",
            "ORD268941               True\n",
            "ORD478343               True\n",
            "ORD064373               True\n",
            "ORD370767               True\n",
            "ORD252102              False\n",
            "ORD330702               True\n",
            "ORD408565               True\n",
            "ORD480194               True\n",
            "ORD494528               True\n",
            "ORD083198              False\n",
            "ORD241933              False\n",
            "ORD246197               True\n",
            "ORD208028               True\n",
            "ORD251878               True\n",
            "ORD405488               True\n",
            "ORD115461               True\n",
            "ORD363854               True\n",
            "ORD435481               True\n",
            "ORD256544               True\n",
            "ORD319183               True\n",
            "ORD102139               True\n",
            "ORD366292              False\n"
          ]
        }
      ],
      "source": [
        "# Fix is_happy_customer\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "unfixed_index = unfixed_data.index\n",
        "\n",
        "incorrect_happy_rows = is_happy_check.loc[~is_happy_check[\"is_correct\"], [\"order_id\", \"happy_prediction\"]]\n",
        "\n",
        "incorrect_happy_id = incorrect_happy_rows[\"order_id\"]\n",
        "\n",
        "happy_index = clean_data.index[clean_data[\"order_id\"].isin(incorrect_happy_id) & clean_data.index.isin(unfixed_index)]\n",
        "\n",
        "happy_target = clean_data.loc[happy_index, \"order_id\"]\n",
        "happy_fix = (is_happy_check.set_index(\"order_id\").reindex(happy_target)[\"happy_prediction\"].values)\n",
        "\n",
        "clean_data.loc[happy_index, \"is_happy_customer\"] = happy_fix\n",
        "\n",
        "fixed_ids = clean_data.loc[happy_index, \"order_id\"].values\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Incorrect is_happy_customer\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[happy_index, [\"order_id\", \"is_happy_customer\"]].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "w8a3dzM9LgpG"
      },
      "outputs": [],
      "source": [
        "# # Check if is_expedited_delivery is correct with linear model\n",
        "\n",
        "# # Plot a boxplot for distribution\n",
        "# sns.boxplot(data=expedited_check,\n",
        "#             x=\"is_expedited_delivery\",\n",
        "#             y=\"delivery_charges\",\n",
        "#             hue=\"season_clean\")\n",
        "\n",
        "# # Run linear model to check the R2 score\n",
        "# cols = [\"is_expedited_delivery\", \"delivery_charges\", \"season\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9KONMBH_yeb"
      },
      "source": [
        "1.2.2 Outlier Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-kODGF__0R_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Outliers using robust z-score ===\n",
            "      order_id  delivery_charges  predicted_delivery_charge   residual\n",
            "17   ORD089831           144.450                  96.864118  47.585882\n",
            "28   ORD322216            71.475                  49.605252  21.869748\n",
            "93   ORD276933            39.570                  76.640083 -37.070083\n",
            "98   ORD142753            39.010                  73.782575 -34.772575\n",
            "104  ORD317663            73.815                  51.904774  21.910226\n",
            "109  ORD233575           119.955                  80.004734  39.950266\n",
            "123  ORD099918            39.790                  80.272405 -40.482405\n",
            "131  ORD171684           102.555                  72.340548  30.214452\n",
            "137  ORD272158            33.335                  64.123499 -30.788499\n",
            "143  ORD414922           143.385                  97.169650  46.215350\n",
            "145  ORD482557           164.775                 112.698279  52.076721\n",
            "167  ORD141312           126.705                  88.620992  38.084008\n",
            "168  ORD109768            26.515                  51.759332 -25.244332\n",
            "193  ORD204921            40.450                  80.686767 -40.236767\n",
            "194  ORD318956           193.875                 145.804701  48.070299\n",
            "207  ORD285918            52.185                 106.343889 -54.158889\n",
            "230  ORD161175            23.140                  46.134896 -22.994896\n",
            "252  ORD181666           167.445                 114.997928  52.447072\n",
            "273  ORD429584            51.875                 102.527430 -50.652430\n",
            "280  ORD113739            54.345                 111.406370 -57.061370\n",
            "296  ORD340379            97.710                  62.725451  34.984549\n",
            "307  ORD388515            39.155                  76.413738 -37.258738\n",
            "324  ORD005998           118.220                 126.103088  -7.883088\n",
            "347  ORD395285            34.030                  66.694396 -32.664396\n",
            "348  ORD449112           147.105                  95.825847  51.279153\n",
            "349  ORD104172            78.300                  55.545522  22.754478\n",
            "381  ORD242690            92.145                  62.212574  29.932426\n",
            "411  ORD087709            38.375                  75.930990 -37.555990\n",
            "431  ORD287879            52.485                 110.647749 -58.162749\n",
            "448  ORD212231            31.870                  63.796444 -31.926444\n",
            "489  ORD325671           136.380                  95.360743  41.019257\n",
            "Removed 31 outliers (robust-based), remaining: 469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_23856\\2421997356.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['is_expedited_delivery'] = X['is_expedited_delivery'].astype(int)\n",
            "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_23856\\2421997356.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['is_happy_customer'] = X['is_happy_customer'].astype(int)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# --- Make a backup of outlier dataframe ---\n",
        "df = outlier_data.copy()\n",
        "\n",
        "# --- Step 1: Prepare features ---\n",
        "X = df[['distance_to_nearest_warehouse', 'is_expedited_delivery', 'is_happy_customer', 'season']]\n",
        "y = df['delivery_charges']\n",
        "\n",
        "# Convert boolean to integer\n",
        "X['is_expedited_delivery'] = X['is_expedited_delivery'].astype(int)\n",
        "X['is_happy_customer'] = X['is_happy_customer'].astype(int)\n",
        "\n",
        "# One-hot encode season (drop first to avoid multicollinearity)\n",
        "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
        "season_encoded = encoder.fit_transform(X[['season']])\n",
        "season_encoded_df = pd.DataFrame(season_encoded, columns=encoder.get_feature_names_out(['season']))\n",
        "\n",
        "# Combine base features and season dummies\n",
        "X_base = X.drop(columns=['season']).reset_index(drop=True)\n",
        "X_encoded = pd.concat([X_base, season_encoded_df], axis=1)\n",
        "\n",
        "# --- Step 2: Add interaction terms between season and numeric predictors ---\n",
        "for season_col in season_encoded_df.columns:\n",
        "    for feature in ['distance_to_nearest_warehouse', 'is_expedited_delivery', 'is_happy_customer']:\n",
        "        interaction_name = f\"{feature}_x_{season_col}\"\n",
        "        X_encoded[interaction_name] = X_base[feature] * season_encoded_df[season_col]\n",
        "\n",
        "# --- Step 3: Fit linear model ---\n",
        "model = LinearRegression()\n",
        "model.fit(X_encoded, y)\n",
        "\n",
        "# --- Step 4: Compute predictions and residuals ---\n",
        "df['predicted_delivery_charge'] = model.predict(X_encoded)\n",
        "df['residual'] = df['delivery_charges'] - df['predicted_delivery_charge']\n",
        "\n",
        "# --- Step 5: Robust Z-score (Median + MAD) of residuals ---\n",
        "median_resid = df['residual'].median()\n",
        "mad_resid = np.median(np.abs(df['residual'] - median_resid))\n",
        "robust_z = 0.6745 * (df['residual'] - median_resid) / mad_resid\n",
        "\n",
        "outlier_robust_mask = np.abs(robust_z) > 3.5   # Common robust z-score threshold\n",
        "outliers_robust = df[outlier_robust_mask]\n",
        "\n",
        "print(\"\\n=== Outliers using robust z-score ===\")\n",
        "print(outliers_robust[['order_id', 'delivery_charges', 'predicted_delivery_charge', 'residual',]])\n",
        "\n",
        "# --- Step 6: Filter outliers ---\n",
        "filtered_robust = df[~outlier_robust_mask].reset_index(drop=True)\n",
        "\n",
        "print(f\"Removed {outliers_robust.shape[0]} outliers (robust-based), remaining: {filtered_robust.shape[0]}\")\n",
        "filtered_robust.to_csv('Group_035_outlier_data_solution.csv', index=False, na_rep=\"NaN\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBtmtL9G503B"
      },
      "source": [
        "1.2.3 Missing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFJC5J6z566q",
        "outputId": "2c228ac7-55b0-48d3-c76a-90baaed4e2cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "order_id                          0\n",
            "customer_id                       0\n",
            "date                              0\n",
            "nearest_warehouse                55\n",
            "shopping_cart                     0\n",
            "order_price                      15\n",
            "delivery_charges                 40\n",
            "customer_lat                      0\n",
            "customer_long                     0\n",
            "coupon_discount                   0\n",
            "order_total                      15\n",
            "season                            0\n",
            "is_expedited_delivery             0\n",
            "distance_to_nearest_warehouse    31\n",
            "latest_customer_review            0\n",
            "is_happy_customer                40\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Show how much missing data there is\n",
        "print(missing_data.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l49DmevR5_2H"
      },
      "outputs": [],
      "source": [
        "# # Build catalog of items and their respective prices\n",
        "# import ast\n",
        "# import numpy as np\n",
        "\n",
        "\n",
        "# # Collect unique items\n",
        "# all_items = sorted({item for cart in missing_data['parsed_cart'] for item, _ in cart})\n",
        "# item_index = {item: i for i, item in enumerate(all_items)}\n",
        "\n",
        "# # Build system of equations A x = b\n",
        "# rows, b = [], []\n",
        "# for _, row in missing_data.iterrows():\n",
        "#     if pd.notna(row['order_price']) and row['parsed_cart']:\n",
        "#         vec = np.zeros(len(all_items))\n",
        "#         for item, qty in row['parsed_cart']:\n",
        "#             vec[item_index[item]] += qty\n",
        "#         rows.append(vec)\n",
        "#         b.append(row['order_price'])\n",
        "\n",
        "# A = np.vstack(rows)\n",
        "# b = np.array(b)\n",
        "\n",
        "# # Solve least squares for unit prices\n",
        "# x, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
        "\n",
        "# # Round to 2 decimals for catalog - prices should not have more than 1 cent precision\n",
        "# x = np.round(x, 2)\n",
        "\n",
        "# # Build catalog\n",
        "# catalog = {item: price for item, price in zip(all_items, x)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9KlXaox6AzN"
      },
      "outputs": [],
      "source": [
        "# Impute missing data\n",
        "# Parse shopping_cart into list of tuples\n",
        "def parse_cart(cart_str):\n",
        "    if pd.isna(cart_str):\n",
        "        return []\n",
        "    try:\n",
        "        return ast.literal_eval(cart_str)\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "missing_data['parsed_cart'] = missing_data['shopping_cart'].apply(parse_cart)\n",
        "# --- Imputation logic ---\n",
        "# We determine the values to impute from the columns from which they are dependent on.\n",
        "# This is imputation by rule calculation, and is definitively correct assuming the relationships and the other columns are correct.\n",
        "def impute_row(row, warehouses, price_map):\n",
        "    # --- Impute nearest_warehouse ---\n",
        "    if pd.isna(row['nearest_warehouse']) and pd.notna(row['customer_lat']) and pd.notna(row['customer_long']):\n",
        "        distances = warehouses.apply(\n",
        "            lambda wh: haversine_dist(row['customer_lat'], row['customer_long'], wh['lat'], wh['lon']), axis=1\n",
        "        )\n",
        "        nearest_idx = distances.idxmin()\n",
        "        row['nearest_warehouse'] = warehouses.loc[nearest_idx, 'names']\n",
        "        row['distance_to_nearest_warehouse'] = distances.min()\n",
        "\n",
        "    # --- Impute order_price ---\n",
        "    if pd.isna(row['order_price']):\n",
        "        if pd.notna(row['order_total']) and pd.notna(row['delivery_charges']) and pd.notna(row['coupon_discount']):\n",
        "            denom = (100 - row['coupon_discount']) / 100\n",
        "            if denom != 0:\n",
        "                row['order_price'] = (row['order_total'] - row['delivery_charges']) / denom\n",
        "        elif pd.isna(row['order_total']) and row['parsed_cart']:  # fallback to catalog\n",
        "            if row['parsed_cart']:\n",
        "                items, qtys = zip(*row['parsed_cart'])\n",
        "                prices = price_map.reindex(items).fillna(0).values\n",
        "                row['order_price'] = np.dot(prices, qtys)\n",
        "\n",
        "    # --- Impute delivery_charges ---\n",
        "    if pd.isna(row['delivery_charges']):\n",
        "        if pd.notna(row['order_total']) and pd.notna(row['order_price']) and pd.notna(row['coupon_discount']):\n",
        "            denom = (100 - row['coupon_discount']) / 100\n",
        "            row['delivery_charges'] = row['order_total'] - row['order_price'] * denom\n",
        "\n",
        "    # --- Impute order_total ---\n",
        "    if pd.isna(row['order_total']):\n",
        "        if pd.notna(row['order_price']) and pd.notna(row['coupon_discount']) and pd.notna(row['delivery_charges']):\n",
        "            denom = (100 - row['coupon_discount']) / 100\n",
        "            row['order_total'] = row['order_price'] * denom + row['delivery_charges']\n",
        "\n",
        "    # --- Impute distance_to_nearest_warehouse ---\n",
        "    if pd.isna(row['distance_to_nearest_warehouse']):\n",
        "        if pd.notna(row['nearest_warehouse']) and pd.notna(row['customer_lat']) and pd.notna(row['customer_long']):\n",
        "            wh = warehouses.loc[warehouses['names'] == row['nearest_warehouse']].iloc[0]\n",
        "            row['distance_to_nearest_warehouse'] = haversine_dist(row['customer_lat'], row['customer_long'], wh['lat'], wh['lon'])\n",
        "\n",
        "    # --- Impute is_happy_customer from sentiment---\n",
        "    if pd.isna(row['is_happy_customer']) and pd.notna(row['latest_customer_review']):\n",
        "        sentiment = sia.polarity_scores(str(row['latest_customer_review']))\n",
        "        row['is_happy_customer'] = sentiment['compound'] >= 0.05\n",
        "\n",
        "    return row\n",
        "\n",
        "# Apply\n",
        "missing_data_imputed = missing_data.apply(lambda r: impute_row(r, warehouse_data, price_map), axis=1)\n",
        "missing_data_imputed.to_csv('Group_035_missing_data_solution.csv', index=False, na_rep=\"NaN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# price_map\n",
        "# # Individual item price\n",
        "# fixed_data = clean_data[clean_data[\"order_id\"].isin(set(fix_log[\"order_id\"]))].copy()\n",
        "\n",
        "# cart_map = shopping_cart_check.set_index(\"order_id\")[\"shopping_cart_parsed\"]\n",
        "# fixed_data[\"cart_parsed\"] = fixed_data[\"order_id\"].map(cart_map)\n",
        "\n",
        "# all_items = [item for cart in fixed_data[\"cart_parsed\"] for (item, qty) in cart]\n",
        "# item_names = pd.Series(all_items).value_counts().index.tolist()\n",
        "\n",
        "# index = {n: i for i, n in enumerate(item_names)}\n",
        "# K = len(item_names)\n",
        "\n",
        "# rows, targets = [], []\n",
        "# for _, r in fixed_data.iterrows():\n",
        "#     v = np.zeros(K)\n",
        "#     for (name, qty) in r[\"cart_parsed\"]:\n",
        "#         if name in index:\n",
        "#             v[index[name]] += float(qty)\n",
        "#             rows.append(v)\n",
        "#             targets.append(float(r[\"order_price\"]))\n",
        "\n",
        "# A = np.vstack(rows)\n",
        "# b = np.array(targets, dtype=float)\n",
        "\n",
        "# unit_prices, *_ = np.linalg.lstsq(A, b, rcond=None)\n",
        "# price_map = pd.Series(unit_prices, index=item_names).round(2)\n",
        "\n",
        "# print(price_map.sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44jrpEWx6Gd7",
        "outputId": "d45d330b-f76f-4916-f24c-8dda740cbee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No missing data remaining\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Verify imputation caught all missing data\n",
        "if sum(missing_data_imputed.isna().sum()) == 0:\n",
        "    print(\"No missing data remaining\\n\")\n",
        "else:\n",
        "    print(missing_data_imputed.isna().sum())\n",
        "    rows_with_nulls = missing_data_imputed[missing_data_imputed.isnull().any(axis=1)]\n",
        "    print(rows_with_nulls)\n",
        "\n",
        "# print(\"Catalog item price:\")\n",
        "# for item in catalog:\n",
        "#     print(f\"{item} price: {catalog[item]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX8mr0HdXJJq"
      },
      "source": [
        "#### 1.1.3 Documentation\n",
        "1. Date: There are 27 columns with NA values, which accounts for 5.4% of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGWrSRbTXrVf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
