{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JY6ZwHgw8C-a"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# base = \"/content/drive/MyDrive/FIT5196Assignment2/\" # for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u4k1Nb-39jM5"
   },
   "outputs": [],
   "source": [
    "# begin here if running locally\n",
    "\n",
    "# for local drive\n",
    "base = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "warehouses = pd.read_csv(base + 'warehouses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knnTQ100A0dl"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dirty_data = pd.read_csv(base + 'Group_035_dirty_data.csv')\n",
    "print(dirty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r7kPAHhdBARv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                          0\n",
      "customer_id                       0\n",
      "date                              0\n",
      "nearest_warehouse                55\n",
      "shopping_cart                     0\n",
      "order_price                      15\n",
      "delivery_charges                 40\n",
      "customer_lat                      0\n",
      "customer_long                     0\n",
      "coupon_discount                   0\n",
      "order_total                      15\n",
      "season                            0\n",
      "is_expedited_delivery             0\n",
      "distance_to_nearest_warehouse    31\n",
      "latest_customer_review            0\n",
      "is_happy_customer                40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "missing_data = pd.read_csv(base + 'Group_035_missing_data.csv')\n",
    "print(missing_data.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# Parse shopping_cart into list of tuples\n",
    "def parse_cart(cart_str):\n",
    "    if pd.isna(cart_str):\n",
    "        return []\n",
    "    try:\n",
    "        return ast.literal_eval(cart_str)\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "missing_data['parsed_cart'] = missing_data['shopping_cart'].apply(parse_cart)\n",
    "\n",
    "# Collect unique items\n",
    "all_items = sorted({item for cart in missing_data['parsed_cart'] for item, _ in cart})\n",
    "item_index = {item: i for i, item in enumerate(all_items)}\n",
    "\n",
    "# Build system of equations A x = b\n",
    "rows, b = [], []\n",
    "for _, row in missing_data.iterrows():\n",
    "    if pd.notna(row['order_price']) and row['parsed_cart']:\n",
    "        vec = np.zeros(len(all_items))\n",
    "        for item, qty in row['parsed_cart']:\n",
    "            vec[item_index[item]] += qty\n",
    "        rows.append(vec)\n",
    "        b.append(row['order_price'])\n",
    "\n",
    "A = np.vstack(rows)\n",
    "b = np.array(b)\n",
    "\n",
    "# Solve least squares for unit prices\n",
    "x, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "\n",
    "# Round to 2 decimals for catalog\n",
    "x = np.round(x, 2)\n",
    "\n",
    "# Build catalog\n",
    "catalog = {item: price for item, price in zip(all_items, x)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# --- Haversine helper ---\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6378  # Earth radius in KM\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "# --- Prepare Sentiment analyzer ---\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# --- Imputation logic ---\n",
    "def impute_row(row, warehouses, catalog):\n",
    "    # --- Impute nearest_warehouse ---\n",
    "    if pd.isna(row['nearest_warehouse']) and pd.notna(row['customer_lat']) and pd.notna(row['customer_long']):\n",
    "        distances = warehouses.apply(\n",
    "            lambda wh: haversine(row['customer_lat'], row['customer_long'], wh['lat'], wh['lon']), axis=1\n",
    "        )\n",
    "        nearest_idx = distances.idxmin()\n",
    "        row['nearest_warehouse'] = warehouses.loc[nearest_idx, 'names']\n",
    "        row['distance_to_nearest_warehouse'] = distances.min()\n",
    "\n",
    "    # --- Impute order_price ---\n",
    "    if pd.isna(row['order_price']):\n",
    "        if pd.notna(row['order_total']) and pd.notna(row['delivery_charges']) and pd.notna(row['coupon_discount']):\n",
    "            denom = (100 - row['coupon_discount']) / 100\n",
    "            if denom != 0:\n",
    "                row['order_price'] = (row['order_total'] - row['delivery_charges']) / denom\n",
    "        elif pd.isna(row['order_total']) and row['parsed_cart']:  # fallback to catalog\n",
    "            row['order_price'] = sum(catalog.get(item, 0) * qty for item, qty in row['parsed_cart'])\n",
    "\n",
    "    # --- Impute delivery_charges ---\n",
    "    if pd.isna(row['delivery_charges']):\n",
    "        if pd.notna(row['order_total']) and pd.notna(row['order_price']) and pd.notna(row['coupon_discount']):\n",
    "            denom = (100 - row['coupon_discount']) / 100\n",
    "            row['delivery_charges'] = row['order_total'] - row['order_price'] * denom\n",
    "\n",
    "    # --- Impute order_total ---\n",
    "    if pd.isna(row['order_total']):\n",
    "        if pd.notna(row['order_price']) and pd.notna(row['coupon_discount']) and pd.notna(row['delivery_charges']):\n",
    "            denom = (100 - row['coupon_discount']) / 100\n",
    "            row['order_total'] = row['order_price'] * denom + row['delivery_charges']\n",
    "\n",
    "    # --- Impute distance_to_nearest_warehouse ---\n",
    "    if pd.isna(row['distance_to_nearest_warehouse']):\n",
    "        if pd.notna(row['nearest_warehouse']) and pd.notna(row['customer_lat']) and pd.notna(row['customer_long']):\n",
    "            wh = warehouses.loc[warehouses['names'] == row['nearest_warehouse']].iloc[0]\n",
    "            row['distance_to_nearest_warehouse'] = haversine(row['customer_lat'], row['customer_long'], wh['lat'], wh['lon'])\n",
    "\n",
    "    # --- Impute is_happy_customer from sentiment---\n",
    "    if pd.isna(row['is_happy_customer']) and pd.notna(row['latest_customer_review']):\n",
    "        sentiment = sia.polarity_scores(str(row['latest_customer_review']))\n",
    "        row['is_happy_customer'] = sentiment['compound'] >= 0.05\n",
    "\n",
    "    return row\n",
    "\n",
    "# Apply\n",
    "missing_data_imputed = missing_data.apply(lambda r: impute_row(r, warehouses, catalog), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                         0\n",
      "customer_id                      0\n",
      "date                             0\n",
      "nearest_warehouse                0\n",
      "shopping_cart                    0\n",
      "order_price                      0\n",
      "delivery_charges                 0\n",
      "customer_lat                     0\n",
      "customer_long                    0\n",
      "coupon_discount                  0\n",
      "order_total                      0\n",
      "season                           0\n",
      "is_expedited_delivery            0\n",
      "distance_to_nearest_warehouse    0\n",
      "latest_customer_review           0\n",
      "is_happy_customer                0\n",
      "parsed_cart                      0\n",
      "dtype: int64\n",
      "{'Alcon 10': np.float64(8950.0), 'Candle Inferno': np.float64(430.0), 'Lucent 330S': np.float64(1230.0), 'Olivia x460': np.float64(1225.0), 'Thunder line': np.float64(2180.0), 'Toshika 750': np.float64(4320.0), 'Universe Note': np.float64(3450.0), 'iAssist Line': np.float64(2225.0), 'iStream': np.float64(150.0), 'pearTV': np.float64(6310.0)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(missing_data_imputed.isna().sum())\n",
    "rows_with_nulls = missing_data_imputed[missing_data_imputed.isnull().any(axis=1)]\n",
    "print(rows_with_nulls)\n",
    "\n",
    "print(catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have two pandas datasets, warehouses and missing_data, with the following columns:\n",
    "1. warehouses has the following columns:\n",
    "names,lat,lon\n",
    "\n",
    "2. missing_data has the following columns:\n",
    "order_id,customer_id,date,nearest_warehouse,shopping_cart,order_price,delivery_charges,customer_lat,customer_long,coupon_discount,order_total,season,is_expedited_delivery,distance_to_nearest_warehouse,latest_customer_review,is_happy_customer\n",
    "\n",
    "I want to perform data imputation. The columns which have missing entries, and the imputing strategy for each column, are:\n",
    "nearest_warehouse: compute the lowest Haversine Distance (with radius of earth = 6378 KM) between the customer_lat, customer_long and each of the lat, lon pairs in warehouses, and impute with the \"names\" of the lowest Haversine Distance.\n",
    "order_price: (order_total - delivery_charges)/((100-coupon_discount)/100)\n",
    "delivery_charges: order_total - order_price*((100-coupon_discount)/100)\n",
    "order_total: order_price*((100-coupon_discount)/100) + delivery_charges\n",
    "distance_to_nearest_warehouse: Haversine Distance (with radius of earth = 6378 KM) of customer_lat, customer_long vs the lat, lon of nearest_warehouse as found in warehouses\n",
    "is_happy_customer: check latest_customer_review with SentimentIntensityAnalyzer from \n",
    "nltk.sentiment.vader to obtain the polarity score. A sentiment is considered positive if it has a 'compound' polarity score of 0.05 or higher and is considered negative otherwise.\n",
    "\n",
    "If any row has too many missing columns to do any of the above imputation, do not impute it so that i can later see what's incomplete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "shopping_cart, a column in missing_data is a list of tuples, of (Item_ordered, Quantity), example: \"[('Item 330S', 1), ('sampleItem', 2)]\". \n",
    "\n",
    "there are 10 categories of items. using the column shopping_cart, first identify the 10 categories of items, then use numpy.linalg to determine the unit price of each item.\n",
    "\n",
    "store the values of this in a dictionary named catalog.\n",
    "\n",
    "in the case that both order_price and order_total are missing, order_price should be imputed from shopping_cart. use the number of each type of item ordered in shopping_cart, and, referencing the values found in catalog calculated earlier, impute order_price from this. order_total then can be imputed as normal.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRC-X7KrBAYl"
   },
   "outputs": [],
   "source": [
    "\n",
    "outlier_data = pd.read_csv(base + 'Group_035_outlier_data.csv')\n",
    "print(outlier_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM2J/3csU4eZksPso9duybE",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
