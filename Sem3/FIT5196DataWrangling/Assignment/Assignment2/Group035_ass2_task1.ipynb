{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FIT5196 Assessment 2\n"
      ],
      "metadata": {
        "id": "RoekGA7GOds1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Table of Contents\n",
        "\n",
        "1. Data Cleansing\n",
        "\n",
        "    1.1 Import Data\n",
        "\n",
        "    1.2 Dirty Data\n",
        "\n",
        "      - 1.2.1 Dirty Data EDA\n",
        "\n",
        "        - 1.2.1.1 Individual Column EDA\n",
        "\n",
        "        - 1.2.1.2 Cross-Column EDA\n",
        "\n",
        "        - 1.2.1.3 Dirty Data Fix\n",
        "    \n",
        "    1.3 Outlier Data\n",
        "    \n",
        "    1.4 Missing Data\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "7eJwZYV00jkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1. Data Cleansing"
      ],
      "metadata": {
        "id": "PBQqEv75OmOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Import Data"
      ],
      "metadata": {
        "id": "GsqdMLFMv5PQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "JY6ZwHgw8C-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5153437-8fec-4c60-b850-feae528fdaf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "base = \"/content/drive/MyDrive/FIT5196Assignment2/\" # for colab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Begin here if running locally\n",
        "\n",
        "# base = \"\""
      ],
      "metadata": {
        "id": "u4k1Nb-39jM5"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Library, data and helper functions preparation ---\n",
        "# --- Import libraries ---\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "from math import radians, cos, sin, asin, sqrt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import r2_score\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# --- Load data ---\n",
        "# Warehouse data\n",
        "warehouse_data = pd.read_csv(base + 'warehouses.csv')\n",
        "\n",
        "# Dirty data\n",
        "dirty_data = pd.read_csv(base + 'Group_035_dirty_data.csv')\n",
        "\n",
        "# Missing data\n",
        "missing_data = pd.read_csv(base + 'Group_035_missing_data.csv')\n",
        "\n",
        "# Outlier data\n",
        "outlier_data = pd.read_csv(base + 'Group_035_outlier_data.csv')\n",
        "\n",
        "# --- Prepare Sentiment analyzer ---\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# --- Prepare Haversine helper ---\n",
        "def haversine_dist(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"\n",
        "    Calculate the Haversine distance between two points on the Earth's surface.\n",
        "    \"\"\"\n",
        "    R = 6378  # Earth radius in KM\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    return R * c"
      ],
      "metadata": {
        "id": "YnlBww44vcHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c061d9-c270-40fe-e69c-9bc2d9b52c1e"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Dirty Data"
      ],
      "metadata": {
        "id": "QAqJ1zv_OTIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1 Dirty Data EDA"
      ],
      "metadata": {
        "id": "kn2zyrGvZdum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check all the data type\n",
        "print(dirty_data.dtypes)"
      ],
      "metadata": {
        "id": "aJfsoooPncBx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ca6e08f-1581-4451-d1af-9aeb56fc3e75"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "order_id                          object\n",
            "customer_id                       object\n",
            "date                              object\n",
            "nearest_warehouse                 object\n",
            "shopping_cart                     object\n",
            "order_price                        int64\n",
            "delivery_charges                 float64\n",
            "customer_lat                     float64\n",
            "customer_long                    float64\n",
            "coupon_discount                    int64\n",
            "order_total                      float64\n",
            "season                            object\n",
            "is_expedited_delivery               bool\n",
            "distance_to_nearest_warehouse    float64\n",
            "latest_customer_review            object\n",
            "is_happy_customer                   bool\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Type Inspection - Interpretation:**\n",
        "\n",
        "The data type inspection confirms that each column in the dataset has a generally appropriate data type. Identifiers such as order_id and customer_id are stored as object, indicating alphanumeric strings. Numerical attributes such as orer_price, deivery_charges, order_total, and the geographic coordinates includig customer_lat, customer_long, distance_to_nearest_warehouse, are correctly stored as either integer or float. Boolean attributes such as is_expedited_delivery and is_happy_customer are properly represented as bool. However, some columsn such as date and shopping_cart are stored as object, which suggests further conversion to datetime type and parsing required respectively.\n",
        "\n",
        "\n",
        "**Justification:**\n",
        "\n",
        "Verifying data types is crucial first step in EDA because incorrect data types may lead to misinterpretation or computational errors during validation and cleaning."
      ],
      "metadata": {
        "id": "q2GPpJMj6t7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of dirty data\n",
        "dirty_data.describe(include = \"all\")"
      ],
      "metadata": {
        "id": "o8RvXGgb44FI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "3232014d-fdfb-43a2-8777-c9f1795ea1fb"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         order_id   customer_id        date nearest_warehouse  \\\n",
              "count         500           500         500               500   \n",
              "unique        500           493         304                 6   \n",
              "top     ORD089659  ID2621587173  2019-05-25          Thompson   \n",
              "freq            1             2           6               201   \n",
              "mean          NaN           NaN         NaN               NaN   \n",
              "std           NaN           NaN         NaN               NaN   \n",
              "min           NaN           NaN         NaN               NaN   \n",
              "25%           NaN           NaN         NaN               NaN   \n",
              "50%           NaN           NaN         NaN               NaN   \n",
              "75%           NaN           NaN         NaN               NaN   \n",
              "max           NaN           NaN         NaN               NaN   \n",
              "\n",
              "                                    shopping_cart   order_price  \\\n",
              "count                                         500    500.000000   \n",
              "unique                                        460           NaN   \n",
              "top     [('Lucent 330S', 1), ('iAssist Line', 1)]           NaN   \n",
              "freq                                            4           NaN   \n",
              "mean                                          NaN  13864.580000   \n",
              "std                                           NaN   7781.162606   \n",
              "min                                           NaN   1375.000000   \n",
              "25%                                           NaN   7900.000000   \n",
              "50%                                           NaN  12260.000000   \n",
              "75%                                           NaN  19260.000000   \n",
              "max                                           NaN  39330.000000   \n",
              "\n",
              "        delivery_charges  customer_lat  customer_long  coupon_discount  \\\n",
              "count         500.000000    500.000000     500.000000       500.000000   \n",
              "unique               NaN           NaN            NaN              NaN   \n",
              "top                  NaN           NaN            NaN              NaN   \n",
              "freq                 NaN           NaN            NaN              NaN   \n",
              "mean           78.031120    -27.942558     135.095643        10.740000   \n",
              "std            14.400599     41.353147      41.351948         8.449567   \n",
              "min            46.400000    -37.831769     -37.827219         0.000000   \n",
              "25%            66.695000    -37.818620     144.948830         5.000000   \n",
              "50%            76.820000    -37.812261     144.962138        10.000000   \n",
              "75%            85.802500    -37.805632     144.978927        15.000000   \n",
              "max           112.430000    145.009445     145.018319        25.000000   \n",
              "\n",
              "         order_total  season is_expedited_delivery  \\\n",
              "count     500.000000     500                   500   \n",
              "unique           NaN       8                     2   \n",
              "top              NaN  Summer                  True   \n",
              "freq             NaN     128                   258   \n",
              "mean    12598.740340     NaN                   NaN   \n",
              "std      6961.477582     NaN                   NaN   \n",
              "min      1450.550000     NaN                   NaN   \n",
              "25%      7405.700000     NaN                   NaN   \n",
              "50%     11111.125000     NaN                   NaN   \n",
              "75%     16934.422500     NaN                   NaN   \n",
              "max     34318.220000     NaN                   NaN   \n",
              "\n",
              "        distance_to_nearest_warehouse  \\\n",
              "count                      500.000000   \n",
              "unique                            NaN   \n",
              "top                               NaN   \n",
              "freq                              NaN   \n",
              "mean                         1.064670   \n",
              "std                          0.492255   \n",
              "min                          0.031900   \n",
              "25%                          0.727350   \n",
              "50%                          1.025750   \n",
              "75%                          1.359200   \n",
              "max                          2.829200   \n",
              "\n",
              "                         latest_customer_review is_happy_customer  \n",
              "count                                       499               500  \n",
              "unique                                      499                 2  \n",
              "top     great value hard to beat for the price.              True  \n",
              "freq                                          1               372  \n",
              "mean                                        NaN               NaN  \n",
              "std                                         NaN               NaN  \n",
              "min                                         NaN               NaN  \n",
              "25%                                         NaN               NaN  \n",
              "50%                                         NaN               NaN  \n",
              "75%                                         NaN               NaN  \n",
              "max                                         NaN               NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29d82469-5130-4822-b113-eecac68bccfb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_id</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>date</th>\n",
              "      <th>nearest_warehouse</th>\n",
              "      <th>shopping_cart</th>\n",
              "      <th>order_price</th>\n",
              "      <th>delivery_charges</th>\n",
              "      <th>customer_lat</th>\n",
              "      <th>customer_long</th>\n",
              "      <th>coupon_discount</th>\n",
              "      <th>order_total</th>\n",
              "      <th>season</th>\n",
              "      <th>is_expedited_delivery</th>\n",
              "      <th>distance_to_nearest_warehouse</th>\n",
              "      <th>latest_customer_review</th>\n",
              "      <th>is_happy_customer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>499</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>500</td>\n",
              "      <td>493</td>\n",
              "      <td>304</td>\n",
              "      <td>6</td>\n",
              "      <td>460</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>499</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>ORD089659</td>\n",
              "      <td>ID2621587173</td>\n",
              "      <td>2019-05-25</td>\n",
              "      <td>Thompson</td>\n",
              "      <td>[('Lucent 330S', 1), ('iAssist Line', 1)]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Summer</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>great value hard to beat for the price.</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>201</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>128</td>\n",
              "      <td>258</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13864.580000</td>\n",
              "      <td>78.031120</td>\n",
              "      <td>-27.942558</td>\n",
              "      <td>135.095643</td>\n",
              "      <td>10.740000</td>\n",
              "      <td>12598.740340</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.064670</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7781.162606</td>\n",
              "      <td>14.400599</td>\n",
              "      <td>41.353147</td>\n",
              "      <td>41.351948</td>\n",
              "      <td>8.449567</td>\n",
              "      <td>6961.477582</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.492255</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1375.000000</td>\n",
              "      <td>46.400000</td>\n",
              "      <td>-37.831769</td>\n",
              "      <td>-37.827219</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1450.550000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.031900</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7900.000000</td>\n",
              "      <td>66.695000</td>\n",
              "      <td>-37.818620</td>\n",
              "      <td>144.948830</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>7405.700000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.727350</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12260.000000</td>\n",
              "      <td>76.820000</td>\n",
              "      <td>-37.812261</td>\n",
              "      <td>144.962138</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>11111.125000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.025750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19260.000000</td>\n",
              "      <td>85.802500</td>\n",
              "      <td>-37.805632</td>\n",
              "      <td>144.978927</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16934.422500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.359200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>39330.000000</td>\n",
              "      <td>112.430000</td>\n",
              "      <td>145.009445</td>\n",
              "      <td>145.018319</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>34318.220000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.829200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29d82469-5130-4822-b113-eecac68bccfb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29d82469-5130-4822-b113-eecac68bccfb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29d82469-5130-4822-b113-eecac68bccfb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-896a0eaa-a5d3-496f-8294-903df911039a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-896a0eaa-a5d3-496f-8294-903df911039a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-896a0eaa-a5d3-496f-8294-903df911039a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dirty_data\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"order_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"500\",\n          \"ORD089659\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"customer_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          493,\n          \"2\",\n          \"500\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1970-01-01 00:00:00.000000006\",\n        \"max\": \"2019-05-25 00:00:00\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          304,\n          \"6\",\n          \"500\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nearest_warehouse\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          6,\n          \"201\",\n          \"500\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shopping_cart\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          460,\n          \"4\",\n          \"500\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"order_price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12409.758233664197,\n        \"min\": 500.0,\n        \"max\": 39330.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          13864.58,\n          12260.0,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delivery_charges\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 155.20003303761086,\n        \"min\": 14.40059851606321,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          78.03112,\n          76.82,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"customer_lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 187.87867263053218,\n        \"min\": -37.831769,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -27.942557974800003,\n          -37.81226095,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"customer_long\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 155.77621873823207,\n        \"min\": -37.8272185,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          135.0956425398,\n          144.96213795,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"coupon_discount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 173.18447446370033,\n        \"min\": 0.0,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          10.74,\n          10.0,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"order_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10762.704996432689,\n        \"min\": 500.0,\n        \"max\": 34318.22,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          12598.74034,\n          11111.125,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"season\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          8,\n          \"128\",\n          \"500\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_expedited_delivery\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          \"258\",\n          \"500\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"distance_to_nearest_warehouse\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 176.39826330404637,\n        \"min\": 0.0319,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.0646696,\n          1.02575,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latest_customer_review\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"499\",\n          \"great value hard to beat for the price.\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_happy_customer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          \"372\",\n          \"500\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Descriptive Summary - Interpretation:**\n",
        "\n",
        "The descriptive summary indicates that the dataset contains 500 records, with all columns having complete counts except for latest_customer_review with only 499 records. The identifiers order_id and customer_id show 500 and 493 unique values respectively, suggesting that some customers placed multiple orders. The dataset spans 304 unique dates, covering several seasons, with Summer accummulating to 128 orders, the highest order count out of all seasons. There are a total of 8 variation in season and 6 variation in nearest_warehouse, suggesting a potential error in both columns. For numerical columns, order_price has a mean of approximately 13,864 AUD and ranges from 1,375 to 39,330 AUDm indicating a wide variety of order quantity and item price. Delivery charges average around 78 AUD, consistent with varying distances and expedited options. The value range of customer_lat and customer_long shows an expected spread around Melbourne's coordinates, but the similarity in minimum (\\~ -37.8) and maximum value (~145.0) of both attributes suggests that there are potential swapped coordinates. The order_total logically tracks below order_price due to discounts and delivery charges. Boolean columns such as is_expedited_delivery and is_happy_customer are roughly balanced, with 258 expedited deliveries and 372 happy customers.\n",
        "\n",
        "\n",
        "**Justification:**\n",
        "\n",
        "Using describe() provides a simple yet efficient high-level assessment of both categorical and numerical attributes. This summary helps verify completeness, detect outliers, and identify naming inconsistencies or duplication. It also provides a clear understanding of the dataset's structure, supporting targeted anomaly detection in later steps, and provides evidence of data integrity across multiple attribute types."
      ],
      "metadata": {
        "id": "XP1KA9Gv8Qkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1.1 Individual Column EDA"
      ],
      "metadata": {
        "id": "NXOgSN4zb1qI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# date\n",
        "dirty_data[\"date\"] = pd.to_datetime(dirty_data[\"date\"], errors=\"coerce\")\n",
        "\n",
        "# Invalid date\n",
        "print(f\"Invalid date: {dirty_data['date'].isna().sum()}\")\n",
        "invalid_date = dirty_data[dirty_data[\"date\"].isna()]\n",
        "print(invalid_date[[\"order_id\", \"customer_id\", \"date\", \"season\"]].to_string(index=False))\n",
        "\n",
        "# Date distribution\n",
        "valid_dates = dirty_data[\"date\"].dropna()\n",
        "print(f\"Min date: {valid_dates.min()}\")\n",
        "print(f\"Max date: {valid_dates.max()}\")\n",
        "print(f\"Number of valid dates: {valid_dates.count()}\")\n",
        "print(f\"Number of unique dates: {valid_dates.nunique()}\")"
      ],
      "metadata": {
        "id": "JZWfGwuhORVN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1ed931-5c23-4d93-ccdb-a214a67dcb58"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid date: 27\n",
            " order_id  customer_id date season\n",
            "ORD164387 ID0289597227  NaT Summer\n",
            "ORD066446 ID0145235264  NaT Winter\n",
            "ORD312565 ID0638050574  NaT Summer\n",
            "ORD181051 ID0709970691  NaT Summer\n",
            "ORD046408 ID5402876538  NaT Spring\n",
            "ORD219265 ID0055722470  NaT Winter\n",
            "ORD006455 ID0634777174  NaT Spring\n",
            "ORD084861 ID3094966833  NaT Winter\n",
            "ORD438655 ID2705184152  NaT Summer\n",
            "ORD234563 ID2383211199  NaT Spring\n",
            "ORD199817 ID0650275823  NaT Summer\n",
            "ORD113549 ID0634780047  NaT Autumn\n",
            "ORD489756 ID0846548135  NaT Spring\n",
            "ORD273300 ID0052599838  NaT Spring\n",
            "ORD194653 ID0575428932  NaT Summer\n",
            "ORD480775 ID4655129040  NaT Spring\n",
            "ORD160619 ID0746917821  NaT Winter\n",
            "ORD402436 ID2621587173  NaT Autumn\n",
            "ORD311888 ID1463620717  NaT Autumn\n",
            "ORD491911 ID2237521759  NaT Winter\n",
            "ORD265708 ID1889073821  NaT Summer\n",
            "ORD060082 ID0576834725  NaT Summer\n",
            "ORD469475 ID0767665017  NaT Summer\n",
            "ORD461231 ID0126934555  NaT Winter\n",
            "ORD047863 ID0638044384  NaT Autumn\n",
            "ORD499923 ID6197211200  NaT Spring\n",
            "ORD036565 ID0616939377  NaT Spring\n",
            "Min date: 2019-01-01 00:00:00\n",
            "Max date: 2019-12-30 00:00:00\n",
            "Number of valid dates: 473\n",
            "Number of unique dates: 278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Date Formatting - Interpretation:**\n",
        "\n",
        "The date column was converted from object to datetime format using pd.to_datetime(), where errors are coerced by automatically assigning NaT to invalid or unrecognisable entries. The result shows 27 missing date values, but these rows have valid season values, suggesting that the order period can be inferred later through seasonal mapping. Among valid entries, the date range spans from 2019-01-01 to 2019-12-30, covering an entire calendar year. There are 473 valid dates with 278 unique dates, indicating multiple orders occurred on the same dates.\n",
        "\n",
        "**Justification:**\n",
        "\n",
        "Validating and converting date formats ensures temporal consistency across the dataset. The use of pd.to_datetime(..., errors=\"coerce\") standardises all date entries while safely identifying anomalies. Detecting 27 invalid dates highlights missing temporal information that must be recovered using related attributes such as season attribute. The date range confirms that the dataset represents a continuous operational year, which supports seasonal trend analysis. To confirm that there's absolutely no more than one error per row requires cross-column EDA with season."
      ],
      "metadata": {
        "id": "4B4GUxZT_7fC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nearest_warehouse\n",
        "# Invalid nearest_warehouse names\n",
        "invalid_warehouse_name = dirty_data[dirty_data[\"nearest_warehouse\"].isna()]\n",
        "print(\"Invalid season found:\", len(invalid_warehouse_name))\n",
        "\n",
        "# Unique values\n",
        "print(dirty_data[\"nearest_warehouse\"].unique())\n",
        "\n",
        "# Invalid nearest_warehouse value\n",
        "invalid_warehouses = dirty_data[~dirty_data[\"nearest_warehouse\"].isin(warehouse_data[\"names\"])]\n",
        "print(\"Number of invalid nearest warehouse names:\", len(invalid_warehouses))\n",
        "print(dirty_data[\"nearest_warehouse\"].value_counts(dropna=False))\n",
        "print(invalid_warehouses[[\"order_id\", \"nearest_warehouse\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "34pnwHsQO0eT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26666441-7b4c-4d35-9b22-57299440d9d9"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid season found: 0\n",
            "['Thompson' 'Nickolson' 'Bakers' 'thompson' 'nickolson' 'bakers']\n",
            "Number of invalid nearest warehouse names: 20\n",
            "nearest_warehouse\n",
            "Thompson     201\n",
            "Nickolson    180\n",
            "Bakers        99\n",
            "thompson       9\n",
            "nickolson      7\n",
            "bakers         4\n",
            "Name: count, dtype: int64\n",
            " order_id nearest_warehouse\n",
            "ORD256861          thompson\n",
            "ORD014442          thompson\n",
            "ORD052629         nickolson\n",
            "ORD166717          thompson\n",
            "ORD461915         nickolson\n",
            "ORD461426            bakers\n",
            "ORD015774         nickolson\n",
            "ORD169718         nickolson\n",
            "ORD120949            bakers\n",
            "ORD138742            bakers\n",
            "ORD025929            bakers\n",
            "ORD393258          thompson\n",
            "ORD201338         nickolson\n",
            "ORD224300         nickolson\n",
            "ORD016571         nickolson\n",
            "ORD471229          thompson\n",
            "ORD164906          thompson\n",
            "ORD118183          thompson\n",
            "ORD300512          thompson\n",
            "ORD099672          thompson\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nearest_warehouse column - Interpretation:**\n",
        "\n",
        "The nearest_warehouse attribute shows a total of six distinct values, but it is confirmed that there are only three valid warehouses (Thompson, Nickolson, Bakers) from the given warehouses.csv dataset. This reveals that there are 20 records with inconsistent naming. The frequency confirms that Thompson is the most common warehouse, followed by Nickolson and Bakers.\n",
        "\n",
        "**Justification:**\n",
        "\n",
        "Warehouse names are categorical attributes that should match a predefined list from the warehouse.csv reference file. Ensuring exact spelling and consistent capitalisation is necessary because these names are used to compute the distance_to_nearest_warehouse and determine the logistics accuracy. To confirm that there's absolutely no more than one error per row requires cross-column EDA with distance_to_nearest_warehouse, customer_lat, and customer_long.\n"
      ],
      "metadata": {
        "id": "lYyyItU7BmAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shopping_cart (item ordered)\n",
        "# Extract the necessary columns\n",
        "shopping_cart_check = dirty_data[[\"order_id\", \"shopping_cart\", \"order_total\"]].copy()\n",
        "\n",
        "# Parse the shopping_cart value to get the item ordered\n",
        "shopping_cart_check[\"shopping_cart_parsed\"] = shopping_cart_check[\"shopping_cart\"].apply(ast.literal_eval)\n",
        "branded_items = [item for cart in shopping_cart_check[\"shopping_cart_parsed\"] for (item, qty) in cart]\n",
        "\n",
        "# Invalid value\n",
        "invalid_cart = shopping_cart_check[shopping_cart_check[\"shopping_cart\"].isna() | shopping_cart_check[\"shopping_cart\"].eq(\"[]\")]\n",
        "print(\"Number of invalid values:\", len(invalid_cart))\n",
        "invalid_items = [item for item in branded_items if pd.isna(item) or item is None]\n",
        "print(\"Number of invalid items:\", len(invalid_items))\n",
        "invalid_duplicates = shopping_cart_check[shopping_cart_check[\"shopping_cart_parsed\"].apply(lambda cart: len({item for item, qty in cart}) != len(cart))]\n",
        "print(\"Number of duplicated items:\", len(invalid_duplicates))\n",
        "\n",
        "# Count and value of unique branded items\n",
        "unique_branded_items = pd.Series(branded_items).unique()\n",
        "print(f\"Number of unique branded items:\", len(unique_branded_items))\n",
        "print(f\"Unique branded items:\", unique_branded_items)\n",
        "\n",
        "# Frequency distribution\n",
        "print(pd.Series(branded_items).value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "px_KfsRLO9eZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca2dc147-c64b-4b34-82bc-a219a7efaac4"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of invalid values: 0\n",
            "Number of invalid items: 0\n",
            "Number of duplicated items: 0\n",
            "Number of unique branded items: 10\n",
            "Unique branded items: ['iAssist Line' 'Alcon 10' 'Universe Note' 'pearTV' 'Toshika 750'\n",
            " 'Candle Inferno' 'Thunder line' 'iStream' 'Olivia x460' 'Lucent 330S']\n",
            "iAssist Line      169\n",
            "Toshika 750       163\n",
            "Lucent 330S       154\n",
            "Alcon 10          153\n",
            "Thunder line      151\n",
            "pearTV            147\n",
            "Candle Inferno    147\n",
            "Olivia x460       146\n",
            "iStream           141\n",
            "Universe Note     134\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shopping_cart column - Interpretation:**  \n",
        "The shopping_cart attribute was parsed from its string representation into Python list format using ast.literal_eval(), allowing each tuple to be separated into item names and quantities. The result shows that there are no invalid or missing cart entries and a total of 10 unique branded items were identified including iAssist Line, Alcon 10, Universe Note, pearTV, Toshika 750, Candle Inferno, Thunder line, iStream, Olivia x460, and Lucent 330S. This matches the specified criteria for the number of unique items in shopping_cart column.\n",
        "\n",
        "**Justification:**\n",
        "\n",
        "Parsing and validating the shopping_cart attribute is essential as it directly influences the accuracy of order_price and order_total. The absence of invalid items with consistent naming and correct number of branded items confirms that the shopping_cart entries adhere to business rule. To confirm that there's absolutely no error in this column requires cross-column EDA with order_price, delivery_charges, coupon_discount, and order_total."
      ],
      "metadata": {
        "id": "Ny1VukiHCxHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Longitude: customer_lat, customer_long\n",
        "invalid_coords = dirty_data[dirty_data[\"customer_lat\"].isna() |\n",
        "                            dirty_data[\"customer_long\"].isna() |\n",
        "                            ~dirty_data[\"customer_lat\"].between(-90, 90) |\n",
        "                            ~dirty_data[\"customer_long\"].between(-180, 180)]\n",
        "print(\"Invalid coordinates found:\", len(invalid_coords))\n",
        "print(invalid_coords[[\"order_id\", \"customer_id\", \"customer_lat\", \"customer_long\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "zzv5rTEhPDut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c2d7eef-5746-4761-ed60-48d07341b403"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid coordinates found: 27\n",
            " order_id  customer_id  customer_lat  customer_long\n",
            "ORD091929 ID0145235237    144.959364     -37.815878\n",
            "ORD299508 ID0260907252    145.009445     -37.823816\n",
            "ORD074143 ID6167247310    144.960234     -37.819701\n",
            "ORD392203 ID0588197234    144.973944     -37.812101\n",
            "ORD208957 ID6245731092    144.977354     -37.810785\n",
            "ORD090831 ID1519470918    144.993262     -37.797624\n",
            "ORD062280 ID6167489480    144.961790     -37.816990\n",
            "ORD155978 ID0452381032    144.949411     -37.824991\n",
            "ORD493957 ID0361227457    144.976899     -37.801182\n",
            "ORD083244 ID0577458190    144.977813     -37.818479\n",
            "ORD373348 ID1888340704    144.985178     -37.793879\n",
            "ORD055195 ID2399230968    144.983469     -37.806415\n",
            "ORD125480 ID2190483590    144.961303     -37.810368\n",
            "ORD285476 ID2141904233    144.935968     -37.802954\n",
            "ORD349254 ID0387153047    144.947587     -37.805420\n",
            "ORD048052 ID0207093528    145.004517     -37.801171\n",
            "ORD479919 ID1449297346    144.977507     -37.815613\n",
            "ORD326763 ID0581709069    144.928230     -37.805420\n",
            "ORD442562 ID0846546860    144.968618     -37.820067\n",
            "ORD063341 ID0248266235    144.988143     -37.827219\n",
            "ORD012510 ID1833120524    144.954950     -37.799791\n",
            "ORD070213 ID0054398922    144.946328     -37.801354\n",
            "ORD481618 ID2810279739    144.988204     -37.816652\n",
            "ORD202182 ID0129549424    144.931580     -37.809350\n",
            "ORD396842 ID0589420528    144.972599     -37.809694\n",
            "ORD130131 ID1283671454    144.964657     -37.796916\n",
            "ORD201885 ID0026051952    144.968469     -37.813794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Geographical coordinates columns - Interpretation:**\n",
        "\n",
        "A total of 27 invalid geographical coordinates were identified in the customer_lat and customer_long columns, where the latitude values exceed the valid range of -90 to 90, and longitude values exceed -180 to 180. The result indicates that the coordinates are swapped where the latitude column contains values around 144 and the longitude column contains values around -37.  \n",
        "\n",
        "**Justification:**\n",
        "\n",
        "Validating geographical coordinates is crucial to ensure spatial integrity. Customer locations directly determine the nearest_warehouse and distance_to_nearest_warehouse using Haversine formula. hence, the swapped coordinates would lead to computational errors.\n"
      ],
      "metadata": {
        "id": "RHQeQEvbEVUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# distance_to_nearest_warehouse\n",
        "invalid_distance = dirty_data[dirty_data[\"distance_to_nearest_warehouse\"].isna() |\n",
        "                              dirty_data[\"distance_to_nearest_warehouse\"] <= 0]\n",
        "print(\"Invalid distance found:\", len(invalid_distance))"
      ],
      "metadata": {
        "id": "UVXATQJSPI2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee67a7b5-0968-43e5-910a-36bb3fdb6b1a"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid distance found: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distance_to_nearest_warehouse column - Interpretation:**\n",
        "\n",
        "The validation check for distance_to_nearest_warehouse column found no invalid or missing distance values. All records contain positive numerical values, confirming that each order has an assigned and non-zero delivery distance.\n",
        "\n",
        "**Justification:**\n",
        "\n",
        "Validating distance_to_nearest_warehouse ensures spatial and logistical consistency. Negative or zero distances would indicate errors in warehouse assignment or coordinate mismatches, while missing values may disrupt calculations. To confirm that there's absolutely no error in this column requires cross-column EDA with nearest_warehouse, customer_lat, and customer_long."
      ],
      "metadata": {
        "id": "6W_gZcHAFk8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# order_total\n",
        "invalid_total = dirty_data[dirty_data[\"order_total\"].isna() |\n",
        "                           dirty_data[\"order_total\"] <= 0 |\n",
        "                           (dirty_data[\"order_total\"].apply(lambda x: len(str(x).split('.')[-1]) > 2 if '.' in str(x) else False))]\n",
        "print(\"Invalid order total found:\", len(invalid_total))"
      ],
      "metadata": {
        "id": "QiSuMZnCPLSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f531d74e-138f-4cff-c127-02ff2e87d18e"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid order total found: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Order_total column - Interpretation:**\n",
        "\n",
        "No invalid or missing values were detected in the order_total column, where all entries are positive and non-zero numerical values with at most two decimal places, indicating that order_total is in valid monetary format.\n",
        "\n",
        "**Justification:**\n",
        "\n",
        "The validation of order_total is essential because it represents the final transaction amount after applying discounts and delivery charges, where all totals should be positive and in correct format to ensure no computational errors later on. To confirm there's absolutely no errors in this column requires cross-column EDA with shopping_cart, order_price, delivery_charges, and coupon_discount.\n"
      ],
      "metadata": {
        "id": "tmG0jzanHhlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# season\n",
        "# Invalid season names\n",
        "invalid_season = dirty_data[dirty_data[\"season\"].isna()]\n",
        "print(\"Invalid season found:\", len(invalid_season))\n",
        "\n",
        "# Unique values\n",
        "print(dirty_data[\"season\"].unique())\n",
        "\n",
        "# Invalid letter case\n",
        "invalid_case_season = dirty_data[~dirty_data[\"season\"].str.match(r\"^[A-Z][a-z]+$\", na=False)]\n",
        "print(\"Number of seasons not capitalised correctly:\", len(invalid_case_season))\n",
        "print(dirty_data[\"season\"].value_counts(dropna=False))\n",
        "print(invalid_case_season[[\"order_id\", \"season\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "N7bWp26CPMo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40a97c8f-116a-442f-8c1c-c15df7e06633"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid season found: 0\n",
            "['Winter' 'Summer' 'spring' 'Autumn' 'Spring' 'autumn' 'winter' 'summer']\n",
            "Number of seasons not capitalised correctly: 21\n",
            "season\n",
            "Summer    128\n",
            "Winter    124\n",
            "Spring    120\n",
            "Autumn    107\n",
            "spring      9\n",
            "summer      6\n",
            "autumn      3\n",
            "winter      3\n",
            "Name: count, dtype: int64\n",
            " order_id season\n",
            "ORD209240 spring\n",
            "ORD277275 spring\n",
            "ORD123382 autumn\n",
            "ORD209230 winter\n",
            "ORD132264 spring\n",
            "ORD192930 spring\n",
            "ORD172628 spring\n",
            "ORD103002 summer\n",
            "ORD344249 summer\n",
            "ORD222038 summer\n",
            "ORD026633 summer\n",
            "ORD455600 summer\n",
            "ORD468030 spring\n",
            "ORD478782 winter\n",
            "ORD345384 summer\n",
            "ORD493849 spring\n",
            "ORD492808 winter\n",
            "ORD385926 spring\n",
            "ORD462038 autumn\n",
            "ORD434426 spring\n",
            "ORD387883 autumn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Season column - Interpretation:**\n",
        "\n",
        "The records in the season column confirmed with no null entries. However, inspection of unique values shows both correctly and incorrectly capitalised season names, such as Winter vs winter. The result shows a total of 21 values were identified with incorrect letter casing.\n",
        "\n",
        "**Justification:**\n",
        "\n",
        "Consistent categorical formatting is critical for accurate grouping, filtering, and model training. Inconsistent letter casing can cause duplicate categories to be treated as separate values, leading to incorrect seasonal aggregations. By using str.match() with capitalised regex pattern, all lowercase entries can be standardised to title case. To confirm that there's absolutely no more than one error in this column requires cross-column EDA with date."
      ],
      "metadata": {
        "id": "7a-wD3k5Hebn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# is_expedited_delivery\n",
        "invalid_expedited = dirty_data[dirty_data[\"is_expedited_delivery\"].isna()]\n",
        "print(\"Invalid expedited delivery found:\", len(invalid_expedited))\n",
        "print(dirty_data[\"is_expedited_delivery\"].value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "nO8CchpmPOQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e142966-587e-432c-c4ad-89bce996a65f"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid expedited delivery found: 0\n",
            "is_expedited_delivery\n",
            "True     258\n",
            "False    242\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Is_expedited_delivery column - Interpretation:**\n",
        "\n",
        "All records in is_expedited_delivery column contain only Boolean values, with no missing entries detected. The frequency distribution shows a near-balanced split with 258 expedited delivery and 242 standard deliveries.\n",
        "\n",
        "**Justification:**\n",
        "\n",
        "Validating is_expedited_delivery column is critical for verifying delivery charge calculations since expedited orders should incur higher costs according to seasonal pricing models. Confirming that all entries are valid Boolean values ensures the integrity of this categorical variable and supports accurate modelling. To confirm there are absolutely no errors in this column requires training of a linear regression model with a good R2 score (over 0.97) to validate the column."
      ],
      "metadata": {
        "id": "733XgnQ0Jsll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# is_happy_customer\n",
        "invalid_happy = dirty_data[dirty_data[\"is_happy_customer\"].isna()]\n",
        "print(\"Invalid positive customer response found:\", len(invalid_happy))\n",
        "print(dirty_data[\"is_happy_customer\"].value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "ju9kAa7rPRHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3883a44-2ed5-403a-dd17-04cfa3cfcbf9"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid positive customer response found: 0\n",
            "is_happy_customer\n",
            "True     372\n",
            "False    128\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Is_happy_customer column - Interpretation:**\n",
        "\n",
        "All records in is_happy_customer column contain only Boolean values, with no missing entries detected. The frequency distribution shows 372 happy customers and 128 unhappy customers, indicating that the majority of customers reported positive experiences with their orders.\n",
        "\n",
        "**Justification:**\n",
        "\n",
        "Validating is_happy_customer column is critical for linear regression modelling that predicts delivery charges, where customer satisfaction can influence business rules. Ensuring all entries are valid Boolean values prevents logical errors during sentiment-based analysis."
      ],
      "metadata": {
        "id": "HPgcCg1fKzon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1.2 Cross-Column EDA"
      ],
      "metadata": {
        "id": "XkLcUyjXcDo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check date and season pairing\n",
        "# Extract the necessary columns and exclude NA values\n",
        "date_season = dirty_data[dirty_data[\"date\"].notna()][[\"order_id\", \"date\", \"season\"]].copy()\n",
        "\n",
        "# Standardise season name\n",
        "date_season[\"season_clean\"] = date_season[\"season\"].str.strip().str.lower()\n",
        "\n",
        "# Get the months from date column\n",
        "date_season[\"month\"] = date_season[\"date\"].dt.month\n",
        "\n",
        "# Mapping of months to seasons\n",
        "season_months = {\"summer\": [12, 1, 2],\n",
        "                 \"autumn\": [3, 4, 5],\n",
        "                 \"winter\": [6, 7, 8],\n",
        "                 \"spring\": [9, 10, 11]}\n",
        "\n",
        "# Valid season check\n",
        "def valid_season (row):\n",
        "  season = row[\"season_clean\"]\n",
        "  month = row[\"month\"]\n",
        "  if season in season_months:\n",
        "    return month in season_months[season]\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "# Apply valid season check to the months and season\n",
        "date_season[\"season_match\"] = date_season.apply(valid_season, axis=1)\n",
        "\n",
        "# Invalid date-season pairs\n",
        "invalid_date_season = date_season[~date_season[\"season_match\"]]\n",
        "invalid_case = invalid_date_season[~invalid_date_season[\"season\"].str.match(r\"^[A-Z][a-z]+$\", na=False)]\n",
        "\n",
        "print(\"Number of mismatched date-season pairs:\", len(invalid_date_season))\n",
        "print(\"Number of seasons not capitalised correctly in date-season pairs:\", len(invalid_case))\n",
        "print(invalid_date_season[[\"order_id\", \"date\", \"month\", \"season\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "AD8DWmeYTJhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5792947-c2b1-42b4-f0ae-e9ac24712137"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mismatched date-season pairs: 21\n",
            "Number of seasons not capitalised correctly in date-season pairs: 15\n",
            " order_id       date  month season\n",
            "ORD209240 2019-02-07      2 spring\n",
            "ORD419503 2019-09-21      9 Autumn\n",
            "ORD277275 2019-12-26     12 spring\n",
            "ORD123382 2019-01-06      1 autumn\n",
            "ORD209230 2019-09-03      9 winter\n",
            "ORD192930 2019-08-30      8 spring\n",
            "ORD172628 2019-03-30      3 spring\n",
            "ORD103002 2019-10-17     10 summer\n",
            "ORD040501 2019-10-17     10 Summer\n",
            "ORD344249 2019-10-23     10 summer\n",
            "ORD222038 2019-11-04     11 summer\n",
            "ORD377228 2019-09-24      9 Autumn\n",
            "ORD468030 2019-05-06      5 spring\n",
            "ORD363647 2019-12-01     12 Winter\n",
            "ORD345384 2019-11-25     11 summer\n",
            "ORD127439 2019-07-25      7 Spring\n",
            "ORD493849 2019-04-24      4 spring\n",
            "ORD495324 2019-07-10      7 Summer\n",
            "ORD462038 2019-07-10      7 autumn\n",
            "ORD434426 2019-06-14      6 spring\n",
            "ORD387883 2019-10-20     10 autumn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Date-season pairing - Interpretation:**\n",
        "\n",
        "The validation of date-season cross-column EDA revealed 21 mismatched pairs where the recorded season does not align with the actual month derived from the date column. Additionally, there are 15 records out of the 21 mismatched pairs were not properly capitalised with title case.\n",
        "\n",
        "**Justification:**\n",
        "\n",
        "The date and season are paired up together to validate the types of error occurred in each row. The method used was to detect the mismatched date-season pairing through mapping each Australian season to its corresponding months (Summer: December - February, Autumn: March - May, Winter: June - August, Spring: September - November). By comparing the month extracted from each order's date with its recorded season, mismatched pairs were detected. By using str.match() with capitalised regex pattern, improper capitalisation of the season names were identified. This is to validate that the improper capitalisation of the season names may not be the actual error in these rows, rather it is actually mismatched date-season pairs.\n",
        "  "
      ],
      "metadata": {
        "id": "7q1yJ9maLv4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if distance_to_nearest_warehouse is correct using Haversine distance\n",
        "# Extract the necessary columns\n",
        "warehouse_dist = dirty_data[[\"order_id\", \"nearest_warehouse\", \"distance_to_nearest_warehouse\", \"customer_lat\", \"customer_long\"]].copy()\n",
        "\n",
        "# Standardise warehouses name\n",
        "warehouse_dist[\"nearest_warehouse_clean\"] = warehouse_dist[\"nearest_warehouse\"].str.strip().str.title()\n",
        "\n",
        "# Swap the invalid customer_lat and customer_long\n",
        "invalid_coords_tmp = warehouse_dist[\"customer_lat\"].between(-180, 180) & warehouse_dist[\"customer_long\"].between(-90, 90)\n",
        "warehouse_dist.loc[invalid_coords_tmp, [\"customer_lat\", \"customer_long\"]] = warehouse_dist.loc[invalid_coords_tmp, [\"customer_long\", \"customer_lat\"]].values\n",
        "\n",
        "# Check warehouse_data data types\n",
        "print(warehouse_data.dtypes)\n",
        "\n",
        "# Merge both datasets\n",
        "merge_warehouse_dist = warehouse_dist.merge(warehouse_data,\n",
        "                                            left_on=\"nearest_warehouse_clean\",\n",
        "                                            right_on=\"names\",\n",
        "                                            how=\"left\")\n",
        "\n",
        "# Apply Haversine distance function to the coordinates\n",
        "merge_warehouse_dist[\"haversine_dist\"] = merge_warehouse_dist.apply(lambda row:\n",
        "                                                                    haversine_dist(row[\"customer_lat\"],\n",
        "                                                                             row[\"customer_long\"],\n",
        "                                                                             row[\"lat\"],\n",
        "                                                                             row[\"lon\"]),\n",
        "                                                                    axis=1)\n",
        "\n",
        "# Compare the distances\n",
        "merge_warehouse_dist[\"dist_diff\"] = (merge_warehouse_dist[\"haversine_dist\"] - merge_warehouse_dist[\"distance_to_nearest_warehouse\"]).abs()\n",
        "\n",
        "# Invalid distance_to_nearest_warehouse\n",
        "invalid_distance = merge_warehouse_dist[merge_warehouse_dist[\"dist_diff\"] > 0.1]\n",
        "print(\"Number of mismatched distances:\", len(invalid_distance))\n",
        "print(invalid_distance[[\"order_id\", \"nearest_warehouse_clean\", \"customer_lat\", \"customer_long\", \"lat\", \"lon\", \"distance_to_nearest_warehouse\", \"haversine_dist\", \"dist_diff\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "7JIwiB08cX1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1efc03d7-3f57-4ff2-d756-528d4d1b7ca2"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "names     object\n",
            "lat      float64\n",
            "lon      float64\n",
            "dtype: object\n",
            "Number of mismatched distances: 43\n",
            " order_id nearest_warehouse_clean  customer_lat  customer_long        lat        lon  distance_to_nearest_warehouse  haversine_dist  dist_diff\n",
            "ORD418280               Nickolson    -37.822991     144.976257 -37.818595 144.969551                         1.9037        0.766301   1.137399\n",
            "ORD237879               Nickolson    -37.800113     144.935310 -37.818595 144.969551                         1.7391        3.647097   1.907997\n",
            "ORD020055                  Bakers    -37.817347     145.008734 -37.809996 144.995232                         0.6764        1.442062   0.765662\n",
            "ORD483341                Thompson    -37.820155     144.952118 -37.812673 144.947069                         0.7995        0.943856   0.144356\n",
            "ORD106152               Nickolson    -37.820522     144.982869 -37.818595 144.969551                         0.7663        1.190577   0.424277\n",
            "ORD052629               Nickolson    -37.821635     144.998632 -37.818595 144.969551                         1.3297        2.579471   1.249771\n",
            "ORD461915               Nickolson    -37.814020     144.949193 -37.818595 144.969551                         0.2395        1.861329   1.621829\n",
            "ORD069936                Thompson    -37.807010     144.965764 -37.812673 144.947069                         1.3319        1.760830   0.428930\n",
            "ORD177750                Thompson    -37.799394     144.959286 -37.812673 144.947069                         1.3601        1.827460   0.467360\n",
            "ORD452867                  Bakers    -37.802381     144.991831 -37.809996 144.995232                         0.1950        0.898913   0.703913\n",
            "ORD461426                  Bakers    -37.807495     144.947983 -37.809996 144.995232                         0.5820        4.164774   3.582774\n",
            "ORD393540                  Bakers    -37.800537     145.008953 -37.809996 144.995232                         1.2162        1.601575   0.385375\n",
            "ORD015774               Nickolson    -37.806332     144.959495 -37.818595 144.969551                         1.3010        1.626555   0.325555\n",
            "ORD135624                  Bakers    -37.804381     145.013385 -37.809996 144.995232                         1.9831        1.714587   0.268513\n",
            "ORD471922                  Bakers    -37.823627     145.007563 -37.809996 144.995232                         1.3422        1.865031   0.522831\n",
            "ORD385052                Thompson    -37.814853     144.937806 -37.812673 144.947069                         0.3711        0.849948   0.478848\n",
            "ORD307211               Nickolson    -37.810965     144.978213 -37.818595 144.969551                         0.5429        1.140909   0.598009\n",
            "ORD120949                  Bakers    -37.801549     144.962927 -37.809996 144.995232                         1.8651        2.992820   1.127720\n",
            "ORD227802                Thompson    -37.809084     144.955502 -37.812673 144.947069                         1.1817        0.842408   0.339292\n",
            "ORD216010                Thompson    -37.809813     144.988879 -37.812673 144.947069                         0.5591        3.690696   3.131596\n",
            "ORD138742                  Bakers    -37.805178     144.947622 -37.809996 144.995232                         0.8358        4.221461   3.385661\n",
            "ORD041333                Thompson    -37.815137     144.940339 -37.812673 144.947069                         0.7914        0.652338   0.139062\n",
            "ORD334316                Thompson    -37.824891     144.982106 -37.812673 144.947069                         1.3077        3.367832   2.060132\n",
            "ORD378423               Nickolson    -37.810399     144.972691 -37.818595 144.969551                         0.8424        0.953248   0.110848\n",
            "ORD081635                Thompson    -37.824700     144.984766 -37.812673 144.947069                         1.5006        3.575057   2.074457\n",
            "ORD321986               Nickolson    -37.820637     144.956867 -37.818595 144.969551                         0.8577        1.138328   0.280628\n",
            "ORD025929                  Bakers    -37.810684     144.959848 -37.809996 144.995232                         1.1455        3.112768   1.967268\n",
            "ORD205213               Nickolson    -37.815469     144.968083 -37.818595 144.969551                         1.5693        0.371129   1.198171\n",
            "ORD201338               Nickolson    -37.800090     144.962035 -37.818595 144.969551                         1.9221        2.163375   0.241275\n",
            "ORD436885               Nickolson    -37.802443     144.991522 -37.818595 144.969551                         0.9019        2.639363   1.737463\n",
            "ORD440634                  Bakers    -37.811592     145.003476 -37.809996 144.995232                         1.3297        0.746466   0.583234\n",
            "ORD224300               Nickolson    -37.807837     144.949431 -37.818595 144.969551                         0.5770        2.136543   1.559543\n",
            "ORD416698                Thompson    -37.818765     144.916487 -37.812673 144.947069                         1.2743        2.773467   1.499167\n",
            "ORD471229                Thompson    -37.821629     144.961412 -37.812673 144.947069                         0.7914        1.607719   0.816319\n",
            "ORD049973                  Bakers    -37.810492     144.985019 -37.809996 144.995232                         1.8431        0.899864   0.943236\n",
            "ORD164906                Thompson    -37.809659     144.964064 -37.812673 144.947069                         1.1056        1.531795   0.426195\n",
            "ORD118183                Thompson    -37.812290     144.990362 -37.812673 144.947069                         0.4986        3.807534   3.308934\n",
            "ORD005273               Nickolson    -37.811312     144.973178 -37.818595 144.969551                         1.0157        0.871168   0.144532\n",
            "ORD300512                Thompson    -37.816251     144.987746 -37.812673 144.947069                         0.9582        3.599247   2.641047\n",
            "ORD048269                  Bakers    -37.811024     145.005489 -37.809996 144.995232                         0.7983        0.909235   0.110935\n",
            "ORD175303                  Bakers    -37.821489     145.007448 -37.809996 144.995232                         1.9142        1.670561   0.243639\n",
            "ORD223207                Thompson    -37.819074     144.952082 -37.812673 144.947069                         0.9455        0.837815   0.107685\n",
            "ORD426908                  Bakers    -37.807431     144.934012 -37.809996 144.995232                         1.2880        5.391663   4.103663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distance_to_nearest_warehouse Validation - Interpretation:**\n",
        "\n",
        "The comparison between the recorded distance_to_nearest_warehouse and the recalculated Haversine distance identified 43 mismatched records where the absolute difference exceeded 0.1 km. These discrepancies indicate that the stored distances were either incorrectly computed or linked to the wrong warehouse coordinates. The mismatches are distributed across all three warehouses (Nickolson, Thompson, and Bakers), suggesting that the issue is not isolated to a single location but likely results from rounding errors, coordinate swaps, or incorrect warehouse assignment in the raw data.\n",
        "\n",
        "**Justification:**\n",
        "\n",
        "To verify distance accuracy, the Haversine formula was applied to recompute the true distance between each customer's coordinates and their assigned warehouse's coordinates. This method detects logical inconsistencies by comparing the physically calculated distance to the recorded value. Rows with deviations greater than 0.1 km were flagged as invalid since such variance exceeds expected rounding or measurement noise in real-world data."
      ],
      "metadata": {
        "id": "xG01pBMnOXwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if nearest_warehouse is correct using Haversine distance\n",
        "# Calculate the distance to all three warehouses\n",
        "for _, row in warehouse_data.iterrows():\n",
        "  wh = row[\"names\"]\n",
        "  lat = row[\"lat\"]\n",
        "  lon = row[\"lon\"]\n",
        "\n",
        "  merge_warehouse_dist[f\"haversine_dist_{wh}\"] = merge_warehouse_dist.apply(lambda row:\n",
        "                                                                    haversine_dist(row[\"customer_lat\"],\n",
        "                                                                             row[\"customer_long\"],\n",
        "                                                                             lat,\n",
        "                                                                             lon),\n",
        "                                                                  axis=1)\n",
        "\n",
        "# Get the nearest warehouse name\n",
        "distance_cols = [f\"haversine_dist_{wh}\" for wh in warehouse_data[\"names\"]]\n",
        "merge_warehouse_dist[distance_cols] = merge_warehouse_dist[distance_cols].apply(lambda x: np.around(x, 4))\n",
        "merge_warehouse_dist[\"actual_nearest_distance\"] = merge_warehouse_dist[distance_cols].min(axis=1)\n",
        "merge_warehouse_dist[\"actual_nearest_warehouse\"] = (merge_warehouse_dist[distance_cols].idxmin(axis=1).str.replace(\"haversine_dist_\", \"\"))\n",
        "\n",
        "# Check if the nearest_warehouse is correct\n",
        "merge_warehouse_dist[\"is_correct\"] = (merge_warehouse_dist[\"nearest_warehouse_clean\"] == merge_warehouse_dist[\"actual_nearest_warehouse\"])\n",
        "\n",
        "# Invalid nearest_warehouse\n",
        "invalid_nearest_warehouse = merge_warehouse_dist[~merge_warehouse_dist[\"is_correct\"]]\n",
        "print(\"Number of invalid nearest warehouse:\", len(invalid_nearest_warehouse))\n",
        "print(invalid_nearest_warehouse[[\"order_id\", \"nearest_warehouse_clean\", \"distance_to_nearest_warehouse\", \"actual_nearest_warehouse\", \"actual_nearest_distance\", \"haversine_dist_Thompson\", \"haversine_dist_Nickolson\", \"haversine_dist_Bakers\"]].to_string(index=False))\n",
        "\n",
        "# Check if any rows for distance_to_nearest_warehouse is exactly the same as actual_nearest_distance\n",
        "distance_check = invalid_nearest_warehouse[\"distance_to_nearest_warehouse\"] == invalid_nearest_warehouse[\"actual_nearest_distance\"]\n",
        "print(\"Number of incorrect nearest warehouse distance:\", len(distance_check[~distance_check]))"
      ],
      "metadata": {
        "id": "WsHEvg4HNlgL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb1e343-dd83-463d-c315-68c504be595a"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of invalid nearest warehouse: 20\n",
            " order_id nearest_warehouse_clean  distance_to_nearest_warehouse actual_nearest_warehouse  actual_nearest_distance  haversine_dist_Thompson  haversine_dist_Nickolson  haversine_dist_Bakers\n",
            "ORD237879               Nickolson                         1.7391                 Thompson                   1.7391                   1.7391                    3.6471                 5.3839\n",
            "ORD052629               Nickolson                         1.3297                   Bakers                   1.3297                   4.6427                    2.5795                 1.3297\n",
            "ORD461915               Nickolson                         0.2395                 Thompson                   0.2395                   0.2395                    1.8613                 4.0736\n",
            "ORD069936                Thompson                         1.3319                Nickolson                   1.3319                   1.7608                    1.3319                 2.6129\n",
            "ORD461426                  Bakers                         0.5820                 Thompson                   0.5820                   0.5820                    2.2637                 4.1648\n",
            "ORD015774               Nickolson                         1.3010                 Thompson                   1.3010                   1.3010                    1.6266                 3.1694\n",
            "ORD120949                  Bakers                         1.8651                 Thompson                   1.8651                   1.8651                    1.9849                 2.9928\n",
            "ORD216010                Thompson                         0.5591                   Bakers                   0.5591                   3.6907                    1.9608                 0.5591\n",
            "ORD138742                  Bakers                         0.8358                 Thompson                   0.8358                   0.8358                    2.4393                 4.2215\n",
            "ORD334316                Thompson                         1.3077                Nickolson                   1.3077                   3.3678                    1.3077                 2.0203\n",
            "ORD081635                Thompson                         1.5006                Nickolson                   1.5006                   3.5751                    1.5006                 1.8777\n",
            "ORD025929                  Bakers                         1.1455                 Thompson                   1.1455                   1.1455                    1.2262                 3.1128\n",
            "ORD201338               Nickolson                         1.9221                 Thompson                   1.9221                   1.9221                    2.1634                 3.1210\n",
            "ORD436885               Nickolson                         0.9019                   Bakers                   0.9019                   4.0721                    2.6394                 0.9019\n",
            "ORD224300               Nickolson                         0.5770                 Thompson                   0.5770                   0.5770                    2.1365                 4.0352\n",
            "ORD471229                Thompson                         0.7914                Nickolson                   0.7914                   1.6077                    0.7914                 3.2438\n",
            "ORD164906                Thompson                         1.1056                Nickolson                   1.1056                   1.5318                    1.1056                 2.7414\n",
            "ORD118183                Thompson                         0.4986                   Bakers                   0.4986                   3.8075                    1.9601                 0.4986\n",
            "ORD300512                Thompson                         0.9582                   Bakers                   0.9582                   3.5992                    1.6211                 0.9582\n",
            "ORD426908                  Bakers                         1.2880                 Thompson                   1.2880                   1.2880                    3.3634                 5.3917\n",
            "Number of incorrect nearest warehouse distance: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nearest_warehouse Validation - Interpretation:**\n",
        "\n",
        "By recalculating the Haversine distance from each customer's coordinates to all three warehouses, 20 orders were identified with incorrect nearest_warehouse assignments. The recorded warehouse name does not match the actual geographically nearest warehouse, even though the distance_to_nearest_warehouse value itself was correct. The consistency in distance_to_nearest_warehouse values suggests that the error lies in the categorical warehouse name rather than in the numeric distance calculation.\n",
        "\n",
        "**Justification:**\n",
        "\n",
        "This ensures geospatial consistency between the warehouse name and the computed minimum distance. The method calculates the distance from each customer to every warehouse using the Haversine formula and determines the true nearest location by identifying the minimum value across all warehouses. Rows where the stored nearest_warehouse does not match this computed result are flagged as incorrect. The comparison between distance_to_nearest_warehouse and actual_nearest_distance confirms that it is a categorical mislabelling rather than a distance computation error."
      ],
      "metadata": {
        "id": "YNGIZH3-QSXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if is_happy_customer is correct using SentimentIntensityAnalyzer\n",
        "# Extract the necessary columns and replace missing values with empty string\n",
        "is_happy_check = dirty_data[[\"order_id\", \"customer_id\", \"is_happy_customer\", \"latest_customer_review\"]].copy()\n",
        "is_happy_check[\"latest_customer_review\"] = is_happy_check[\"latest_customer_review\"].fillna(\"\").astype(str)\n",
        "\n",
        "# Apply sentiment analysis to each row of latest_review_customer and return the compound_score but None if it is an empty string\n",
        "is_happy_check[\"compound_score\"] = is_happy_check[\"latest_customer_review\"].apply(lambda row: sia.polarity_scores(row)[\"compound\"]\n",
        "                                                                                  if row.strip() != \"\"\n",
        "                                                                                  else None)\n",
        "\n",
        "# Create a column to store True when compound_score is more than 0.05 or is an empty string\n",
        "is_happy_check[\"happy_prediction\"] = is_happy_check.apply(lambda row: True\n",
        "                                                          if row[\"latest_customer_review\"].strip() == \"\"\n",
        "                                                          else row[\"compound_score\"] >= 0.05,\n",
        "                                                          axis=1)\n",
        "\n",
        "# Check if is_happy_customer aligns with latest_review_customer\n",
        "is_happy_check[\"is_correct\"] = is_happy_check[\"happy_prediction\"] == is_happy_check[\"is_happy_customer\"]\n",
        "\n",
        "# Invalid is_happy_customer\n",
        "invalid_sentiment = is_happy_check[~is_happy_check[\"is_correct\"]]\n",
        "print(\"Number of invalid sentiment labels:\", len(invalid_sentiment))\n",
        "print(invalid_sentiment[[\"order_id\", \"latest_customer_review\", \"is_happy_customer\", \"compound_score\", \"happy_prediction\", \"is_correct\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "9U_I_EAEN50v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d92ed66-a51c-45ba-c5b4-f2846010ffe4"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of invalid sentiment labels: 27\n",
            " order_id                                                                                                                                                                                                                                                      latest_customer_review  is_happy_customer  compound_score  happy_prediction  is_correct\n",
            "ORD216249                                                                                                          battery runs low fast the phone works fine, although the battery runs out fast and you have to charge it a lot .i like the phone but wish the battery didn't suck.              False          0.8052              True       False\n",
            "ORD412492                                                                                                                                                                                                                                      nice i don't see any problems with it.              False          0.6197              True       False\n",
            "ORD457652                                                                                                                                                                                                                                                            five stars great              False          0.6249              True       False\n",
            "ORD066764                                                                                                                               good phone. i love this phone. toshika is doing a great job. just to be tweaking the next model to have a faster ship and a higher roslution.              False          0.9042              True       False\n",
            "ORD352239                                                                                                                                                                                                                                    four stars my son like it so far so good              False          0.7629              True       False\n",
            "ORD268941                                                                                                                                          great phone i love it, the screen has a great quality and the battery get almost all day, stay charged fast and had a good camera.              False          0.9382              True       False\n",
            "ORD478343                                                                                                                                                                                                                             doesn't have support to sdcard great cell phone              False          0.4295              True       False\n",
            "ORD064373                                                                                                                                         perfect phone, fast shipping other than the packaging, you would think this phone was new! perfect phone, fast shipping, thank you.              False          0.8805              True       False\n",
            "ORD370767             note 8 - 5 stars received a note 8 from this seller in mint condition. not a scratch or dent anywhere. phone works perfectly. was a little nervous about buying a pre owned phone online but so glad i did. saved a lot of money and its practically brand new.              False          0.9116              True       False\n",
            "ORD252102 defective screen phone has black lines across screen. spoke with olivia which referred me to their repair place. i was informed that the screen would need to be replaced with a genuine screen for about $280. my bad for purchasing a used \"certified refurbished\" phone.               True         -0.7506             False       False\n",
            "ORD330702                                                                                                                                                                                                           for the price: amazing. the screen is just great. really fast to.              False          0.8360              True       False\n",
            "ORD408565                                                                                                                                                                                                                     five stars it arrived when promised and work very well.              False          0.5984              True       False\n",
            "ORD480194                                                                                                                                                                                                                                                              its good!              False          0.4926              True       False\n",
            "ORD494528                                                                                                                                                                                                                                                          five stars love it              False          0.6369              True       False\n",
            "ORD083198                                                   phone not so good the phone is nice but i can't use my t-moble data and i also wanted the locked phone witch is what i payed for but it was unlocked so i can't use wifi calling that's another reason i bought the phone               True         -0.5210             False       False\n",
            "ORD241933                                                                                                                                                                                                                                             one star a total waste of money               True         -0.4215             False       False\n",
            "ORD246197                                                                                                                                                                                                      but a good solid phone a little fat and heavy, but a good solid phone.              False          0.8885              True       False\n",
            "ORD208028                                                                                                                                          works great. saved about $300 from new to this refurbished works great. saved about $300 from new to this refurbished. looked new.              False          0.9300              True       False\n",
            "ORD251878                                                                                                                                                                                                                                    works great! fast shipping! works great!              False          0.8772              True       False\n",
            "ORD405488                                                                                                                                                                                four stars excellent phone but the cable does not last.. a better cable would gave been nice              False          0.4480              True       False\n",
            "ORD115461                                                                                                                                          ... what he had to do to make the customer happy awsome really kind did what he had to do to make the customer happy awsome person              False          0.9020              True       False\n",
            "ORD363854                                                                                                                                                                                                              tuve una duda y respondieron muy rpidamente. todo funciona ok              False          0.2960              True       False\n",
            "ORD435481                                                                                                                                                                                                                                              speaker could be better qualty              False          0.4404              True       False\n",
            "ORD256544                                                 great phone. get sim from sprint service store. great phone. came in great shape. don't try to get a sim by calling sprint. goto a sprint store with a service center.now that i have the sim. works great.love this phone.              False          0.9231              True       False\n",
            "ORD319183                                                                                                                                                                                                                        get it! great alcon. love how easy it was to set up.              False          0.9098              True       False\n",
            "ORD102139                                                                                                                                                                                                                                                        five stars excellent              False          0.5719              True       False\n",
            "ORD366292                                                                                                   no longer compatible. i received this phone yesterday. took it to the verizon corporate store today and was advised that this model is no longer compatible with verizon.               True         -0.5267             False       False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Is_happy_customer Validation - Interpretation:**\n",
        "\n",
        "The sentiment analysis comparison revealed 27 mismatched rows where the recorded is_happy_customer label does not align with the predicted sentiment derived from the latest_customer_review. The compound sentiment scores, generated by the SentimentIntensityAnalyzer, ranging from 0.2 to 0.9 for positive reviews and below -0.4 for negative ones. These inconsistencies suggest errors during manual or automated label assignment in the raw dataset.\n",
        "\n",
        "**Justification:**\n",
        "\n",
        "To verify the correctness of the is_happy_customer field, each customer review was analysed using the VADER SentimentIntensityAnalyzer, which assigns a compound_score representing the polarity of the review text. A score of  0.05 indicates positive sentiment (True), while lower scores indicate negative sentiment (False). Empty reviews were assumed positive, following the datasets business rule that customers without complaints are considered satisfied. Detection of these mismatches are crucial for modelling that relate customer happiness to delivery performance and product quality.\n"
      ],
      "metadata": {
        "id": "v39VFuwOTqd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1.3 Dirty Data Fix"
      ],
      "metadata": {
        "id": "uQnfRh3J7Fv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a duplicate of dirty_data to clean\n",
        "clean_data = dirty_data.copy()\n",
        "\n",
        "# Create fix log\n",
        "fix_log = pd.DataFrame(columns=[\"order_id\", \"error_type\"])"
      ],
      "metadata": {
        "id": "W7wX74A9gmnb"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Backup - Justification:**\n",
        "\n",
        "Storing the raw data preserves a reference point for all subsequent data-cleaning operations. Maintaining an unaltered copy ensures that any modifications can be traced back to the original records, supporting transparency and reproducibility. A fix log is created to systematically record each detected anomaly and the corresponding correction applied. Every fixed rows is will be logged into fix log, which tracks the order_id and corresponding error_type. The fixed rows listed in fix log will be excluded from further processing to maintain the single-fault assumption."
      ],
      "metadata": {
        "id": "fE9hUBNYUgK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix season and casing based on date\n",
        "# Extract the unfixed data\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])]\n",
        "\n",
        "# Parse date to datetime data type and extract month\n",
        "unfixed_data[\"date\"] = pd.to_datetime(unfixed_data[\"date\"], errors=\"coerce\")\n",
        "unfixed_data[\"month\"]= unfixed_data[\"date\"].dt.month\n",
        "\n",
        "# Mapping for month to season\n",
        "season_map = {12: \"Summer\", 1: \"Summer\", 2: \"Summer\",\n",
        "              3: \"Autumn\", 4: \"Autumn\", 5: \"Autumn\",\n",
        "              6: \"Winter\", 7: \"Winter\", 8: \"Winter\",\n",
        "              9: \"Spring\", 10: \"Spring\", 11: \"Spring\"}\n",
        "\n",
        "unfixed_data[\"season_clean\"] = unfixed_data[\"month\"].map(season_map)\n",
        "\n",
        "unfixed_data[\"season_clean\"] = np.where(\n",
        "    unfixed_data[\"month\"].isna(),\n",
        "    unfixed_data[\"season\"],\n",
        "    unfixed_data[\"season_clean\"]\n",
        ")\n",
        "\n",
        "# Mismatched season\n",
        "season_mismatch = (unfixed_data[\"month\"].notna() &\n",
        "                   (unfixed_data[\"season\"] != unfixed_data[\"season_clean\"]))\n",
        "print(\"Number of mismatched seasons:\", season_mismatch.sum())\n",
        "\n",
        "# Replace the invalid rows with the correct values\n",
        "clean_data.loc[season_mismatch, \"season\"] = unfixed_data.loc[season_mismatch, \"season_clean\"]\n",
        "\n",
        "# Log the order_id for fixed rows\n",
        "fixed_ids = unfixed_data.loc[season_mismatch, \"order_id\"]\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Incorrect season\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[unfixed_data.loc[season_mismatch].index, [\"order_id\", \"date\", \"season\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "zsMqticyflF0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f19a797-e4d3-4a04-b24f-dca741e811af"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mismatched seasons: 27\n",
            "Fixed 27 rows.\n",
            " order_id       date season\n",
            "ORD209240 2019-02-07 Summer\n",
            "ORD419503 2019-09-21 Spring\n",
            "ORD277275 2019-12-26 Summer\n",
            "ORD123382 2019-01-06 Summer\n",
            "ORD209230 2019-09-03 Spring\n",
            "ORD132264 2019-10-14 Spring\n",
            "ORD192930 2019-08-30 Winter\n",
            "ORD172628 2019-03-30 Autumn\n",
            "ORD103002 2019-10-17 Spring\n",
            "ORD040501 2019-10-17 Spring\n",
            "ORD344249 2019-10-23 Spring\n",
            "ORD222038 2019-11-04 Spring\n",
            "ORD026633 2019-01-16 Summer\n",
            "ORD377228 2019-09-24 Spring\n",
            "ORD455600 2019-02-18 Summer\n",
            "ORD468030 2019-05-06 Autumn\n",
            "ORD478782 2019-07-26 Winter\n",
            "ORD363647 2019-12-01 Summer\n",
            "ORD345384 2019-11-25 Spring\n",
            "ORD127439 2019-07-25 Winter\n",
            "ORD493849 2019-04-24 Autumn\n",
            "ORD492808 2019-08-07 Winter\n",
            "ORD495324 2019-07-10 Winter\n",
            "ORD385926 2019-09-10 Spring\n",
            "ORD462038 2019-07-10 Winter\n",
            "ORD434426 2019-06-14 Winter\n",
            "ORD387883 2019-10-20 Spring\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Season fix - Justification:**\n",
        "\n",
        "The correct season is derived directly from the date column using the Australian calendar. Dates were converted to the datetime format, and months were mapped to their respective seasons. A total of 21 rows with mismatched date-season pairs were corrected using this mapping. After ensuring date-season consistency, the 6 rows with improper text casing is standardised to proper capitalisation. A total of 27 rows were fixed and logged as \"Incorrect season\" in the fix_log."
      ],
      "metadata": {
        "id": "b-YHv2vnVmX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix date\n",
        "# Extract the unfixed data\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "\n",
        "# Mapping for season to date\n",
        "date_map = {\n",
        "    \"Summer\": \"2019-01-15\",\n",
        "    \"Autumn\": \"2019-04-15\",\n",
        "    \"Winter\": \"2019-07-15\",\n",
        "    \"Spring\": \"2019-10-15\"\n",
        "}\n",
        "\n",
        "# Missing date value\n",
        "missing_date = unfixed_data[\"date\"].isna()\n",
        "print(\"Number of missing dates:\", missing_date.sum())\n",
        "\n",
        "# Extract the missing date index\n",
        "date_index = unfixed_data.index[missing_date]\n",
        "\n",
        "# Map the missing date to date_map\n",
        "correct_date = pd.to_datetime(unfixed_data.loc[date_index, \"season\"].map(date_map), errors=\"coerce\")\n",
        "\n",
        "# Replace the invalid rows with the correct values\n",
        "clean_data.loc[date_index, \"date\"] = correct_date\n",
        "\n",
        "# Log the order_id for fixed rows\n",
        "fixed_ids = unfixed_data.loc[date_index, \"order_id\"]\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Missing date\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[date_index, [\"order_id\", \"date\", \"season\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "06icfMdpjQ0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d9f9d68-2015-4034-dd21-6be27b32c12a"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of missing dates: 27\n",
            "Fixed 27 rows.\n",
            " order_id       date season\n",
            "ORD164387 2019-01-15 Summer\n",
            "ORD066446 2019-07-15 Winter\n",
            "ORD312565 2019-01-15 Summer\n",
            "ORD181051 2019-01-15 Summer\n",
            "ORD046408 2019-10-15 Spring\n",
            "ORD219265 2019-07-15 Winter\n",
            "ORD006455 2019-10-15 Spring\n",
            "ORD084861 2019-07-15 Winter\n",
            "ORD438655 2019-01-15 Summer\n",
            "ORD234563 2019-10-15 Spring\n",
            "ORD199817 2019-01-15 Summer\n",
            "ORD113549 2019-04-15 Autumn\n",
            "ORD489756 2019-10-15 Spring\n",
            "ORD273300 2019-10-15 Spring\n",
            "ORD194653 2019-01-15 Summer\n",
            "ORD480775 2019-10-15 Spring\n",
            "ORD160619 2019-07-15 Winter\n",
            "ORD402436 2019-04-15 Autumn\n",
            "ORD311888 2019-04-15 Autumn\n",
            "ORD491911 2019-07-15 Winter\n",
            "ORD265708 2019-01-15 Summer\n",
            "ORD060082 2019-01-15 Summer\n",
            "ORD469475 2019-01-15 Summer\n",
            "ORD461231 2019-07-15 Winter\n",
            "ORD047863 2019-04-15 Autumn\n",
            "ORD499923 2019-10-15 Spring\n",
            "ORD036565 2019-10-15 Spring\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Date fix - Justification:**\n",
        "\n",
        "The date column was fixed by filling missing values based on each record's season. Since the dataset represents 2019 transactions, a mapping (Summer  2019-01-15, Autumn  2019-04-15, Winter  2019-07-15, Spring  2019-10-15) was applied to assign a representative mid-season date for each missing entry. This approach ensures temporal consistency and preserves the logical relationship between date and season when the original date was unavailable. A total of 27 rows were fixed and logged as \"Missing date\" in the fix_log."
      ],
      "metadata": {
        "id": "0afnYcfTZJuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix customer_lat and customer_long\n",
        "# Extract the unfixed data\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "\n",
        "# Swapped coordinates\n",
        "swapped_coords = (unfixed_data[\"customer_lat\"].between(-180, 180) &\n",
        "                  unfixed_data[\"customer_long\"].between(-90, 90))\n",
        "print(\"Number of swapped coordinates:\", swapped_coords.sum())\n",
        "\n",
        "swapped_coords_index = unfixed_data.index[swapped_coords]\n",
        "\n",
        "# Replace the invalid rows with the correct values\n",
        "clean_data.loc[swapped_coords_index, [\"customer_lat\", \"customer_long\"]] = (clean_data.loc[swapped_coords_index, [\"customer_long\", \"customer_lat\"]].to_numpy())\n",
        "\n",
        "# Log the order_id for fixed rows\n",
        "fixed_ids = clean_data.loc[swapped_coords_index, \"order_id\"].tolist()\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Swapped coordinates\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[swapped_coords_index, [\"order_id\", \"customer_lat\", \"customer_long\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "eJhNodJGmP9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a72ced8-f83b-4647-be2b-5f74fee3c7ea"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of swapped coordinates: 27\n",
            "Fixed 27 rows.\n",
            " order_id  customer_lat  customer_long\n",
            "ORD091929    -37.815878     144.959364\n",
            "ORD299508    -37.823816     145.009445\n",
            "ORD074143    -37.819701     144.960234\n",
            "ORD392203    -37.812101     144.973944\n",
            "ORD208957    -37.810785     144.977354\n",
            "ORD090831    -37.797624     144.993262\n",
            "ORD062280    -37.816990     144.961790\n",
            "ORD155978    -37.824991     144.949411\n",
            "ORD493957    -37.801182     144.976899\n",
            "ORD083244    -37.818479     144.977813\n",
            "ORD373348    -37.793879     144.985178\n",
            "ORD055195    -37.806415     144.983469\n",
            "ORD125480    -37.810368     144.961303\n",
            "ORD285476    -37.802954     144.935968\n",
            "ORD349254    -37.805420     144.947587\n",
            "ORD048052    -37.801171     145.004517\n",
            "ORD479919    -37.815613     144.977507\n",
            "ORD326763    -37.805420     144.928230\n",
            "ORD442562    -37.820067     144.968618\n",
            "ORD063341    -37.827219     144.988143\n",
            "ORD012510    -37.799791     144.954950\n",
            "ORD070213    -37.801354     144.946328\n",
            "ORD481618    -37.816652     144.988204\n",
            "ORD202182    -37.809350     144.931580\n",
            "ORD396842    -37.809694     144.972599\n",
            "ORD130131    -37.796916     144.964657\n",
            "ORD201885    -37.813794     144.968469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Geographical Coordinates Fix - Justification:**\n",
        "\n",
        "The customer_lat and customer_long columns were corrected by identifying rows where latitude and longitude values were likely swapped. Normally, latitude values should range between -90 and 90, while longitude values fall between -180 and 180. Rows where latitude was within the longitude range (-180 to 180) and longitude within the latitude range (-90 to 90) were flagged as swapped. For these records, the coordinates were exchanged to their correct positions, ensuring geographical validity and consistency with expected coordinate ranges. A total of 27 rows were fixed and logged as Swapped coordinates in the fix_log."
      ],
      "metadata": {
        "id": "AjKN1pfqZlzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix nearest_warehouse\n",
        "# 1. Actual nearest warehouse\n",
        "# Extract the unfixed data\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "unfixed_index = unfixed_data.index\n",
        "\n",
        "# Extract the original nearest_warehouse and the actual nearest_warehouse in stripped string format\n",
        "ori_wh = merge_warehouse_dist.loc[unfixed_index, \"nearest_warehouse_clean\"].astype(str).str.strip()\n",
        "actual_wh = merge_warehouse_dist.loc[unfixed_index, \"actual_nearest_warehouse\"].astype(str).str.strip()\n",
        "\n",
        "incorrect_wh = (ori_wh != actual_wh)\n",
        "\n",
        "# Extract rows with incorrect nearest_warehouse but correct distance_to_nearest_warehouse\n",
        "correct_dist = ((merge_warehouse_dist.loc[unfixed_index, \"distance_to_nearest_warehouse\"] -\n",
        "                 merge_warehouse_dist.loc[unfixed_index, \"actual_nearest_distance\"]).abs() <= 0)\n",
        "\n",
        "# Invalid nearest_warehouse\n",
        "wh_fix = incorrect_wh & correct_dist\n",
        "incorrect_wh_index = merge_warehouse_dist.loc[unfixed_index].index[wh_fix]\n",
        "print(\"Number of incorrect nearest warehouse name:\", len(incorrect_wh_index))\n",
        "\n",
        "# Replace the invalid rows with the correct values\n",
        "clean_data.loc[incorrect_wh_index, \"nearest_warehouse\"] = (merge_warehouse_dist.loc[incorrect_wh_index, \"actual_nearest_warehouse\"].values)\n",
        "\n",
        "# Log the order_id for fixed rows\n",
        "fixed_ids = clean_data.loc[incorrect_wh_index, \"order_id\"].values\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Incorrect nearest_warehouse\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[incorrect_wh_index, [\"order_id\", \"nearest_warehouse\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "XslGFsSolw2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a4e00e9-2c15-4851-a150-884ac9efa691"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of incorrect nearest warehouse name: 20\n",
            "Fixed 20 rows.\n",
            " order_id nearest_warehouse\n",
            "ORD237879          Thompson\n",
            "ORD052629            Bakers\n",
            "ORD461915          Thompson\n",
            "ORD069936         Nickolson\n",
            "ORD461426          Thompson\n",
            "ORD015774          Thompson\n",
            "ORD120949          Thompson\n",
            "ORD216010            Bakers\n",
            "ORD138742          Thompson\n",
            "ORD334316         Nickolson\n",
            "ORD081635         Nickolson\n",
            "ORD025929          Thompson\n",
            "ORD201338          Thompson\n",
            "ORD436885            Bakers\n",
            "ORD224300          Thompson\n",
            "ORD471229         Nickolson\n",
            "ORD164906         Nickolson\n",
            "ORD118183            Bakers\n",
            "ORD300512            Bakers\n",
            "ORD426908          Thompson\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nearest_warehouse Fix - Justification:**\n",
        "\n",
        "The nearest_warehouse column was corrected by verifying each customer's recorded warehouse against the actual nearest warehouse computed using the Haversine distance. Rows where the nearest_warehouse name differed from the calculated nearest one were identified as incorrect, but only those with a correct distance_to_nearest_warehouse value were updated to prevent cascading errors. The warehouse names were then replaced with the accurate ones derived from distance calculations. A total of 20 rows were corrected and logged under Incorrect nearest_warehouse, ensuring each order now correctly reflects its true nearest warehouse location."
      ],
      "metadata": {
        "id": "FGcTNhn_aQGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix distance_to_nearest_warehouse\n",
        "# Haversine distance\n",
        "# Extract the unfixed data\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "unfixed_index = unfixed_data.index\n",
        "\n",
        "# Extract the original nearest_warehouse and the actual nearest_warehouse in stripped string format\n",
        "ori_wh = merge_warehouse_dist.loc[unfixed_index, \"nearest_warehouse_clean\"].astype(str).str.strip()\n",
        "actual_wh = merge_warehouse_dist.loc[unfixed_index, \"actual_nearest_warehouse\"].astype(str).str.strip()\n",
        "\n",
        "correct_wh = (ori_wh == actual_wh)\n",
        "\n",
        "# Extract the actual nearest_warehouse distance in unfixed data only\n",
        "actual_nearest_distance = np.around(merge_warehouse_dist.loc[unfixed_index, \"actual_nearest_distance\"].values, 4)\n",
        "\n",
        "# Extract the original distance_to_nearest_warehouse\n",
        "ori_distance = merge_warehouse_dist.loc[unfixed_index, \"distance_to_nearest_warehouse\"].values\n",
        "\n",
        "# Calculate the distance difference\n",
        "mismatch_dist = np.abs(ori_distance - actual_nearest_distance) > 0.1\n",
        "\n",
        "# Invalid distance_to_nearest_warehouse\n",
        "dist_fix = correct_wh & mismatch_dist\n",
        "incorrect_dist_index = merge_warehouse_dist.loc[unfixed_index].index[dist_fix]\n",
        "print(\"Number of incorrect distance to nearest warehouse:\", len(incorrect_dist_index))\n",
        "\n",
        "# Replace the invalid rows with the correct values\n",
        "clean_data.loc[incorrect_dist_index, \"distance_to_nearest_warehouse\"] = (merge_warehouse_dist.loc[incorrect_dist_index, \"actual_nearest_distance\"].values)\n",
        "\n",
        "# Log the order_id for fixed rows\n",
        "fixed_ids = clean_data.loc[incorrect_dist_index, \"order_id\"].values\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Incorrect distance_to_nearest_warehouse\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[incorrect_dist_index, [\"order_id\", \"distance_to_nearest_warehouse\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "aQKjKRWDpWGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56c301a9-145d-4147-a0bd-61a61662b50b"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of incorrect distance to nearest warehouse: 23\n",
            "Fixed 23 rows.\n",
            " order_id  distance_to_nearest_warehouse\n",
            "ORD418280                         0.7663\n",
            "ORD020055                         1.4421\n",
            "ORD483341                         0.9439\n",
            "ORD106152                         1.1906\n",
            "ORD177750                         1.8275\n",
            "ORD452867                         0.8989\n",
            "ORD393540                         1.6016\n",
            "ORD135624                         1.7146\n",
            "ORD471922                         1.8650\n",
            "ORD385052                         0.8499\n",
            "ORD307211                         1.1409\n",
            "ORD227802                         0.8424\n",
            "ORD041333                         0.6523\n",
            "ORD378423                         0.9532\n",
            "ORD321986                         1.1383\n",
            "ORD205213                         0.3711\n",
            "ORD440634                         0.7465\n",
            "ORD416698                         2.7735\n",
            "ORD049973                         0.8999\n",
            "ORD005273                         0.8712\n",
            "ORD048269                         0.9092\n",
            "ORD175303                         1.6706\n",
            "ORD223207                         0.8378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distance_to_nearest_warehouse Fix - Justification:**\n",
        "\n",
        "The distance_to_nearest_warehouse column was fixed by recalculating the true Haversine distance between each customer's coordinates and their nearest warehouse. For each record where the warehouse name was already verified as correct, the stored distance was compared with the computed actual distance. Rows showing a deviation greater than 0.1 km were flagged as inaccurate and updated with the precise recalculated values. A total of 23 rows were corrected and recorded in the fix_log under Incorrect distance_to_nearest_warehouse.\n"
      ],
      "metadata": {
        "id": "7iqx-Manal3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix nearest_warehouse\n",
        "# 2. Naming inconsistency\n",
        "# Extract the unfixed data\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "\n",
        "# Extract the warehouse name from warehouse.csv\n",
        "valid_names = warehouse_data[\"names\"].str.strip().str.title()\n",
        "\n",
        "# Invalid nearest_warehouse\n",
        "invalid_names = ~unfixed_data[\"nearest_warehouse\"].astype(str).str.strip().isin(valid_names)\n",
        "invalid_name_index = unfixed_data.index[invalid_names]\n",
        "print(\"Number of invalid warehouse names:\", len(invalid_name_index))\n",
        "\n",
        "# Replace the invalid rows with correct values\n",
        "clean_data.loc[invalid_name_index, \"nearest_warehouse\"] = (clean_data.loc[invalid_name_index, \"nearest_warehouse\"].astype(str).str.strip().str.title())\n",
        "\n",
        "# Log the order_id for fixed rows\n",
        "fixed_ids = clean_data.loc[invalid_name_index, \"order_id\"].values\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Inconsistent nearest_warehouse naming\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[invalid_name_index, [\"order_id\", \"nearest_warehouse\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "HsiXdwIMpWvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d348cc63-f5c7-42f3-cf06-db7ea17572ff"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of invalid warehouse names: 7\n",
            "Fixed 7 rows.\n",
            " order_id nearest_warehouse\n",
            "ORD256861          Thompson\n",
            "ORD014442          Thompson\n",
            "ORD166717          Thompson\n",
            "ORD169718         Nickolson\n",
            "ORD393258          Thompson\n",
            "ORD016571         Nickolson\n",
            "ORD099672          Thompson\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Warehouse Name Fix - Justification:**\n",
        "\n",
        "All warehouse names were compared against the valid list extracted from warehouse.csv, converting them to a consistent title-cased format using .str.title() and stripping extra spaces. This correction ensures uniform naming conventions across all records. A total of 7 were corrected and logged as Inconsistent nearest_warehouse naming in the fix_log.\n"
      ],
      "metadata": {
        "id": "9NU_jg6kbH22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Individual item price\n",
        "# Extract the fixed data\n",
        "fixed_data = clean_data[clean_data[\"order_id\"].isin(set(fix_log[\"order_id\"]))].copy()\n",
        "\n",
        "# Map the order id from fixed data to the parsed shopping_cart value\n",
        "cart_map = shopping_cart_check.set_index(\"order_id\")[\"shopping_cart_parsed\"]\n",
        "fixed_data[\"cart_parsed\"] = fixed_data[\"order_id\"].map(cart_map)\n",
        "\n",
        "# Extract all the item and the item names in shopping_cart as a list\n",
        "all_items = [item for cart in fixed_data[\"cart_parsed\"] for (item, qty) in cart]\n",
        "item_names = pd.Series(all_items).value_counts().index.tolist()\n",
        "\n",
        "# Lookup for item name with column index\n",
        "index = {n: i for i, n in enumerate(item_names)}\n",
        "K = len(item_names)\n",
        "\n",
        "# Build numerical matrices by looping through each order\n",
        "rows, targets = [], []\n",
        "for _, r in fixed_data.iterrows():\n",
        "    v = np.zeros(K)\n",
        "    for (name, qty) in r[\"cart_parsed\"]:\n",
        "        if name in index:\n",
        "            v[index[name]] += float(qty)\n",
        "            rows.append(v)\n",
        "            targets.append(float(r[\"order_price\"]))\n",
        "\n",
        "A = np.vstack(rows) # Item quantities per order\n",
        "b = np.array(targets, dtype=float) # order_price\n",
        "\n",
        "# Calculate the individual item prices with linalg\n",
        "unit_prices, *_ = np.linalg.lstsq(A, b, rcond=None)\n",
        "price_map = pd.Series(unit_prices, index=item_names).round(2)\n",
        "\n",
        "print(price_map.sort_index())"
      ],
      "metadata": {
        "id": "aOJhdDpMTfGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28969b76-0e6c-4cbe-df70-429b749b9c42"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alcon 10          8950.0\n",
            "Candle Inferno     430.0\n",
            "Lucent 330S       1230.0\n",
            "Olivia x460       1225.0\n",
            "Thunder line      2180.0\n",
            "Toshika 750       4320.0\n",
            "Universe Note     3450.0\n",
            "iAssist Line      2225.0\n",
            "iStream            150.0\n",
            "pearTV            6310.0\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shopping_cart, order_price, order_total is correct\n",
        "# Extract the unfixed data\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(set(fix_log[\"order_id\"]))].copy()\n",
        "unfixed_data[\"cart_parsed\"] = unfixed_data[\"order_id\"].map(shopping_cart_check.set_index(\"order_id\")[\"shopping_cart_parsed\"])\n",
        "\n",
        "# Calculate expected order_price with individual item price\n",
        "def order_price_check(cart):\n",
        "  '''\n",
        "  Calculates the order_price based on individual item price\n",
        "  '''\n",
        "  return round(sum(price_map[item]*float(qty) for item, qty in cart), 2)\n",
        "\n",
        "# Compute expected values based on individual item price\n",
        "unfixed_data[\"expected_order_price\"] = unfixed_data[\"cart_parsed\"].apply(order_price_check)\n",
        "unfixed_data[\"expected_order_total\"] = (unfixed_data[\"expected_order_price\"] * (1 - unfixed_data[\"coupon_discount\"]/100) + unfixed_data[\"delivery_charges\"]).round(2)\n",
        "\n",
        "# Compute the difference for order_price and order_total\n",
        "unfixed_data[\"price_diff\"] = (unfixed_data[\"expected_order_price\"] - unfixed_data[\"order_price\"]).abs().round(2)\n",
        "unfixed_data[\"total_diff\"] = (unfixed_data[\"expected_order_total\"] - unfixed_data[\"order_total\"]).abs().round(2)\n",
        "\n",
        "# Compare the expected order_price and order_total with the record and check if it matches\n",
        "unfixed_data[\"price_match\"] = unfixed_data[\"price_diff\"] <= 0\n",
        "unfixed_data[\"total_match\"] = unfixed_data[\"total_diff\"] <= 0\n",
        "\n",
        "# Mismatched rows\n",
        "mismatch_order = unfixed_data[(~unfixed_data[\"price_match\"]) | (~unfixed_data[\"total_match\"])].copy()\n",
        "\n",
        "# Output\n",
        "output = [\"order_id\", \"shopping_cart\", \"order_price\",\n",
        "        \"expected_order_price\", \"price_diff\", \"price_match\",\n",
        "        \"order_total\", \"expected_order_total\", \"total_diff\", \"total_match\"]\n",
        "\n",
        "print(f\"Rows mismatch order:\", len(mismatch_order))\n",
        "print(mismatch_order[output].to_string(index=False))"
      ],
      "metadata": {
        "id": "PnDWJJO1otKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bce66f4-5463-4c6c-8422-cbc52c6df2af"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows mismatch order: 81\n",
            " order_id                                                                        shopping_cart  order_price  expected_order_price  price_diff  price_match  order_total  expected_order_total  total_diff  total_match\n",
            "ORD012542                                            [('Thunder line', 1), ('Toshika 750', 2)]         6740               10820.0      4080.0        False      9809.79               9809.79        0.00         True\n",
            "ORD136268                                               [('Alcon 10', 2), ('iAssist Line', 2)]         2600               22350.0     19750.0        False     21331.40              21331.40        0.00         True\n",
            "ORD396615                              [('Olivia x460', 1), ('Lucent 330S', 1), ('pearTV', 2)]        14010               15075.0      1065.0        False     15151.80              15151.80        0.00         True\n",
            "ORD038061                               [('Candle Inferno', 2), ('pearTV', 1), ('iStream', 1)]         8920                7320.0      1600.0        False      7644.46               6284.46     1360.00        False\n",
            "ORD276861    [('Toshika 750', 2), ('Alcon 10', 1), ('Candle Inferno', 1), ('Thunder line', 2)]        19820               22380.0      2560.0        False     16885.78              16885.78        0.00         True\n",
            "ORD159650                                            [('Lucent 330S', 1), ('iAssist Line', 1)]         3455                3455.0         0.0         True     31975.46               3028.94    28946.52        False\n",
            "ORD105180                                                [('Universe Note', 2), ('pearTV', 1)]        13210               13210.0         0.0         True     10700.35              11957.17     1256.82        False\n",
            "ORD157781                                                 [('iStream', 2), ('Olivia x460', 2)]         3310                2750.0       560.0        False      3216.20               2684.20      532.00        False\n",
            "ORD390068                      [('Lucent 330S', 2), ('Candle Inferno', 1), ('Toshika 750', 2)]        11530               11530.0         0.0         True     20131.65              11024.52     9107.13        False\n",
            "ORD135183             [('pearTV', 2), ('Olivia x460', 2), ('Alcon 10', 1), ('Lucent 330S', 1)]        26200               25250.0       950.0        False     23659.85              22804.85      855.00        False\n",
            "ORD098805   [('iAssist Line', 2), ('Candle Inferno', 1), ('Thunder line', 1), ('Alcon 10', 1)]        16010               16010.0         0.0         True      7850.39              13718.93     5868.54        False\n",
            "ORD108147                                                [('Universe Note', 2), ('pearTV', 2)]         7760               19520.0     11760.0        False      7438.22              18610.22    11172.00        False\n",
            "ORD097415     [('Olivia x460', 2), ('Candle Inferno', 1), ('Alcon 10', 2), ('Lucent 330S', 1)]        13485               22010.0      8525.0        False     19876.99              19876.99        0.00         True\n",
            "ORD292260            [('Lucent 330S', 2), ('Toshika 750', 2), ('iStream', 1), ('Alcon 10', 2)]        33590               29150.0      4440.0        False     31975.46              27757.46     4218.00        False\n",
            "ORD286146                                           [('Toshika 750', 1), ('Universe Note', 2)]         7330               11220.0      3890.0        False      7414.65              11304.65     3890.00        False\n",
            "ORD371831                        [('Thunder line', 2), ('Toshika 750', 1), ('Olivia x460', 1)]         9905                9905.0         0.0         True     16666.90               7534.92     9131.98        False\n",
            "ORD115991                                           [('Universe Note', 1), ('Toshika 750', 2)]        12090               12090.0         0.0         True      2222.91               9139.41     6916.50        False\n",
            "ORD460642                     [('iAssist Line', 1), ('Lucent 330S', 1), ('Candle Inferno', 2)]         4315                4315.0         0.0         True     15196.80               3745.31    11451.49        False\n",
            "ORD258960                            [('Olivia x460', 2), ('pearTV', 1), ('Universe Note', 2)]        31110               15660.0     15450.0        False     28103.56              14198.56    13905.00        False\n",
            "ORD489080                          [('iAssist Line', 1), ('Candle Inferno', 2), ('pearTV', 1)]        16120                9395.0      6725.0        False     15382.43               8993.68     6388.75        False\n",
            "ORD282385        [('Alcon 10', 1), ('Olivia x460', 1), ('Lucent 330S', 1), ('Toshika 750', 2)]        31110               20045.0     11065.0        False     18133.08              18133.08        0.00         True\n",
            "ORD063030                                               [('Thunder line', 2), ('Alcon 10', 2)]        18760               22260.0      3500.0        False     14135.75              16760.75     2625.00        False\n",
            "ORD368942                       [('Universe Note', 1), ('Lucent 330S', 1), ('Olivia x460', 2)]        15970                7130.0      8840.0        False      6849.09               6849.09        0.00         True\n",
            "ORD035025                       [('Thunder line', 1), ('Olivia x460', 1), ('iAssist Line', 2)]        12940                7855.0      5085.0        False     13012.65               7927.65     5085.00        False\n",
            "ORD181929         [('Candle Inferno', 2), ('iStream', 2), ('Lucent 330S', 2), ('Alcon 10', 2)]        23485               21520.0      1965.0        False     20512.70              20512.70        0.00         True\n",
            "ORD377946                    [('Universe Note', 2), ('Candle Inferno', 2), ('Olivia x460', 2)]         3750               10210.0      6460.0        False      7748.37               7748.37        0.00         True\n",
            "ORD293767                                               [('Thunder line', 1), ('Alcon 10', 1)]        11130               11130.0         0.0         True      9867.52              11196.19     1328.67        False\n",
            "ORD070614                                          [('Universe Note', 1), ('Thunder line', 1)]        11130                5630.0      5500.0        False     10647.86               5422.86     5225.00        False\n",
            "ORD479953         [('iAssist Line', 2), ('Olivia x460', 2), ('Toshika 750', 2), ('pearTV', 2)]        23880               28160.0      4280.0        False     23948.99              28228.99     4280.00        False\n",
            "ORD431838                                [('Alcon 10', 1), ('Olivia x460', 2), ('iStream', 2)]         5630               11700.0      6070.0        False     10587.72              10587.72        0.00         True\n",
            "ORD228598                          [('Olivia x460', 1), ('Universe Note', 2), ('Alcon 10', 1)]        10350               17075.0      6725.0        False      9936.07              16324.82     6388.75        False\n",
            "ORD189464   [('iAssist Line', 2), ('Olivia x460', 1), ('Thunder line', 1), ('Lucent 330S', 2)]         8770               10315.0      1545.0        False      9355.17               9355.17        0.00         True\n",
            "ORD330007                                               [('Alcon 10', 2), ('iAssist Line', 2)]        22350               22350.0         0.0         True      9465.23              22399.00    12933.77        False\n",
            "ORD221277                                [('Olivia x460', 1), ('iStream', 1), ('Alcon 10', 2)]        11060               19275.0      8215.0        False     14513.65              14513.65        0.00         True\n",
            "ORD319958                           [('Universe Note', 2), ('Thunder line', 2), ('pearTV', 2)]        23880               23880.0         0.0         True     20605.07              22753.58     2148.51        False\n",
            "ORD294135                                          [('Candle Inferno', 2), ('Toshika 750', 2)]        33590                9500.0     24090.0        False      9103.68               9103.68        0.00         True\n",
            "ORD225804    [('Lucent 330S', 2), ('iAssist Line', 1), ('Olivia x460', 2), ('Toshika 750', 2)]        13700               15775.0      2075.0        False     10355.63              11911.88     1556.25        False\n",
            "ORD007117                             [('iStream', 2), ('Olivia x460', 1), ('Toshika 750', 2)]         4315               10165.0      5850.0        False     10270.49              10270.49        0.00         True\n",
            "ORD390858                                            [('Thunder line', 2), ('Toshika 750', 2)]        15540               13000.0      2540.0        False     14063.10              11777.10     2286.00        False\n",
            "ORD354953                                                [('iStream', 1), ('Thunder line', 1)]         9810                2330.0      7480.0        False      2174.84               2174.84        0.00         True\n",
            "ORD069151    [('Candle Inferno', 2), ('Alcon 10', 2), ('Olivia x460', 2), ('iAssist Line', 2)]        25660               25660.0         0.0         True     25220.77              24451.51      769.26        False\n",
            "ORD455667          [('Alcon 10', 1), ('iStream', 2), ('Toshika 750', 1), ('Universe Note', 2)]         1375               20470.0     19095.0        False     18494.63              18494.63        0.00         True\n",
            "ORD203938      [('Thunder line', 2), ('iStream', 1), ('Lucent 330S', 2), ('Universe Note', 2)]         5630               13870.0      8240.0        False     11850.81              11850.81        0.00         True\n",
            "ORD394587                      [('Lucent 330S', 1), ('Toshika 750', 2), ('Candle Inferno', 2)]         9650               10730.0      1080.0        False      9234.85              10260.85     1026.00        False\n",
            "ORD120331                                            [('Olivia x460', 2), ('iAssist Line', 1)]         6770                4675.0      2095.0        False      6511.35               4521.10     1990.25        False\n",
            "ORD185952                                             [('Toshika 750', 1), ('Lucent 330S', 2)]         6780                6780.0         0.0         True      2799.92               6195.12     3395.20        False\n",
            "ORD384172                          [('Olivia x460', 2), ('Alcon 10', 1), ('Universe Note', 1)]         8125               14850.0      6725.0        False      7378.09              13430.59     6052.50        False\n",
            "ORD052541                              [('Candle Inferno', 2), ('pearTV', 1), ('Alcon 10', 2)]        25070               25070.0         0.0         True     16144.61              23890.43     7745.82        False\n",
            "ORD267973                             [('iAssist Line', 2), ('Toshika 750', 2), ('pearTV', 2)]        22690               25710.0      3020.0        False     21946.02              21946.02        0.00         True\n",
            "ORD372162                                               [('Alcon 10', 2), ('Thunder line', 2)]        22260               22260.0         0.0         True     14926.57              16792.73     1866.16        False\n",
            "ORD198059                         [('iAssist Line', 2), ('Candle Inferno', 2), ('iStream', 1)]        14260                5460.0      8800.0        False     10804.93               4204.93     6600.00        False\n",
            "ORD200848                         [('Alcon 10', 1), ('Thunder line', 2), ('Universe Note', 2)]        20210               20210.0         0.0         True      7758.14              20273.34    12515.20        False\n",
            "ORD488026                                                     [('pearTV', 1), ('Alcon 10', 1)]        11175               15260.0      4085.0        False     10120.63              13797.13     3676.50        False\n",
            "ORD353697        [('Lucent 330S', 1), ('Toshika 750', 1), ('iAssist Line', 2), ('iStream', 1)]         9280               10150.0       870.0        False      7026.26               7678.76      652.50        False\n",
            "ORD486573         [('Alcon 10', 1), ('Candle Inferno', 1), ('iAssist Line', 1), ('pearTV', 2)]        15970               24225.0      8255.0        False     21901.20              21901.20        0.00         True\n",
            "ORD405673            [('iAssist Line', 1), ('iStream', 1), ('pearTV', 1), ('Thunder line', 1)]        10865               10865.0         0.0         True     30179.11               8228.93    21950.18        False\n",
            "ORD455855                                 [('pearTV', 2), ('Alcon 10', 2), ('Lucent 330S', 1)]        31750               31750.0         0.0         True     13887.67              31816.16    17928.49        False\n",
            "ORD411297                                             [('Toshika 750', 1), ('Lucent 330S', 1)]         3455                5550.0      2095.0        False      4824.72               4824.72        0.00         True\n",
            "ORD470970     [('Thunder line', 1), ('iStream', 1), ('Candle Inferno', 1), ('Toshika 750', 2)]        23880               11400.0     12480.0        False     11464.83              11464.83        0.00         True\n",
            "ORD022783 [('iAssist Line', 1), ('Thunder line', 2), ('Universe Note', 2), ('Toshika 750', 1)]        17805               17805.0         0.0         True     15349.24              13428.47     1920.77        False\n",
            "ORD363756          [('iStream', 1), ('Thunder line', 2), ('Alcon 10', 1), ('iAssist Line', 1)]        15230               15685.0       455.0        False     14999.68              14999.68        0.00         True\n",
            "ORD113541                           [('Candle Inferno', 1), ('pearTV', 1), ('Lucent 330S', 1)]        10295                7970.0      2325.0        False      7645.73               7645.73        0.00         True\n",
            "ORD153936                         [('Candle Inferno', 2), ('Toshika 750', 1), ('Alcon 10', 1)]        14130               14130.0         0.0         True     31816.16              12820.31    18995.85        False\n",
            "ORD291184          [('Olivia x460', 1), ('Candle Inferno', 2), ('Alcon 10', 1), ('pearTV', 2)]         4405               23655.0     19250.0        False     22536.94              22536.94        0.00         True\n",
            "ORD177246         [('Olivia x460', 2), ('pearTV', 2), ('Thunder line', 2), ('Lucent 330S', 1)]        22880               20660.0      2220.0        False     21819.48              19710.48     2109.00        False\n",
            "ORD421787                             [('Toshika 750', 2), ('pearTV', 2), ('iAssist Line', 1)]        23485               23485.0         0.0         True      7886.26              23579.36    15693.10        False\n",
            "ORD435347                            [('Olivia x460', 2), ('Alcon 10', 1), ('Lucent 330S', 2)]         8360               13860.0      5500.0        False      7618.09              12568.09     4950.00        False\n",
            "ORD199032      [('Toshika 750', 1), ('Universe Note', 2), ('iAssist Line', 2), ('iStream', 2)]        11175               15970.0      4795.0        False     15250.28              15250.28        0.00         True\n",
            "ORD034671        [('iStream', 1), ('Olivia x460', 2), ('Thunder line', 1), ('Lucent 330S', 2)]         7240                7240.0         0.0         True      6165.18               5499.14      666.04        False\n",
            "ORD421351                          [('iStream', 2), ('Candle Inferno', 2), ('Lucent 330S', 1)]         2390                2390.0         0.0         True      5997.22               2243.80     3753.42        False\n",
            "ORD187672             [('pearTV', 2), ('Olivia x460', 1), ('iAssist Line', 1), ('iStream', 2)]        16370               16370.0         0.0         True     11519.52              15613.34     4093.82        False\n",
            "ORD400044                    [('Candle Inferno', 2), ('Olivia x460', 1), ('Universe Note', 1)]        22575                5535.0     17040.0        False     22673.84               5633.84    17040.00        False\n",
            "ORD208094                                          [('Thunder line', 2), ('Universe Note', 1)]         6900                7810.0       910.0        False      7094.06               7094.06        0.00         True\n",
            "ORD172961 [('iAssist Line', 2), ('Olivia x460', 2), ('Candle Inferno', 1), ('Lucent 330S', 2)]        12810                9790.0      3020.0        False      9708.53               7443.53     2265.00        False\n",
            "ORD153201                         [('Universe Note', 1), ('pearTV', 2), ('Candle Inferno', 2)]        16930               16930.0         0.0         True     21946.02              14470.76     7475.26        False\n",
            "ORD496180     [('Universe Note', 2), ('Lucent 330S', 1), ('Alcon 10', 1), ('Thunder line', 1)]        19260               19260.0         0.0         True     18950.30              14523.18     4427.12        False\n",
            "ORD314406                                         [('iAssist Line', 1), ('Candle Inferno', 1)]         8535                2655.0      5880.0        False      7758.14               2466.14     5292.00        False\n",
            "ORD230545                     [('Universe Note', 2), ('Thunder line', 2), ('iAssist Line', 1)]        13485               13485.0         0.0         True      5499.14              12202.81     6703.67        False\n",
            "ORD023631 [('Candle Inferno', 2), ('Toshika 750', 1), ('Olivia x460', 2), ('Thunder line', 2)]         6960               11990.0      5030.0        False     11493.52              11493.52        0.00         True\n",
            "ORD000718                                           [('iAssist Line', 2), ('Thunder line', 2)]        22260                8810.0     13450.0        False     18988.47               7555.97    11432.50        False\n",
            "ORD089659                                          [('Lucent 330S', 1), ('Candle Inferno', 2)]         2090                2090.0         0.0         True      9508.96               2051.85     7457.11        False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shopping_cart, Order_price, Order_total Check - Justification:**\n",
        "\n",
        "Using the fixed unit prices in price_map, the code recalculates the expected pre-discount total (expected_order_price) and applies the business rule order_total = order_price * (1 - coupon_discount/100) + delivery_charges to obtain the expected final total. Any differences indicate data anomalies such as incorrect item prices, misapplied discounts, or wrongly added delivery charges."
      ],
      "metadata": {
        "id": "KBkw4vfXbv3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the mismatched rows into shopping_cart error, order_price error, order_total error\n",
        "# List out the item names\n",
        "item_names = list(price_map.index)\n",
        "\n",
        "# Function to check if row will be correct by swapping item\n",
        "def swap_item(row):\n",
        "  '''\n",
        "  Check if order_price and order_total can be correct by swapping between each item in the cart\n",
        "  '''\n",
        "  cart = row[\"cart_parsed\"]\n",
        "\n",
        "  price_diff = float(row[\"order_price\"]  - row[\"expected_order_price\"])\n",
        "  total_diff = float(row[\"order_total\"]  - row[\"expected_order_total\"])\n",
        "  discount  = 1 - float(row[\"coupon_discount\"])/100\n",
        "\n",
        "  for old_name, qty in cart:\n",
        "    old_p = float(price_map[old_name])\n",
        "    for new_name in item_names:\n",
        "      if new_name == old_name:\n",
        "        continue\n",
        "      new_p = float(price_map[new_name])\n",
        "      delta_price = (new_p - old_p) * float(qty)\n",
        "      if (round(abs(delta_price - price_diff), 2)<= 0 and\n",
        "          round(abs(delta_price * discount - total_diff), 2) <= 0):\n",
        "        return True, {\"incorrect item\": old_name, \"correct item\": new_name, \"qty\": float(qty)}\n",
        "  return False, {}\n",
        "\n",
        "# Classify the mismatched rows to their error type\n",
        "# If the item can be swapped for the row to be correct -> shopping_cart_error\n",
        "# If the order_price calculated with individual item price matches order_total -> order_price_error\n",
        "# If the order_price calculated with individual item price matches the original order_price, but order_total is incorrect -> order_total_error\n",
        "error_cat = []\n",
        "error_details = []\n",
        "\n",
        "for _, r in mismatch_order.iterrows():\n",
        "    # shopping_cart error\n",
        "    can_swap, swap_info = swap_item(r)\n",
        "    if can_swap:\n",
        "        error_cat.append(\"shopping_cart_error\")\n",
        "        error_details.append(swap_info)\n",
        "        continue\n",
        "\n",
        "    # order_price error\n",
        "    incorrect_price = abs(float(r[\"expected_order_price\"] - r[\"order_price\"])) > 0\n",
        "    correct_total = abs(float(r[\"expected_order_total\"] - r[\"order_total\"])) <= 0\n",
        "    if incorrect_price and correct_total:\n",
        "        error_cat.append(\"order_price_error\")\n",
        "        error_details.append({})\n",
        "        continue\n",
        "\n",
        "    # order_total error\n",
        "    correct_price  = not incorrect_price\n",
        "    incorrect_total = not correct_total\n",
        "    if correct_price and incorrect_total:\n",
        "        error_cat.append(\"order_total_error\")\n",
        "        error_details.append({})\n",
        "        continue\n",
        "\n",
        "    # unknown error\n",
        "    error_cat.append(\"unknown_error\")\n",
        "    error_details.append({})\n",
        "\n",
        "# Create new columns to store error_type and error_details\n",
        "mismatch_order[\"error_cat\"] = error_cat\n",
        "mismatch_order[\"error_details\"]  = error_details\n",
        "\n",
        "# Summary for error type\n",
        "error_summary = (mismatch_order[\"error_cat\"]\n",
        "                 .value_counts()\n",
        "                 .rename_axis(\"error category\")\n",
        "                 .reset_index(name=\"rows\"))\n",
        "\n",
        "# Print out the order_id and error_details for shopping_cart error\n",
        "print(error_summary.to_string(index=False))\n",
        "print(\"Detected shopping_cart error:\")\n",
        "print(mismatch_order.loc[mismatch_order[\"error_cat\"]==\"shopping_cart_error\", [\"order_id\",\"error_details\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "92sgoLA9ER-g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "935a097f-6a80-4fb5-c49f-5f877872e47e"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     error category  rows\n",
            "  order_price_error    27\n",
            "shopping_cart_error    27\n",
            "  order_total_error    27\n",
            "Detected shopping_cart error:\n",
            " order_id                                                                     error_details\n",
            "ORD038061   {'incorrect item': 'Candle Inferno', 'correct item': 'Lucent 330S', 'qty': 2.0}\n",
            "ORD157781       {'incorrect item': 'iStream', 'correct item': 'Candle Inferno', 'qty': 2.0}\n",
            "ORD135183     {'incorrect item': 'Lucent 330S', 'correct item': 'Thunder line', 'qty': 1.0}\n",
            "ORD108147        {'incorrect item': 'pearTV', 'correct item': 'Candle Inferno', 'qty': 2.0}\n",
            "ORD292260    {'incorrect item': 'Lucent 330S', 'correct item': 'Universe Note', 'qty': 2.0}\n",
            "ORD286146   {'incorrect item': 'Toshika 750', 'correct item': 'Candle Inferno', 'qty': 1.0}\n",
            "ORD258960         {'incorrect item': 'Olivia x460', 'correct item': 'Alcon 10', 'qty': 2.0}\n",
            "ORD489080        {'incorrect item': 'iAssist Line', 'correct item': 'Alcon 10', 'qty': 1.0}\n",
            "ORD063030  {'incorrect item': 'Thunder line', 'correct item': 'Candle Inferno', 'qty': 2.0}\n",
            "ORD035025           {'incorrect item': 'Olivia x460', 'correct item': 'pearTV', 'qty': 1.0}\n",
            "ORD070614       {'incorrect item': 'Universe Note', 'correct item': 'Alcon 10', 'qty': 1.0}\n",
            "ORD479953     {'incorrect item': 'Toshika 750', 'correct item': 'Thunder line', 'qty': 2.0}\n",
            "ORD228598        {'incorrect item': 'Alcon 10', 'correct item': 'iAssist Line', 'qty': 1.0}\n",
            "ORD225804         {'incorrect item': 'iAssist Line', 'correct item': 'iStream', 'qty': 1.0}\n",
            "ORD390858   {'incorrect item': 'Thunder line', 'correct item': 'Universe Note', 'qty': 2.0}\n",
            "ORD394587          {'incorrect item': 'Lucent 330S', 'correct item': 'iStream', 'qty': 1.0}\n",
            "ORD120331     {'incorrect item': 'iAssist Line', 'correct item': 'Toshika 750', 'qty': 1.0}\n",
            "ORD384172        {'incorrect item': 'Alcon 10', 'correct item': 'iAssist Line', 'qty': 1.0}\n",
            "ORD198059             {'incorrect item': 'iStream', 'correct item': 'Alcon 10', 'qty': 1.0}\n",
            "ORD488026          {'incorrect item': 'pearTV', 'correct item': 'iAssist Line', 'qty': 1.0}\n",
            "ORD353697    {'incorrect item': 'Toshika 750', 'correct item': 'Universe Note', 'qty': 1.0}\n",
            "ORD177246    {'incorrect item': 'Lucent 330S', 'correct item': 'Universe Note', 'qty': 1.0}\n",
            "ORD435347       {'incorrect item': 'Alcon 10', 'correct item': 'Universe Note', 'qty': 1.0}\n",
            "ORD400044      {'incorrect item': 'Candle Inferno', 'correct item': 'Alcon 10', 'qty': 2.0}\n",
            "ORD172961 {'incorrect item': 'Candle Inferno', 'correct item': 'Universe Note', 'qty': 1.0}\n",
            "ORD314406        {'incorrect item': 'Candle Inferno', 'correct item': 'pearTV', 'qty': 1.0}\n",
            "ORD000718        {'incorrect item': 'iAssist Line', 'correct item': 'Alcon 10', 'qty': 2.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shopping_cart, Order_price, Order_total Classification- Justification:**\n",
        "\n",
        "First, shopping_cart error is tested by checking whether swapping any one item in the parsed cart while keeping quantity fixed makes both order_price and order_total match after applying the coupon. A successful one-item swap implies the cart contains a wrong item. If no swap explains the mismatch, it checks arithmetic consistency where it checks if the recomputed expected_order_price (from unit prices * quantities) disagrees with the recorded order_price but the final order_total still matches, the row is labeled order_price_error. If order_price matches but order_total does not, it is labeled order_total_error. Anything else is unknown_error for manual review."
      ],
      "metadata": {
        "id": "Hey_LehIeXJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix shopping_cart error\n",
        "# Extract the unfixed data\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "unfixed_index = unfixed_data.index\n",
        "\n",
        "# Extract the rows with shopping_cart_error\n",
        "cart_error = (mismatch_order[\"error_cat\"] == \"shopping_cart_error\")\n",
        "cart_error_rows = mismatch_order.loc[cart_error, [\"order_id\", \"error_details\"]].copy()\n",
        "\n",
        "# Mapping of the order_id with invalid shopping_cart value to its error_details\n",
        "cart_error_swap = dict(zip(cart_error_rows[\"order_id\"], cart_error_rows[\"error_details\"]))\n",
        "\n",
        "# Function to swap item name\n",
        "def swap_shopping_cart(cart_list, old_name, new_name, qty):\n",
        "  new_list = []\n",
        "  swapped = False\n",
        "  for name, q in cart_list:\n",
        "    if (not swapped) and (name == old_name) and (float(q) == float(qty)):\n",
        "      new_list.append((new_name, q))\n",
        "      swapped = True\n",
        "    else:\n",
        "      new_list.append((name, q))\n",
        "  if not swapped:\n",
        "    for i, (n, q) in enumerate(new_list):\n",
        "      if n == old_name:\n",
        "        new_list[i] = (new_name , q)\n",
        "        swapped = True\n",
        "        break\n",
        "  return new_list, swapped\n",
        "\n",
        "# Invalid shopping_cart (item name)\n",
        "cart_fix = clean_data[\"order_id\"].isin(cart_error_swap.keys())\n",
        "cart_index = clean_data.index[cart_fix & clean_data.index.isin(unfixed_index)]\n",
        "\n",
        "# Swap the invalid item name to the correct item name in shopping_cart\n",
        "for i in cart_index:\n",
        "  old_id = clean_data.at[i, \"order_id\"]\n",
        "  info = cart_error_swap[old_id]\n",
        "  old_name = info[\"incorrect item\"]\n",
        "  new_name = info[\"correct item\"]\n",
        "  qty = info[\"qty\"]\n",
        "\n",
        "  raw = clean_data.at[i, \"shopping_cart\"]\n",
        "\n",
        "  cart_list = list(ast.literal_eval(raw))\n",
        "\n",
        "  new_cart, did_swap = swap_shopping_cart(cart_list, old_name, new_name, qty)\n",
        "  if did_swap:\n",
        "    clean_data.at[i, \"shopping_cart\"] = repr(new_cart)\n",
        "\n",
        "# Log the order_id for fixed rows\n",
        "fixed_ids = clean_data.loc[cart_index, \"order_id\"].values\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Incorrect shopping_cart\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[cart_index, [\"order_id\", \"shopping_cart\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "dQTYCH-a5sJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "600f13ac-6945-468e-9268-4442c346420d"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed 27 rows.\n",
            " order_id                                                                       shopping_cart\n",
            "ORD038061                                 [('Lucent 330S', 2), ('pearTV', 1), ('iStream', 1)]\n",
            "ORD157781                                         [('Candle Inferno', 2), ('Olivia x460', 2)]\n",
            "ORD135183           [('pearTV', 2), ('Olivia x460', 2), ('Alcon 10', 1), ('Thunder line', 1)]\n",
            "ORD108147                                       [('Universe Note', 2), ('Candle Inferno', 2)]\n",
            "ORD292260         [('Universe Note', 2), ('Toshika 750', 2), ('iStream', 1), ('Alcon 10', 2)]\n",
            "ORD286146                                       [('Candle Inferno', 1), ('Universe Note', 2)]\n",
            "ORD258960                              [('Alcon 10', 2), ('pearTV', 1), ('Universe Note', 2)]\n",
            "ORD489080                             [('Alcon 10', 1), ('Candle Inferno', 2), ('pearTV', 1)]\n",
            "ORD063030                                            [('Candle Inferno', 2), ('Alcon 10', 2)]\n",
            "ORD035025                           [('Thunder line', 1), ('pearTV', 1), ('iAssist Line', 2)]\n",
            "ORD070614                                              [('Alcon 10', 1), ('Thunder line', 1)]\n",
            "ORD479953       [('iAssist Line', 2), ('Olivia x460', 2), ('Thunder line', 2), ('pearTV', 2)]\n",
            "ORD228598                     [('Olivia x460', 1), ('Universe Note', 2), ('iAssist Line', 1)]\n",
            "ORD225804        [('Lucent 330S', 2), ('iStream', 1), ('Olivia x460', 2), ('Toshika 750', 2)]\n",
            "ORD390858                                          [('Universe Note', 2), ('Toshika 750', 2)]\n",
            "ORD394587                         [('iStream', 1), ('Toshika 750', 2), ('Candle Inferno', 2)]\n",
            "ORD120331                                            [('Olivia x460', 2), ('Toshika 750', 1)]\n",
            "ORD384172                     [('Olivia x460', 2), ('iAssist Line', 1), ('Universe Note', 1)]\n",
            "ORD198059                       [('iAssist Line', 2), ('Candle Inferno', 2), ('Alcon 10', 1)]\n",
            "ORD488026                                              [('iAssist Line', 1), ('Alcon 10', 1)]\n",
            "ORD353697     [('Lucent 330S', 1), ('Universe Note', 1), ('iAssist Line', 2), ('iStream', 1)]\n",
            "ORD177246      [('Olivia x460', 2), ('pearTV', 2), ('Thunder line', 2), ('Universe Note', 1)]\n",
            "ORD435347                      [('Olivia x460', 2), ('Universe Note', 1), ('Lucent 330S', 2)]\n",
            "ORD400044                         [('Alcon 10', 2), ('Olivia x460', 1), ('Universe Note', 1)]\n",
            "ORD172961 [('iAssist Line', 2), ('Olivia x460', 2), ('Universe Note', 1), ('Lucent 330S', 2)]\n",
            "ORD314406                                                [('iAssist Line', 1), ('pearTV', 1)]\n",
            "ORD000718                                              [('Alcon 10', 2), ('Thunder line', 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shopping_cart Fix - Justification:**\n",
        "\n",
        "A mapping order_id  error_details from the classifier is built and for each affected order, we parse the stored cart, perform a single in-place name swap, and write the corrected cart back. Each successful fix is appended to fix_log as \"Incorrect shopping_cart\"."
      ],
      "metadata": {
        "id": "ve3-cVhae0TL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix order_price\n",
        "# Extract the unfixed data\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "\n",
        "# Extract the rows with order_price_error\n",
        "price_error = (mismatch_order[\"error_cat\"] == \"order_price_error\")\n",
        "price_error_rows = set(mismatch_order.loc[price_error, \"order_id\"])\n",
        "\n",
        "# Extract the correct order_price\n",
        "price_error_unfixed = mismatch_order.loc[mismatch_order[\"order_id\"].isin(price_error_rows), [\"order_id\", \"expected_order_price\"]]\n",
        "\n",
        "# Mapping of the order_id with the correct order_price value\n",
        "expected_price_map = dict(zip(price_error_unfixed[\"order_id\"], price_error_unfixed[\"expected_order_price\"]))\n",
        "\n",
        "# Replace the invalid rows with the correct values\n",
        "price_fix = clean_data[\"order_id\"].isin(expected_price_map.keys())\n",
        "price_index = clean_data.index[price_fix]\n",
        "clean_data.loc[price_index, \"order_price\"] = (clean_data.loc[price_index, \"order_id\"].map(expected_price_map))\n",
        "\n",
        "# Log the order_id for fixed rows\n",
        "fixed_ids = clean_data.loc[price_index, \"order_id\"].values\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Incorrect order_price\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[price_index, [\"order_id\", \"order_price\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "tpIvRqbMl3w6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3484ca05-8537-4cdc-fb7a-dd74b2d3bdb3"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed 27 rows.\n",
            " order_id  order_price\n",
            "ORD012542        10820\n",
            "ORD136268        22350\n",
            "ORD396615        15075\n",
            "ORD276861        22380\n",
            "ORD097415        22010\n",
            "ORD282385        20045\n",
            "ORD368942         7130\n",
            "ORD181929        21520\n",
            "ORD377946        10210\n",
            "ORD431838        11700\n",
            "ORD189464        10315\n",
            "ORD221277        19275\n",
            "ORD294135         9500\n",
            "ORD007117        10165\n",
            "ORD354953         2330\n",
            "ORD455667        20470\n",
            "ORD203938        13870\n",
            "ORD267973        25710\n",
            "ORD486573        24225\n",
            "ORD411297         5550\n",
            "ORD470970        11400\n",
            "ORD363756        15685\n",
            "ORD113541         7970\n",
            "ORD291184        23655\n",
            "ORD199032        15970\n",
            "ORD208094         7810\n",
            "ORD023631        11990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Order_price Fix - Justification:**\n",
        "\n",
        "This fixes rows labeled order_price_error by overwriting the recorded order_price with the recomputed expected_order_price derived from unit prices * quantities. An order_id  expected_order_price map is built from the mismatch table, and update only those rows. Because the error category guarantees the final order_total was already consistent with the correct pre-discount price, we do not touch order_total. Each fix is appended to fix_log as \"Incorrect order_price\"."
      ],
      "metadata": {
        "id": "_MBzqxXwflXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix order_total\n",
        "# Extract the unfixed data\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "\n",
        "# Extract the rows with order_total_error\n",
        "total_error = (mismatch_order[\"error_cat\"] == \"order_total_error\")\n",
        "total_error_rows = set(mismatch_order.loc[total_error, \"order_id\"])\n",
        "\n",
        "# Extract the correct order_total\n",
        "total_error_unfixed = mismatch_order.loc[mismatch_order[\"order_id\"].isin(total_error_rows), [\"order_id\", \"expected_order_total\"]]\n",
        "\n",
        "# Mapping of the order_id with the correct order_total value\n",
        "expected_total_map = dict(zip(total_error_unfixed[\"order_id\"], total_error_unfixed[\"expected_order_total\"]))\n",
        "\n",
        "# Replace the invalid rows with the correct values\n",
        "total_fix = clean_data[\"order_id\"].isin(expected_total_map.keys())\n",
        "total_index = clean_data.index[total_fix]\n",
        "clean_data.loc[total_index, \"order_total\"] = (clean_data.loc[total_index, \"order_id\"].map(expected_total_map))\n",
        "\n",
        "# Log the order_id for fixed rows\n",
        "fixed_ids = clean_data.loc[total_index, \"order_id\"].values\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Incorrect order_total\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[total_index, [\"order_id\", \"order_total\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "caoo2RDUvsVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d65bed-ad72-4453-af6e-c3eacb5d5037"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed 27 rows.\n",
            " order_id  order_total\n",
            "ORD159650      3028.94\n",
            "ORD105180     11957.17\n",
            "ORD390068     11024.52\n",
            "ORD098805     13718.93\n",
            "ORD371831      7534.92\n",
            "ORD115991      9139.41\n",
            "ORD460642      3745.31\n",
            "ORD293767     11196.19\n",
            "ORD330007     22399.00\n",
            "ORD319958     22753.58\n",
            "ORD069151     24451.51\n",
            "ORD185952      6195.12\n",
            "ORD052541     23890.43\n",
            "ORD372162     16792.73\n",
            "ORD200848     20273.34\n",
            "ORD405673      8228.93\n",
            "ORD455855     31816.16\n",
            "ORD022783     13428.47\n",
            "ORD153936     12820.31\n",
            "ORD421787     23579.36\n",
            "ORD034671      5499.14\n",
            "ORD421351      2243.80\n",
            "ORD187672     15613.34\n",
            "ORD153201     14470.76\n",
            "ORD496180     14523.18\n",
            "ORD230545     12202.81\n",
            "ORD089659      2051.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Order_total Fix - Justification:**\n",
        "\n",
        "This step corrects order_total_error by recalculating the final total using the business rule (apply coupon to the pre-discount order_price, then add delivery_charges) and overwriting the recorded order_total with the computed value. All corrected order_ids are appended to fix_log as \"Incorrect order_total\"."
      ],
      "metadata": {
        "id": "9LQeI6jegEMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix is_happy_customer\n",
        "# Extract the unfixed data\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "unfixed_index = unfixed_data.index\n",
        "\n",
        "# Invalid is_happy_customer\n",
        "incorrect_happy_rows = is_happy_check.loc[~is_happy_check[\"is_correct\"], [\"order_id\", \"happy_prediction\"]]\n",
        "incorrect_happy_id = incorrect_happy_rows[\"order_id\"]\n",
        "happy_index = clean_data.index[clean_data[\"order_id\"].isin(incorrect_happy_id) & clean_data.index.isin(unfixed_index)]\n",
        "\n",
        "# Replace the invalid rows with the correct values\n",
        "happy_target = clean_data.loc[happy_index, \"order_id\"]\n",
        "happy_fix = (is_happy_check.set_index(\"order_id\").reindex(happy_target)[\"happy_prediction\"].values)\n",
        "clean_data.loc[happy_index, \"is_happy_customer\"] = happy_fix\n",
        "\n",
        "# Log the order_id for fixed rows\n",
        "fixed_ids = clean_data.loc[happy_index, \"order_id\"].values\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Incorrect is_happy_customer\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[happy_index, [\"order_id\", \"is_happy_customer\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "w_HzL6kKrTWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba52da3c-86dd-4928-9937-87117d9b5cde"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed 27 rows.\n",
            " order_id  is_happy_customer\n",
            "ORD216249               True\n",
            "ORD412492               True\n",
            "ORD457652               True\n",
            "ORD066764               True\n",
            "ORD352239               True\n",
            "ORD268941               True\n",
            "ORD478343               True\n",
            "ORD064373               True\n",
            "ORD370767               True\n",
            "ORD252102              False\n",
            "ORD330702               True\n",
            "ORD408565               True\n",
            "ORD480194               True\n",
            "ORD494528               True\n",
            "ORD083198              False\n",
            "ORD241933              False\n",
            "ORD246197               True\n",
            "ORD208028               True\n",
            "ORD251878               True\n",
            "ORD405488               True\n",
            "ORD115461               True\n",
            "ORD363854               True\n",
            "ORD435481               True\n",
            "ORD256544               True\n",
            "ORD319183               True\n",
            "ORD102139               True\n",
            "ORD366292              False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Is_happy_customer Fix - Justification:**\n",
        "\n",
        "The model's happy_prediction is pulled from the incorrect rows, then overwrites the label, and log each fix in fix_log as \"Incorrect is_happy_customer\"."
      ],
      "metadata": {
        "id": "KiXiPv8Zgs0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if is_expedited_delivery is correct with linear model\n",
        "# Extract the unfixed data\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "\n",
        "# Extract cleaned data as train_data\n",
        "train_data = clean_data[clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "\n",
        "features = [\"distance_to_nearest_warehouse\", \"is_expedited_delivery\", \"is_happy_customer\"]\n",
        "target = \"delivery_charges\"\n",
        "\n",
        "# Dictionary of models and r2 score by season\n",
        "models = {}\n",
        "r2_scores = {}\n",
        "\n",
        "# Train model based on season\n",
        "for season in train_data[\"season\"].unique():\n",
        "  season_data = train_data[train_data[\"season\"] == season].copy()\n",
        "\n",
        "  x = season_data[features]\n",
        "  y = season_data[target]\n",
        "\n",
        "  model = LinearRegression()\n",
        "  model.fit(x,y)\n",
        "\n",
        "  r2 = model.score(x, y)\n",
        "\n",
        "  models[season] = model\n",
        "  r2_scores[season] = r2\n",
        "\n",
        "  print(f\"R2 score for {season} model trained = {r2:.5f}\")\n",
        "\n",
        "# Function to apply linear model for prediction\n",
        "def predict_delivery(row):\n",
        "    model = models[row[\"season\"]]\n",
        "    x_row = pd.DataFrame(\n",
        "        [[row[\"distance_to_nearest_warehouse\"],\n",
        "          int(row[\"is_expedited_delivery\"]),\n",
        "          int(row[\"is_happy_customer\"])]],\n",
        "        columns = features)\n",
        "    return model.predict(x_row)[0]\n",
        "\n",
        "# Predict is_expedited_delivery with the linear model\n",
        "unfixed_data[\"predicted_delivery_charges\"] = unfixed_data.apply(predict_delivery, axis=1)\n",
        "unfixed_data[\"delivery_error\"] = unfixed_data[\"delivery_charges\"] - unfixed_data[\"predicted_delivery_charges\"]\n",
        "\n",
        "# Calculate the tolerance for delivery_error using Median Absolute Deviation (MAD)\n",
        "tolerance_dict = {}\n",
        "\n",
        "for season, model in models.items():\n",
        "    season_data = train_data[train_data[\"season\"] == season]\n",
        "    preds = model.predict(season_data[features])\n",
        "    residuals = season_data[target] - preds\n",
        "    resid_mad = np.median(np.abs(residuals - np.median(residuals)))\n",
        "    tolerance = 3 * 1.4826 * resid_mad\n",
        "    tolerance_dict[season] = tolerance\n",
        "    print(f\"Tolerance for {season} model: {tolerance:.3f}\")\n",
        "\n",
        "# Check for invalid is_expedited_delivery based on the calculated tolerance\n",
        "def check_expedited(row):\n",
        "    tol = tolerance_dict[row[\"season\"]]\n",
        "    error = row[\"delivery_error\"]\n",
        "\n",
        "    if error > tol:\n",
        "        return True\n",
        "    elif error < -tol:\n",
        "        return False\n",
        "    else:\n",
        "        return row[\"is_expedited_delivery\"]\n",
        "\n",
        "unfixed_data[\"correct_expedited\"] = unfixed_data.apply(check_expedited, axis=1)\n",
        "\n",
        "# Invalid is_expedited_delivery\n",
        "invalid_expedited = unfixed_data[unfixed_data[\"correct_expedited\"] != unfixed_data[\"is_expedited_delivery\"]]\n",
        "print(\"Number of invalid is_delivery_expedited:\", len(invalid_expedited))\n",
        "print(invalid_expedited[[\"order_id\", \"season\", \"delivery_error\", \"is_expedited_delivery\", \"correct_expedited\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "w8a3dzM9LgpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df644241-6603-4990-f70d-36d5b187699d"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 score for Winter model trained = 0.98377\n",
            "R2 score for Summer model trained = 0.99552\n",
            "R2 score for Autumn model trained = 0.98718\n",
            "R2 score for Spring model trained = 0.99378\n",
            "Tolerance for Winter model: 3.143\n",
            "Tolerance for Summer model: 2.575\n",
            "Tolerance for Autumn model: 2.593\n",
            "Tolerance for Spring model: 3.536\n",
            "Number of invalid is_delivery_expedited: 54\n",
            " order_id season  delivery_error  is_expedited_delivery  correct_expedited\n",
            "ORD316891 Winter       13.560236                  False               True\n",
            "ORD092985 Summer       21.000244                  False               True\n",
            "ORD337660 Autumn      -14.224409                   True              False\n",
            "ORD398696 Summer       21.087023                  False               True\n",
            "ORD232419 Summer       19.701900                  False               True\n",
            "ORD013805 Summer       20.113138                  False               True\n",
            "ORD333779 Autumn      -14.797708                   True              False\n",
            "ORD403640 Spring      -26.648642                   True              False\n",
            "ORD423616 Winter      -11.753484                   True              False\n",
            "ORD205988 Summer       20.323743                  False               True\n",
            "ORD068755 Autumn       13.691507                  False               True\n",
            "ORD041144 Summer      -17.681798                   True              False\n",
            "ORD161558 Winter       12.553959                  False               True\n",
            "ORD331515 Winter       12.535881                  False               True\n",
            "ORD482432 Autumn      -14.099589                   True              False\n",
            "ORD227689 Summer      -19.676066                   True              False\n",
            "ORD387260 Spring       24.602818                  False               True\n",
            "ORD474989 Winter       12.474173                  False               True\n",
            "ORD303124 Summer      -19.345835                   True              False\n",
            "ORD176250 Winter       11.209640                  False               True\n",
            "ORD377178 Summer       20.639254                  False               True\n",
            "ORD400642 Summer      -20.220177                   True              False\n",
            "ORD231763 Spring       23.621693                  False               True\n",
            "ORD175829 Spring       25.436312                  False               True\n",
            "ORD066841 Spring      -22.915790                   True              False\n",
            "ORD397774 Autumn      -13.243542                   True              False\n",
            "ORD172403 Winter       12.958154                  False               True\n",
            "ORD451073 Winter       12.750070                  False               True\n",
            "ORD297470 Spring      -22.300213                   True              False\n",
            "ORD391673 Winter      -11.206529                   True              False\n",
            "ORD163603 Spring      -25.231345                   True              False\n",
            "ORD301373 Spring      -26.971367                   True              False\n",
            "ORD182563 Summer       18.375748                  False               True\n",
            "ORD270237 Summer      -20.357059                   True              False\n",
            "ORD090673 Spring       25.496532                  False               True\n",
            "ORD041039 Summer       19.024026                  False               True\n",
            "ORD486411 Autumn      -14.832974                   True              False\n",
            "ORD467243 Autumn       14.517567                  False               True\n",
            "ORD466778 Summer       18.271449                  False               True\n",
            "ORD380109 Spring      -26.429087                   True              False\n",
            "ORD215316 Winter      -11.628860                   True              False\n",
            "ORD152982 Winter      -13.225885                   True              False\n",
            "ORD005848 Spring       26.627992                  False               True\n",
            "ORD183167 Winter      -12.765629                   True              False\n",
            "ORD240676 Summer      -20.699460                   True              False\n",
            "ORD444410 Spring       26.295119                  False               True\n",
            "ORD250528 Autumn      -13.791918                   True              False\n",
            "ORD227892 Autumn       12.685078                  False               True\n",
            "ORD409545 Summer       18.987574                  False               True\n",
            "ORD273834 Winter       11.562617                  False               True\n",
            "ORD317561 Winter      -12.761736                   True              False\n",
            "ORD038424 Autumn       13.118257                  False               True\n",
            "ORD419009 Spring      -24.682933                   True              False\n",
            "ORD329999 Spring       24.869913                  False               True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Is_expedited_delivery Check - Justification:**\n",
        "\n",
        "To validate is_expedited_delivery, linear regression models by season is trained fixed data to predict delivery_charges from distance_to_nearest_warehouse, is_expedited_delivery, and is_happy_customer. For each unfixed row, the residual is computed and a robust MAD-based tolerance is used to flag inconsistencies where a large positive residual suggests the charge is too high, a large negative residual suggests it's too low, otherwise the original flag is retained."
      ],
      "metadata": {
        "id": "u9dJzkKuhcMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix is_expedited_delivery\n",
        "# Extract the unfixed data\n",
        "unfixed_data = clean_data[~clean_data[\"order_id\"].isin(fix_log[\"order_id\"])].copy()\n",
        "unfixed_index = unfixed_data.index\n",
        "\n",
        "# Mapping of the order_id with the correct is_expedited_delivery value\n",
        "\n",
        "expedited_map = (invalid_expedited\n",
        "                 .loc[:, [\"order_id\", \"correct_expedited\"]]\n",
        "                 .set_index(\"order_id\")[\"correct_expedited\"])\n",
        "\n",
        "# Invalid is_expedited_delivery\n",
        "incorrect_expedited = unfixed_data[\"order_id\"].isin(expedited_map.index)\n",
        "expedited_index = unfixed_data.index[incorrect_expedited]\n",
        "\n",
        "# Replace the invalid rows with the correct values\n",
        "clean_data.loc[expedited_index, \"is_expedited_delivery\"] = (clean_data.loc[expedited_index, \"order_id\"].map(expedited_map).astype(bool).values)\n",
        "\n",
        "# Log the order_id for fixed_rows\n",
        "fixed_ids = clean_data.loc[expedited_index, \"order_id\"].values\n",
        "fix_log = pd.concat([fix_log,\n",
        "                     pd.DataFrame({\"order_id\": fixed_ids,\n",
        "                                   \"error_type\": \"Incorrect is_expedited_delivery\"})],\n",
        "                    ignore_index=True)\n",
        "\n",
        "print(f\"Fixed {len(fixed_ids)} rows.\")\n",
        "print(clean_data.loc[expedited_index, [\"order_id\", \"is_expedited_delivery\"]].to_string(index=False))"
      ],
      "metadata": {
        "id": "Sv_3i8jjnwTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c1a2ce-8449-4b2f-c46c-6ff7923d322f"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed 54 rows.\n",
            " order_id  is_expedited_delivery\n",
            "ORD316891                   True\n",
            "ORD092985                   True\n",
            "ORD337660                  False\n",
            "ORD398696                   True\n",
            "ORD232419                   True\n",
            "ORD013805                   True\n",
            "ORD333779                  False\n",
            "ORD403640                  False\n",
            "ORD423616                  False\n",
            "ORD205988                   True\n",
            "ORD068755                   True\n",
            "ORD041144                  False\n",
            "ORD161558                   True\n",
            "ORD331515                   True\n",
            "ORD482432                  False\n",
            "ORD227689                  False\n",
            "ORD387260                   True\n",
            "ORD474989                   True\n",
            "ORD303124                  False\n",
            "ORD176250                   True\n",
            "ORD377178                   True\n",
            "ORD400642                  False\n",
            "ORD231763                   True\n",
            "ORD175829                   True\n",
            "ORD066841                  False\n",
            "ORD397774                  False\n",
            "ORD172403                   True\n",
            "ORD451073                   True\n",
            "ORD297470                  False\n",
            "ORD391673                  False\n",
            "ORD163603                  False\n",
            "ORD301373                  False\n",
            "ORD182563                   True\n",
            "ORD270237                  False\n",
            "ORD090673                   True\n",
            "ORD041039                   True\n",
            "ORD486411                  False\n",
            "ORD467243                   True\n",
            "ORD466778                   True\n",
            "ORD380109                  False\n",
            "ORD215316                  False\n",
            "ORD152982                  False\n",
            "ORD005848                   True\n",
            "ORD183167                  False\n",
            "ORD240676                  False\n",
            "ORD444410                   True\n",
            "ORD250528                  False\n",
            "ORD227892                   True\n",
            "ORD409545                   True\n",
            "ORD273834                   True\n",
            "ORD317561                  False\n",
            "ORD038424                   True\n",
            "ORD419009                  False\n",
            "ORD329999                   True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Is_expedited_delivery Fix - Justification:**\n",
        "\n",
        "This step corrects is_expedited_delivery for rows the residual-model flagged as inconsistent. Each affected order_id is mapped to its correct_expedited value, overwrite the flag, and append the fix to fix_log as \"Incorrect is_expedited_delivery\"."
      ],
      "metadata": {
        "id": "foKtiosuhfYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of fixed rows\n",
        "print(\"Summary of dirty_data.csv:\")\n",
        "print(\"- Number of fixed rows:\", len(fix_log))\n",
        "\n",
        "duplicate_order_id = fix_log[\"order_id\"].duplicated().any()\n",
        "print(\"- Only one error per row fixed:\", ~duplicate_order_id)\n",
        "\n",
        "print(\"- Types of error in dirty_data.csv:\")\n",
        "error_count = fix_log[\"error_type\"].value_counts()\n",
        "for error_type, count in error_count.items():\n",
        "  print(f\"  * {error_type}: {count}\")"
      ],
      "metadata": {
        "id": "t8sl0JkaWJUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8072722-a652-4a9d-b214-7bf9a0ea9ed4"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary of dirty_data.csv:\n",
            "- Number of fixed rows: 293\n",
            "- Only one error per row fixed: True\n",
            "- Types of error in dirty_data.csv:\n",
            "  * Incorrect is_expedited_delivery: 54\n",
            "  * Missing date: 27\n",
            "  * Incorrect season: 27\n",
            "  * Swapped coordinates: 27\n",
            "  * Incorrect shopping_cart: 27\n",
            "  * Incorrect order_price: 27\n",
            "  * Incorrect order_total: 27\n",
            "  * Incorrect is_happy_customer: 27\n",
            "  * Incorrect distance_to_nearest_warehouse: 23\n",
            "  * Incorrect nearest_warehouse: 20\n",
            "  * Inconsistent nearest_warehouse naming: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to csv\n",
        "file_name = \"Group035_dirty_data_solution.csv\"\n",
        "output_path = os.path.join(base, file_name)\n",
        "clean_data.to_csv(output_path, index=False, na_rep=\"NaN\")"
      ],
      "metadata": {
        "id": "LTyKFhinwC5I"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3 Outlier Data"
      ],
      "metadata": {
        "id": "Q9KONMBH_yeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect and remove outlier data by fitting linear model and computing robust z-score (Median + MAD) from residuals\n",
        "def remove_delivery_charge_outliers(df):\n",
        "    \"\"\"\n",
        "    Detect and remove delivery charge outliers using a linear model with\n",
        "    robust z-score residual analysis. Returns (filtered_df, outliers_df).\n",
        "    \"\"\"\n",
        "    df = df.copy()  # work on a copy to avoid side effects\n",
        "\n",
        "    # --- Step 1: Prepare features ---\n",
        "    X = df[['distance_to_nearest_warehouse', 'is_expedited_delivery', 'is_happy_customer', 'season']]\n",
        "    y = df['delivery_charges']\n",
        "\n",
        "    # Convert boolean to integer\n",
        "    X['is_expedited_delivery'] = X['is_expedited_delivery'].astype(int)\n",
        "    X['is_happy_customer'] = X['is_happy_customer'].astype(int)\n",
        "\n",
        "    # One-hot encode season (drop first to avoid multicollinearity)\n",
        "    encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
        "    season_encoded = encoder.fit_transform(X[['season']])\n",
        "    season_encoded_df = pd.DataFrame(season_encoded, columns=encoder.get_feature_names_out(['season']))\n",
        "\n",
        "    # Combine base features and season dummies\n",
        "    X_base = X.drop(columns=['season']).reset_index(drop=True)\n",
        "    X_encoded = pd.concat([X_base, season_encoded_df], axis=1)\n",
        "\n",
        "    # --- Step 2: Add interaction terms between season and numeric predictors ---\n",
        "    for season_col in season_encoded_df.columns:\n",
        "        for feature in ['distance_to_nearest_warehouse', 'is_expedited_delivery', 'is_happy_customer']:\n",
        "            interaction_name = f\"{feature}_x_{season_col}\"\n",
        "            X_encoded[interaction_name] = X_base[feature] * season_encoded_df[season_col]\n",
        "\n",
        "    # --- Step 3: Fit linear model ---\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_encoded, y)\n",
        "\n",
        "    # --- Step 4: Compute predictions and residuals (temporary only) ---\n",
        "    predicted = model.predict(X_encoded)\n",
        "    residuals = df['delivery_charges'] - predicted\n",
        "\n",
        "    # --- Step 5: Robust Z-score (Median + MAD) method ---\n",
        "    median_resid = np.median(residuals)\n",
        "    mad_resid = np.median(np.abs(residuals - median_resid))\n",
        "    robust_z = 0.6745 * (residuals - median_resid) / mad_resid\n",
        "\n",
        "    outlier_mask = np.abs(robust_z) > 3.5\n",
        "    outliers_df = df[outlier_mask].copy()\n",
        "    filtered_df = df[~outlier_mask].reset_index(drop=True)\n",
        "\n",
        "    print(f\"Removed {outliers_df.shape[0]} outliers (robust-based), remaining: {filtered_df.shape[0]}\")\n",
        "\n",
        "    return filtered_df, outliers_df\n",
        "\n",
        "filtered_data, outliers = remove_delivery_charge_outliers(outlier_data)\n",
        "\n",
        "print(\"\\nDetected Outliers:\")\n",
        "print(outliers[['order_id', 'delivery_charges']].head())\n",
        "\n",
        "# Export to csv\n",
        "file_name = \"Group035_outlier_data_solution.csv\"\n",
        "output_path = os.path.join(base, file_name)\n",
        "filtered_data.to_csv(output_path, index=False, na_rep=\"NaN\")"
      ],
      "metadata": {
        "id": "zDj3yr-sMrDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "430cca50-1fab-4391-a744-fbf50a90e510"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed 31 outliers (robust-based), remaining: 469\n",
            "\n",
            "Detected Outliers:\n",
            "      order_id  delivery_charges\n",
            "17   ORD089831           144.450\n",
            "28   ORD322216            71.475\n",
            "93   ORD276933            39.570\n",
            "98   ORD142753            39.010\n",
            "104  ORD317663            73.815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1343172152.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['is_expedited_delivery'] = X['is_expedited_delivery'].astype(int)\n",
            "/tmp/ipython-input-1343172152.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['is_happy_customer'] = X['is_happy_customer'].astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Outlier data - Methodology**  \n",
        " To detect and remove outlier data, we create a linear model and fit it according to the predictors described. We then compute the residuals of expected delivery charge vs actual delivery charge, and computed the robust z-score of median + median absolute deviation to identify which delivery charges were far unlike the predicted delivery charges. We then remove these outliers and display them for identification."
      ],
      "metadata": {
        "id": "Jo5rnuhVPaia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.4 Missing Data"
      ],
      "metadata": {
        "id": "mBtmtL9G503B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show how much missing data there is\n",
        "print(missing_data.isna().sum())"
      ],
      "metadata": {
        "id": "SFJC5J6z566q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72285e20-3a05-4cf4-d235-2bd20900b305"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "order_id                          0\n",
            "customer_id                       0\n",
            "date                              0\n",
            "nearest_warehouse                55\n",
            "shopping_cart                     0\n",
            "order_price                      15\n",
            "delivery_charges                 40\n",
            "customer_lat                      0\n",
            "customer_long                     0\n",
            "coupon_discount                   0\n",
            "order_total                      15\n",
            "season                            0\n",
            "is_expedited_delivery             0\n",
            "distance_to_nearest_warehouse    31\n",
            "latest_customer_review            0\n",
            "is_happy_customer                40\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute missing data by logical rule-based imputation\n",
        "# --- Imputation logic ---\n",
        "# We determine the values to impute from the columns from which they are dependent on.\n",
        "# This is imputation by rule calculation, and is definitively correct assuming the relationships and the other columns are correct.\n",
        "def impute_row(row, warehouses, price_map):\n",
        "    # Parse shopping_cart into list of tuples locally (in-place, no extra column)\n",
        "    try:\n",
        "        parsed_cart = ast.literal_eval(row['shopping_cart']) if pd.notna(row['shopping_cart']) else []\n",
        "    except Exception:\n",
        "        parsed_cart = []\n",
        "\n",
        "    # --- Impute nearest_warehouse from nearest warehouse and customer lat long ---\n",
        "    if pd.isna(row['nearest_warehouse']) and pd.notna(row['customer_lat']) and pd.notna(row['customer_long']):\n",
        "        distances = warehouses.apply(\n",
        "            lambda wh: haversine_dist(row['customer_lat'], row['customer_long'], wh['lat'], wh['lon']), axis=1\n",
        "        )\n",
        "        nearest_idx = distances.idxmin()\n",
        "        row['nearest_warehouse'] = warehouses.loc[nearest_idx, 'names']\n",
        "        row['distance_to_nearest_warehouse'] = distances.min()\n",
        "\n",
        "    # --- Impute order_price order total, delivery charge and coupon discount, or shopping cart if needed ---\n",
        "    if pd.isna(row['order_price']):\n",
        "        if pd.notna(row['order_total']) and pd.notna(row['delivery_charges']) and pd.notna(row['coupon_discount']):\n",
        "            denom = (100 - row['coupon_discount']) / 100\n",
        "            if denom != 0:\n",
        "                row['order_price'] = (row['order_total'] - row['delivery_charges']) / denom\n",
        "        elif pd.isna(row['order_total']) and parsed_cart:  # fallback to catalog\n",
        "            items, qtys = zip(*parsed_cart)\n",
        "            prices = price_map.reindex(items).fillna(0).values\n",
        "            row['order_price'] = np.dot(prices, qtys)\n",
        "\n",
        "    # --- Impute delivery_charges from order total, order price and coupon discount ---\n",
        "    if pd.isna(row['delivery_charges']):\n",
        "        if pd.notna(row['order_total']) and pd.notna(row['order_price']) and pd.notna(row['coupon_discount']):\n",
        "            denom = (100 - row['coupon_discount']) / 100\n",
        "            row['delivery_charges'] = row['order_total'] - row['order_price'] * denom\n",
        "\n",
        "    # --- Impute order_total ---\n",
        "    if pd.isna(row['order_total']):\n",
        "        if pd.notna(row['order_price']) and pd.notna(row['coupon_discount']) and pd.notna(row['delivery_charges']):\n",
        "            denom = (100 - row['coupon_discount']) / 100\n",
        "            row['order_total'] = row['order_price'] * denom + row['delivery_charges']\n",
        "\n",
        "    # --- Impute distance_to_nearest_warehouse from customer lat long---\n",
        "    if pd.isna(row['distance_to_nearest_warehouse']):\n",
        "        if pd.notna(row['nearest_warehouse']) and pd.notna(row['customer_lat']) and pd.notna(row['customer_long']):\n",
        "            wh = warehouses.loc[warehouses['names'] == row['nearest_warehouse']].iloc[0]\n",
        "            row['distance_to_nearest_warehouse'] = haversine_dist(row['customer_lat'], row['customer_long'], wh['lat'], wh['lon'])\n",
        "\n",
        "    # --- Impute is_happy_customer from sentiment---\n",
        "    if pd.isna(row['is_happy_customer']) and pd.notna(row['latest_customer_review']):\n",
        "        sentiment = sia.polarity_scores(str(row['latest_customer_review']))\n",
        "        row['is_happy_customer'] = sentiment['compound'] >= 0.05\n",
        "\n",
        "    return row\n",
        "\n",
        "# Apply\n",
        "missing_data_imputed = missing_data.apply(lambda r: impute_row(r, warehouse_data, price_map), axis=1)\n",
        "\n",
        "# Export to csv\n",
        "file_name = \"Group035_missing_data_solution.csv\"\n",
        "output_path = os.path.join(base, file_name)\n",
        "missing_data_imputed.to_csv(output_path, index=False, na_rep=\"NaN\")"
      ],
      "metadata": {
        "id": "W9KlXaox6AzN"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify that imputation caught all missing data\n",
        "if sum(missing_data_imputed.isna().sum()) == 0:\n",
        "    print(\"No missing data remaining\\n\")\n",
        "else:\n",
        "    print(missing_data_imputed.isna().sum())\n",
        "    rows_with_nulls = missing_data_imputed[missing_data_imputed.isnull().any(axis=1)]\n",
        "    print(rows_with_nulls)"
      ],
      "metadata": {
        "id": "44jrpEWx6Gd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0621c966-92e5-4614-df2d-cf2f3dda94c0"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No missing data remaining\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Missing Data Imputation - Methodology**  \n",
        "To impute the missing data, we notice that few columns are actually missing, and these columns can be directly derived from other columns which are said to be error-free. As such, we can directly impute the missing data to be derived from the other columns. For example, the order total can be imputed as the order price after applying coupon discounts and adding delivery charges.\n",
        "\n",
        "Given the assumption that the other columns are error free, this is the most direct, logical and correct way to impute missing data as it is deterministic."
      ],
      "metadata": {
        "id": "aJy_rApbQmTk"
      }
    }
  ]
}