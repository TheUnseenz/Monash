{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JY6ZwHgw8C-a"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# base = \"/content/drive/MyDrive/FIT5196Assignment2/\" # for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u4k1Nb-39jM5"
   },
   "outputs": [],
   "source": [
    "# begin here if running locally\n",
    "\n",
    "# for local drive\n",
    "base = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "warehouses = pd.read_csv(base + 'warehouses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "knnTQ100A0dl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      order_id   customer_id        date nearest_warehouse  \\\n",
      "0    ORD257850  ID0767584756  2019-07-13          Thompson   \n",
      "1    ORD216249  ID2247272473  2019-07-11         Nickolson   \n",
      "2    ORD316891  ID6167441075  2019-06-22         Nickolson   \n",
      "3    ORD040572  ID2189145378  2019-07-16         Nickolson   \n",
      "4    ORD091929  ID0145235237  2019-06-06         Nickolson   \n",
      "..         ...           ...         ...               ...   \n",
      "495  ORD329999  ID0615176175  2019-11-09            Bakers   \n",
      "496  ORD379470  ID0287629420  2019-04-27          Thompson   \n",
      "497  ORD000718  ID3313134375  2019-12-11         Nickolson   \n",
      "498  ORD201885  ID0026051952  2019-02-07         Nickolson   \n",
      "499  ORD089659  ID0575375067  2019-07-18         Nickolson   \n",
      "\n",
      "                                         shopping_cart  order_price  \\\n",
      "0               [('iAssist Line', 1), ('Alcon 10', 1)]        11175   \n",
      "1    [('Universe Note', 2), ('pearTV', 2), ('Toshik...        29020   \n",
      "2    [('Universe Note', 2), ('Thunder line', 2), ('...        11410   \n",
      "3    [('iAssist Line', 1), ('Olivia x460', 1), ('Ca...         6490   \n",
      "4          [('Toshika 750', 2), ('Candle Inferno', 2)]         9500   \n",
      "..                                                 ...          ...   \n",
      "495  [('Olivia x460', 1), ('Toshika 750', 2), ('Thu...        12045   \n",
      "496  [('Olivia x460', 1), ('Toshika 750', 1), ('Alc...        17945   \n",
      "497         [('iAssist Line', 2), ('Thunder line', 2)]        22260   \n",
      "498  [('Olivia x460', 1), ('Toshika 750', 2), ('Can...        10725   \n",
      "499        [('Lucent 330S', 1), ('Candle Inferno', 2)]         2090   \n",
      "\n",
      "     delivery_charges  customer_lat  customer_long  coupon_discount  \\\n",
      "0               75.59    -37.807212     144.950856               15   \n",
      "1               77.85    -37.816239     144.963762                5   \n",
      "2               61.41    -37.815915     144.964706               15   \n",
      "3               66.05    -37.816654     144.958595               15   \n",
      "4               76.93    144.959364     -37.815878               25   \n",
      "..                ...           ...            ...              ...   \n",
      "495            108.41    -37.801347     144.979727                5   \n",
      "496             79.69    -37.803889     144.948781               15   \n",
      "497             67.47    -37.817240     144.967353               15   \n",
      "498             89.82    144.968469     -37.813794               15   \n",
      "499             66.35    -37.819422     144.982956                5   \n",
      "\n",
      "     order_total  season  is_expedited_delivery  \\\n",
      "0        9574.34  Winter                   True   \n",
      "1       27646.85  Winter                   True   \n",
      "2        9759.91  Winter                  False   \n",
      "3        5582.55  Winter                  False   \n",
      "4        7201.93  Winter                   True   \n",
      "..           ...     ...                    ...   \n",
      "495     11551.16  Spring                  False   \n",
      "496     15332.94  Autumn                   True   \n",
      "497     18988.47  Summer                  False   \n",
      "498      9206.07  Summer                   True   \n",
      "499      9508.96  Winter                  False   \n",
      "\n",
      "     distance_to_nearest_warehouse  \\\n",
      "0                           0.6932   \n",
      "1                           0.5727   \n",
      "2                           0.5201   \n",
      "3                           0.9874   \n",
      "4                           0.9455   \n",
      "..                             ...   \n",
      "495                         1.6693   \n",
      "496                         0.9894   \n",
      "497                         0.2452   \n",
      "498                         0.5429   \n",
      "499                         1.1823   \n",
      "\n",
      "                                latest_customer_review  is_happy_customer  \n",
      "0    screech! where you at?! good phone lucentrola ...               True  \n",
      "1    battery runs low fast the phone works fine, al...              False  \n",
      "2    two stars lcd screen went out after only a month.              False  \n",
      "3                        love it everything best phone               True  \n",
      "4    near perfect phone perfect phone except the fi...               True  \n",
      "..                                                 ...                ...  \n",
      "495  z3 play is a great phone i'm a bit of a lucent...               True  \n",
      "496  this phone is amazing this is one phone that i...               True  \n",
      "497  this is a great tablet with great features. i ...               True  \n",
      "498  fyi on universe note 3 this is a excellent pho...               True  \n",
      "499            great value hard to beat for the price.               True  \n",
      "\n",
      "[500 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dirty_data = pd.read_csv(base + 'Group_035_dirty_data.csv')\n",
    "print(dirty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier data\n",
    "outlier_data = pd.read_csv(base + 'Group_035_outlier_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Outliers using standard deviation rule ===\n",
      "      order_id  delivery_charges  predicted_delivery_charge   residual\n",
      "17   ORD089831           144.450                  96.864118  47.585882\n",
      "93   ORD276933            39.570                  76.640083 -37.070083\n",
      "98   ORD142753            39.010                  73.782575 -34.772575\n",
      "109  ORD233575           119.955                  80.004734  39.950266\n",
      "123  ORD099918            39.790                  80.272405 -40.482405\n",
      "137  ORD272158            33.335                  64.123499 -30.788499\n",
      "143  ORD414922           143.385                  97.169650  46.215350\n",
      "145  ORD482557           164.775                 112.698279  52.076721\n",
      "167  ORD141312           126.705                  88.620992  38.084008\n",
      "193  ORD204921            40.450                  80.686767 -40.236767\n",
      "194  ORD318956           193.875                 145.804701  48.070299\n",
      "207  ORD285918            52.185                 106.343889 -54.158889\n",
      "252  ORD181666           167.445                 114.997928  52.447072\n",
      "273  ORD429584            51.875                 102.527430 -50.652430\n",
      "280  ORD113739            54.345                 111.406370 -57.061370\n",
      "296  ORD340379            97.710                  62.725451  34.984549\n",
      "307  ORD388515            39.155                  76.413738 -37.258738\n",
      "347  ORD395285            34.030                  66.694396 -32.664396\n",
      "348  ORD449112           147.105                  95.825847  51.279153\n",
      "411  ORD087709            38.375                  75.930990 -37.555990\n",
      "431  ORD287879            52.485                 110.647749 -58.162749\n",
      "448  ORD212231            31.870                  63.796444 -31.926444\n",
      "489  ORD325671           136.380                  95.360743  41.019257\n",
      "\n",
      "=== Outliers using robust z-score ===\n",
      "      order_id  delivery_charges  predicted_delivery_charge   residual\n",
      "17   ORD089831           144.450                  96.864118  47.585882\n",
      "28   ORD322216            71.475                  49.605252  21.869748\n",
      "93   ORD276933            39.570                  76.640083 -37.070083\n",
      "98   ORD142753            39.010                  73.782575 -34.772575\n",
      "104  ORD317663            73.815                  51.904774  21.910226\n",
      "109  ORD233575           119.955                  80.004734  39.950266\n",
      "123  ORD099918            39.790                  80.272405 -40.482405\n",
      "131  ORD171684           102.555                  72.340548  30.214452\n",
      "137  ORD272158            33.335                  64.123499 -30.788499\n",
      "143  ORD414922           143.385                  97.169650  46.215350\n",
      "145  ORD482557           164.775                 112.698279  52.076721\n",
      "167  ORD141312           126.705                  88.620992  38.084008\n",
      "168  ORD109768            26.515                  51.759332 -25.244332\n",
      "193  ORD204921            40.450                  80.686767 -40.236767\n",
      "194  ORD318956           193.875                 145.804701  48.070299\n",
      "207  ORD285918            52.185                 106.343889 -54.158889\n",
      "230  ORD161175            23.140                  46.134896 -22.994896\n",
      "252  ORD181666           167.445                 114.997928  52.447072\n",
      "273  ORD429584            51.875                 102.527430 -50.652430\n",
      "280  ORD113739            54.345                 111.406370 -57.061370\n",
      "296  ORD340379            97.710                  62.725451  34.984549\n",
      "307  ORD388515            39.155                  76.413738 -37.258738\n",
      "324  ORD005998           118.220                 126.103088  -7.883088\n",
      "347  ORD395285            34.030                  66.694396 -32.664396\n",
      "348  ORD449112           147.105                  95.825847  51.279153\n",
      "349  ORD104172            78.300                  55.545522  22.754478\n",
      "381  ORD242690            92.145                  62.212574  29.932426\n",
      "411  ORD087709            38.375                  75.930990 -37.555990\n",
      "431  ORD287879            52.485                 110.647749 -58.162749\n",
      "448  ORD212231            31.870                  63.796444 -31.926444\n",
      "489  ORD325671           136.380                  95.360743  41.019257\n",
      "\n",
      "Removed 23 outliers (std-based), remaining: 477\n",
      "Removed 31 outliers (robust-based), remaining: 469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_6676\\1690034405.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['is_expedited_delivery'] = X['is_expedited_delivery'].astype(int)\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_6676\\1690034405.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['is_happy_customer'] = X['is_happy_customer'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# --- Assume you have already loaded ---\n",
    "df = outlier_data.copy()\n",
    "\n",
    "# --- Step 1: Prepare features ---\n",
    "X = df[['distance_to_nearest_warehouse', 'is_expedited_delivery', 'is_happy_customer', 'season']]\n",
    "y = df['delivery_charges']\n",
    "\n",
    "# Convert boolean to integer\n",
    "X['is_expedited_delivery'] = X['is_expedited_delivery'].astype(int)\n",
    "X['is_happy_customer'] = X['is_happy_customer'].astype(int)\n",
    "\n",
    "# One-hot encode season (drop first to avoid multicollinearity)\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "season_encoded = encoder.fit_transform(X[['season']])\n",
    "season_encoded_df = pd.DataFrame(season_encoded, columns=encoder.get_feature_names_out(['season']))\n",
    "\n",
    "# Combine base features and season dummies\n",
    "X_base = X.drop(columns=['season']).reset_index(drop=True)\n",
    "X_encoded = pd.concat([X_base, season_encoded_df], axis=1)\n",
    "\n",
    "# --- Step 2: Add interaction terms between season and numeric predictors ---\n",
    "for season_col in season_encoded_df.columns:\n",
    "    for feature in ['distance_to_nearest_warehouse', 'is_expedited_delivery', 'is_happy_customer']:\n",
    "        interaction_name = f\"{feature}_x_{season_col}\"\n",
    "        X_encoded[interaction_name] = X_base[feature] * season_encoded_df[season_col]\n",
    "\n",
    "# --- Step 3: Fit linear model ---\n",
    "model = LinearRegression()\n",
    "model.fit(X_encoded, y)\n",
    "\n",
    "# --- Step 4: Compute predictions and residuals ---\n",
    "df['predicted_delivery_charge'] = model.predict(X_encoded)\n",
    "df['residual'] = df['delivery_charges'] - df['predicted_delivery_charge']\n",
    "\n",
    "# --- Step 5: Standard deviationâ€“based outlier detection ---\n",
    "std_resid = df['residual'].std()\n",
    "outlier_std_mask = np.abs(df['residual']) > 3 * std_resid\n",
    "outliers_std = df[outlier_std_mask]\n",
    "\n",
    "print(\"=== Outliers using standard deviation rule ===\")\n",
    "print(outliers_std[['order_id', 'delivery_charges', 'predicted_delivery_charge', 'residual']])\n",
    "\n",
    "# --- Step 6: Robust Z-score (Median + MAD) method ---\n",
    "median_resid = df['residual'].median()\n",
    "mad_resid = np.median(np.abs(df['residual'] - median_resid))\n",
    "robust_z = 0.6745 * (df['residual'] - median_resid) / mad_resid\n",
    "\n",
    "outlier_robust_mask = np.abs(robust_z) > 3.5   # Common robust z-score threshold\n",
    "outliers_robust = df[outlier_robust_mask]\n",
    "\n",
    "print(\"\\n=== Outliers using robust z-score ===\")\n",
    "print(outliers_robust[['order_id', 'delivery_charges', 'predicted_delivery_charge', 'residual',]])\n",
    "\n",
    "# --- Step 7: Optionally filter outliers ---\n",
    "filtered_std = df[~outlier_std_mask].reset_index(drop=True)\n",
    "filtered_robust = df[~outlier_robust_mask].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nRemoved {outliers_std.shape[0]} outliers (std-based), remaining: {filtered_std.shape[0]}\")\n",
    "print(f\"Removed {outliers_robust.shape[0]} outliers (robust-based), remaining: {filtered_robust.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected outliers based on delivery_charge residuals:\n",
      "      order_id  delivery_charges  predicted_delivery_charge   residual\n",
      "17   ORD089831           144.450                  94.770491  49.679509\n",
      "93   ORD276933            39.570                  79.393501 -39.823501\n",
      "98   ORD142753            39.010                  75.439337 -36.429337\n",
      "109  ORD233575           119.955                  84.049439  35.905561\n",
      "123  ORD099918            39.790                  83.044732 -43.254732\n",
      "143  ORD414922           143.385                  95.117816  48.267184\n",
      "145  ORD482557           164.775                 105.864411  58.910589\n",
      "167  ORD141312           126.705                  88.983992  37.721008\n",
      "193  ORD204921            40.450                  83.339513 -42.889513\n",
      "194  ORD318956           193.875                 129.416621  64.458379\n",
      "207  ORD285918            52.185                 101.343840 -49.158840\n",
      "252  ORD181666           167.445                 107.500402  59.944598\n",
      "273  ORD429584            51.875                 101.208475 -49.333475\n",
      "280  ORD113739            54.345                 104.945335 -50.600335\n",
      "296  ORD340379            97.710                  58.199272  39.510728\n",
      "307  ORD388515            39.155                  78.014753 -38.859753\n",
      "348  ORD449112           147.105                  93.861209  53.243791\n",
      "411  ORD087709            38.375                  79.956209 -41.581209\n",
      "431  ORD287879            52.485                 104.405645 -51.920645\n",
      "489  ORD325671           136.380                  93.061473  43.318527\n",
      "\n",
      "Removed 20 outliers. Remaining records: 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_6676\\3947782600.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['is_expedited_delivery'] = X['is_expedited_delivery'].astype(int)\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_6676\\3947782600.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['is_happy_customer'] = X['is_happy_customer'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df = outlier_data.copy()\n",
    "\n",
    "# --- Step 1: Prepare data for modeling ---\n",
    "X = df[['distance_to_nearest_warehouse', 'is_expedited_delivery', 'is_happy_customer', 'season']]\n",
    "y = df['delivery_charges']\n",
    "\n",
    "# Convert boolean to int (0/1)\n",
    "X['is_expedited_delivery'] = X['is_expedited_delivery'].astype(int)\n",
    "X['is_happy_customer'] = X['is_happy_customer'].astype(int)\n",
    "\n",
    "# One-hot encode the categorical 'season'\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "season_encoded = encoder.fit_transform(X[['season']])\n",
    "season_encoded_df = pd.DataFrame(season_encoded, columns=encoder.get_feature_names_out(['season']))\n",
    "X_encoded = pd.concat([X.drop(columns=['season']).reset_index(drop=True), season_encoded_df], axis=1)\n",
    "\n",
    "# --- Step 2: Fit linear regression model ---\n",
    "model = LinearRegression()\n",
    "model.fit(X_encoded, y)\n",
    "\n",
    "# --- Step 3: Compute predicted values and residuals ---\n",
    "df['predicted_delivery_charge'] = model.predict(X_encoded)\n",
    "df['residual'] = df['delivery_charges'] - df['predicted_delivery_charge']\n",
    "\n",
    "# --- Step 4: Identify outliers based on residuals ---\n",
    "# Define outliers as points more than 3 standard deviations away\n",
    "std_resid = df['residual'].std()\n",
    "outlier_mask = np.abs(df['residual']) > 3 * std_resid\n",
    "outliers = df[outlier_mask]\n",
    "\n",
    "# --- Step 5: Print outliers ---\n",
    "print(\"Detected outliers based on delivery_charge residuals:\")\n",
    "print(outliers[['order_id', 'delivery_charges', 'predicted_delivery_charge', 'residual']])\n",
    "\n",
    "# --- Step 6: Remove outliers ---\n",
    "filtered_df = df[~outlier_mask].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nRemoved {outliers.shape[0]} outliers. Remaining records: {filtered_df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have two pandas datasets, warehouses and outlier_data, with the following columns: \n",
    "1. warehouses has the following columns: \n",
    "names,lat,lon \n",
    "\n",
    "2. outlier_data has the following columns: \n",
    "order_id,customer_id,date,nearest_warehouse,shopping_cart,order_price,delivery_charges,customer_lat,customer_long,coupon_discount,order_total,season,is_expedited_delivery,distance_to_nearest_warehouse,latest_customer_review,is_happy_customer \n",
    "\n",
    "i want to detect and remove outliers in delivery_charge. delivery_charge depends linearly on: distance_to_nearest_warehouse,is_expedited_delivery,is_happy_customer, and these 3 variables vary differently depending on season. \n",
    "\n",
    "to solve this, use sklearn.linear_model.LinearRegression to build a linear model to determine delivery_charge. distance_to_nearest_warehouse is a positive float, is_expedited_delivery and is_happy_customer are booleans. season is a categorical variable with 4 values, that modifies the weights of the other 3 variables. after building the linear model to determine delivery_charge, identify which values are considered outliers as compared to the predicted value. print out these outliers first, then filter them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "r7kPAHhdBARv"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m missing_data = \u001b[43mpd\u001b[49m.read_csv(base + \u001b[33m'\u001b[39m\u001b[33mGroup_035_missing_data.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(missing_data.isna().sum())\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "missing_data = pd.read_csv(base + 'Group_035_missing_data.csv')\n",
    "print(missing_data.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# Parse shopping_cart into list of tuples\n",
    "def parse_cart(cart_str):\n",
    "    if pd.isna(cart_str):\n",
    "        return []\n",
    "    try:\n",
    "        return ast.literal_eval(cart_str)\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "missing_data['parsed_cart'] = missing_data['shopping_cart'].apply(parse_cart)\n",
    "\n",
    "# Collect unique items\n",
    "all_items = sorted({item for cart in missing_data['parsed_cart'] for item, _ in cart})\n",
    "item_index = {item: i for i, item in enumerate(all_items)}\n",
    "\n",
    "# Build system of equations A x = b\n",
    "rows, b = [], []\n",
    "for _, row in missing_data.iterrows():\n",
    "    if pd.notna(row['order_price']) and row['parsed_cart']:\n",
    "        vec = np.zeros(len(all_items))\n",
    "        for item, qty in row['parsed_cart']:\n",
    "            vec[item_index[item]] += qty\n",
    "        rows.append(vec)\n",
    "        b.append(row['order_price'])\n",
    "\n",
    "A = np.vstack(rows)\n",
    "b = np.array(b)\n",
    "\n",
    "# Solve least squares for unit prices\n",
    "x, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "\n",
    "# Round to 2 decimals for catalog\n",
    "x = np.round(x, 2)\n",
    "\n",
    "# Build catalog\n",
    "catalog = {item: price for item, price in zip(all_items, x)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# --- Haversine helper ---\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6378  # Earth radius in KM\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "# --- Prepare Sentiment analyzer ---\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# --- Imputation logic ---\n",
    "def impute_row(row, warehouses, catalog):\n",
    "    # --- Impute nearest_warehouse ---\n",
    "    if pd.isna(row['nearest_warehouse']) and pd.notna(row['customer_lat']) and pd.notna(row['customer_long']):\n",
    "        distances = warehouses.apply(\n",
    "            lambda wh: haversine(row['customer_lat'], row['customer_long'], wh['lat'], wh['lon']), axis=1\n",
    "        )\n",
    "        nearest_idx = distances.idxmin()\n",
    "        row['nearest_warehouse'] = warehouses.loc[nearest_idx, 'names']\n",
    "        row['distance_to_nearest_warehouse'] = distances.min()\n",
    "\n",
    "    # --- Impute order_price ---\n",
    "    if pd.isna(row['order_price']):\n",
    "        if pd.notna(row['order_total']) and pd.notna(row['delivery_charges']) and pd.notna(row['coupon_discount']):\n",
    "            denom = (100 - row['coupon_discount']) / 100\n",
    "            if denom != 0:\n",
    "                row['order_price'] = (row['order_total'] - row['delivery_charges']) / denom\n",
    "        elif pd.isna(row['order_total']) and row['parsed_cart']:  # fallback to catalog\n",
    "            row['order_price'] = sum(catalog.get(item, 0) * qty for item, qty in row['parsed_cart'])\n",
    "\n",
    "    # --- Impute delivery_charges ---\n",
    "    if pd.isna(row['delivery_charges']):\n",
    "        if pd.notna(row['order_total']) and pd.notna(row['order_price']) and pd.notna(row['coupon_discount']):\n",
    "            denom = (100 - row['coupon_discount']) / 100\n",
    "            row['delivery_charges'] = row['order_total'] - row['order_price'] * denom\n",
    "\n",
    "    # --- Impute order_total ---\n",
    "    if pd.isna(row['order_total']):\n",
    "        if pd.notna(row['order_price']) and pd.notna(row['coupon_discount']) and pd.notna(row['delivery_charges']):\n",
    "            denom = (100 - row['coupon_discount']) / 100\n",
    "            row['order_total'] = row['order_price'] * denom + row['delivery_charges']\n",
    "\n",
    "    # --- Impute distance_to_nearest_warehouse ---\n",
    "    if pd.isna(row['distance_to_nearest_warehouse']):\n",
    "        if pd.notna(row['nearest_warehouse']) and pd.notna(row['customer_lat']) and pd.notna(row['customer_long']):\n",
    "            wh = warehouses.loc[warehouses['names'] == row['nearest_warehouse']].iloc[0]\n",
    "            row['distance_to_nearest_warehouse'] = haversine(row['customer_lat'], row['customer_long'], wh['lat'], wh['lon'])\n",
    "\n",
    "    # --- Impute is_happy_customer from sentiment---\n",
    "    if pd.isna(row['is_happy_customer']) and pd.notna(row['latest_customer_review']):\n",
    "        sentiment = sia.polarity_scores(str(row['latest_customer_review']))\n",
    "        row['is_happy_customer'] = sentiment['compound'] >= 0.05\n",
    "\n",
    "    return row\n",
    "\n",
    "# Apply\n",
    "missing_data_imputed = missing_data.apply(lambda r: impute_row(r, warehouses, catalog), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                         0\n",
      "customer_id                      0\n",
      "date                             0\n",
      "nearest_warehouse                0\n",
      "shopping_cart                    0\n",
      "order_price                      0\n",
      "delivery_charges                 0\n",
      "customer_lat                     0\n",
      "customer_long                    0\n",
      "coupon_discount                  0\n",
      "order_total                      0\n",
      "season                           0\n",
      "is_expedited_delivery            0\n",
      "distance_to_nearest_warehouse    0\n",
      "latest_customer_review           0\n",
      "is_happy_customer                0\n",
      "parsed_cart                      0\n",
      "dtype: int64\n",
      "{'Alcon 10': np.float64(8950.0), 'Candle Inferno': np.float64(430.0), 'Lucent 330S': np.float64(1230.0), 'Olivia x460': np.float64(1225.0), 'Thunder line': np.float64(2180.0), 'Toshika 750': np.float64(4320.0), 'Universe Note': np.float64(3450.0), 'iAssist Line': np.float64(2225.0), 'iStream': np.float64(150.0), 'pearTV': np.float64(6310.0)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(missing_data_imputed.isna().sum())\n",
    "rows_with_nulls = missing_data_imputed[missing_data_imputed.isnull().any(axis=1)]\n",
    "print(rows_with_nulls)\n",
    "\n",
    "print(catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have two pandas datasets, warehouses and missing_data, with the following columns:\n",
    "1. warehouses has the following columns:\n",
    "names,lat,lon\n",
    "\n",
    "2. missing_data has the following columns:\n",
    "order_id,customer_id,date,nearest_warehouse,shopping_cart,order_price,delivery_charges,customer_lat,customer_long,coupon_discount,order_total,season,is_expedited_delivery,distance_to_nearest_warehouse,latest_customer_review,is_happy_customer\n",
    "\n",
    "I want to perform data imputation. The columns which have missing entries, and the imputing strategy for each column, are:\n",
    "nearest_warehouse: compute the lowest Haversine Distance (with radius of earth = 6378 KM) between the customer_lat, customer_long and each of the lat, lon pairs in warehouses, and impute with the \"names\" of the lowest Haversine Distance.\n",
    "order_price: (order_total - delivery_charges)/((100-coupon_discount)/100)\n",
    "delivery_charges: order_total - order_price*((100-coupon_discount)/100)\n",
    "order_total: order_price*((100-coupon_discount)/100) + delivery_charges\n",
    "distance_to_nearest_warehouse: Haversine Distance (with radius of earth = 6378 KM) of customer_lat, customer_long vs the lat, lon of nearest_warehouse as found in warehouses\n",
    "is_happy_customer: check latest_customer_review with SentimentIntensityAnalyzer from \n",
    "nltk.sentiment.vader to obtain the polarity score. A sentiment is considered positive if it has a 'compound' polarity score of 0.05 or higher and is considered negative otherwise.\n",
    "\n",
    "If any row has too many missing columns to do any of the above imputation, do not impute it so that i can later see what's incomplete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "shopping_cart, a column in missing_data is a list of tuples, of (Item_ordered, Quantity), example: \"[('Item 330S', 1), ('sampleItem', 2)]\". \n",
    "\n",
    "there are 10 categories of items. using the column shopping_cart, first identify the 10 categories of items, then use numpy.linalg to determine the unit price of each item.\n",
    "\n",
    "store the values of this in a dictionary named catalog.\n",
    "\n",
    "in the case that both order_price and order_total are missing, order_price should be imputed from shopping_cart. use the number of each type of item ordered in shopping_cart, and, referencing the values found in catalog calculated earlier, impute order_price from this. order_total then can be imputed as normal.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRC-X7KrBAYl"
   },
   "outputs": [],
   "source": [
    "\n",
    "outlier_data = pd.read_csv(base + 'Group_035_outlier_data.csv')\n",
    "print(outlier_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM2J/3csU4eZksPso9duybE",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
