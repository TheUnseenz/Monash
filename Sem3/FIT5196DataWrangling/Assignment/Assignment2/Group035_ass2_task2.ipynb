{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d678d996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'number_of_houses': [np.float64(0.0), np.float64(0.5), np.float64(-0.5)], 'number_of_units': [np.float64(0.0), np.float64(0.5), np.float64(-0.5)], 'population': [np.float64(0.5), np.float64(1.0), np.float64(1.5)], 'aus_born_perc': [np.float64(3.0), np.float64(2.5), np.float64(3.5)], 'median_income': [np.float64(0.5), np.float64(1.0), np.float64(0.0)]}\n",
      "Total runs to evaluate: 729\n",
      "Best result (by mean R^2):\n",
      "  scaler: minmax\n",
      "  lambdas (per feature order ['number_of_houses', 'number_of_units', 'population', 'aus_born_perc', 'median_income']): (np.float64(0.5), np.float64(0.0), np.float64(1.5), np.float64(2.5), np.float64(1.0))\n",
      "  mean R^2: 0.666431 (std 0.078910)\n",
      "  mean RMSE: 270254.737312 (std 37885.187524)\n",
      "All results saved to: boxcox_scaling_results.csv\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "import os\n",
    "import math\n",
    "\n",
    "INPUT_FILE = \"suburb_info.xlsx\"\n",
    "FEATURES = [\"number_of_houses\", \"number_of_units\", \"population\", \"aus_born_perc\", \"median_income\"]\n",
    "TARGET = \"median_house_price\"\n",
    "LAMBDAS = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "SCALERS = [\"minmax\", \"robust\", \"zscore\"]\n",
    "CV_FOLDS = 3\n",
    "RANDOM_STATE = 0\n",
    "\n",
    "# Load\n",
    "if not os.path.exists(INPUT_FILE):\n",
    "    raise FileNotFoundError(f\"Could not find {INPUT_FILE} in the working directory. Make sure the file is present.\")\n",
    "\n",
    "df = pd.read_excel(INPUT_FILE)\n",
    "\n",
    "# Convert 'aus_born_perc' from '67%' → 67.0 (float)\n",
    "df[\"aus_born_perc\"] = df[\"aus_born_perc\"].astype(str).str.replace('%', '', regex=False)\n",
    "df[\"aus_born_perc\"] = pd.to_numeric(df[\"aus_born_perc\"], errors=\"coerce\")\n",
    "\n",
    "# Convert 'median_income' from '$1,583' → 1583 (int)\n",
    "df[\"median_income\"] = (\n",
    "    df[\"median_income\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r\"[\\$,]\", \"\", regex=True)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Convert 'median_house_price' from '$1,148,100' → 1148100 (int)\n",
    "df[\"median_house_price\"] = (\n",
    "    df[\"median_house_price\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r\"[\\$,]\", \"\", regex=True)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Check positives (Box-Cox requires > 0)\n",
    "for col in FEATURES + [TARGET]:\n",
    "    if (df[col] <= 0).any():\n",
    "        raise ValueError(f\"Column {col} contains non-positive values; Box-Cox requires strictly positive values.\")\n",
    "\n",
    "X_orig = df[FEATURES].astype(float).copy()\n",
    "y = df[TARGET].astype(float).copy()\n",
    "\n",
    "results = []\n",
    "kf = KFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "model = LinearRegression()\n",
    "\n",
    "lambda_combos = list(itertools.product(LAMBDAS, repeat=len(FEATURES)))\n",
    "total_runs = len(SCALERS) * len(lambda_combos)\n",
    "print(f\"Total runs to evaluate: {total_runs}\")\n",
    "\n",
    "for scaler_name in SCALERS:\n",
    "    for lambdas in lambda_combos:\n",
    "        # Box-Cox transform each feature with its lambda\n",
    "        X_trans = np.zeros_like(X_orig.values, dtype=float)\n",
    "        for i, col in enumerate(FEATURES):\n",
    "            lam = lambdas[i]\n",
    "            X_trans[:, i] = stats.boxcox(X_orig.iloc[:, i].values, lmbda=lam)\n",
    "\n",
    "        # Scale\n",
    "        if scaler_name == \"minmax\":\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        elif scaler_name == \"robust\":\n",
    "            scaler = RobustScaler()\n",
    "        else:\n",
    "            scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_trans)\n",
    "\n",
    "        # CV\n",
    "        r2_scores = cross_val_score(model, X_scaled, y.values, cv=kf, scoring=\"r2\")\n",
    "        neg_mse_scores = cross_val_score(model, X_scaled, y.values, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "        mse_scores = -neg_mse_scores\n",
    "        rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "        results.append({\n",
    "            \"scaler\": scaler_name,\n",
    "            \"lambdas\": tuple(lambdas),\n",
    "            \"mean_R2\": float(np.mean(r2_scores)),\n",
    "            \"std_R2\": float(np.std(r2_scores)),\n",
    "            \"mean_RMSE\": float(np.mean(rmse_scores)),\n",
    "            \"std_RMSE\": float(np.std(rmse_scores))\n",
    "        })\n",
    "\n",
    "res_df = pd.DataFrame(results).sort_values(by=\"mean_R2\", ascending=False).reset_index(drop=True)\n",
    "out_path = \"boxcox_scaling_results.csv\"\n",
    "res_df.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Best result (by mean R^2):\")\n",
    "best = res_df.iloc[0]\n",
    "print(f\"  scaler: {best['scaler']}\")\n",
    "print(f\"  lambdas (per feature order {FEATURES}): {best['lambdas']}\")\n",
    "print(f\"  mean R^2: {best['mean_R2']:.6f} (std {best['std_R2']:.6f})\")\n",
    "print(f\"  mean RMSE: {best['mean_RMSE']:.6f} (std {best['std_RMSE']:.6f})\")\n",
    "print(f\"All results saved to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4aa888c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               suburb  number_of_houses  number_of_units   municipality  \\\n",
      "0          ABBOTSFORD              2304             4706          Yarra   \n",
      "1          ABERFELDIE              1410              453  Moonee Valley   \n",
      "2           ALBANVALE              1897              138       Brimbank   \n",
      "3              ALBION              1389             1392       Brimbank   \n",
      "4          ALPHINGTON              1729             1099        Darebin   \n",
      "..                ...               ...              ...            ...   \n",
      "197  WILLIAMS LANDING              2735              173        Wyndham   \n",
      "198           WINDSOR              2201             4448    Stonnington   \n",
      "199           WOLLERT              6516              259     Whittlesea   \n",
      "200         YALLAMBIE              1286               81        Banyule   \n",
      "201        YARRAVILLE              5855             2072    Maribyrnong   \n",
      "\n",
      "     aus_born_perc  median_income  median_house_price  population  \n",
      "0               68         1797.0           1299400.0        4025  \n",
      "1               81         1571.0           1926600.0       22442  \n",
      "2               46          907.0            594200.0       54005  \n",
      "3               52          929.0            739100.0       30677  \n",
      "4               73         1538.0           1729600.0        9227  \n",
      "..             ...            ...                 ...         ...  \n",
      "197             87         1842.0            866400.0         170  \n",
      "198             66         1560.0           1629600.0       17776  \n",
      "199             80         1355.0            704700.0         350  \n",
      "200             79         1458.0            998200.0       12063  \n",
      "201             67         1583.0           1148100.0       11645  \n",
      "\n",
      "[202 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06ffee2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m    120\u001b[39m df = pd.read_excel(fn, sheet_name=SHEET_NAME)\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# Basic checks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m missing_cols = [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m FEATURE_COLS + [TARGET_COL] \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m]\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required columns in Excel file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "boxcox_grid_search.py\n",
    "\n",
    "Run a grid search over:\n",
    " - scaling_method: 'minmax' or 'robust' (same for all features)\n",
    " - box-cox lambda per feature, chosen from LAMBDAS = [-1, -0.5, 0, 0.5, 1]\n",
    "\n",
    "Features (input columns expected in suburb_info.xlsx):\n",
    "    number_of_houses, number_of_units, population, aus_born_perc, median_income\n",
    "\n",
    "Target:\n",
    "    median_house_price\n",
    "\n",
    "Saves results to `boxcox_grid_results.csv` and prints the best config by mean R^2.\n",
    "\"\"\"\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.utils import check_random_state\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------- USER SETTINGS -------------\n",
    "INPUT_FILE = \"suburb_info.xlsx\"   # must be in working dir\n",
    "SHEET_NAME = None                 # or set to sheet name if needed\n",
    "FEATURE_COLS = [\n",
    "    \"number_of_houses\",\n",
    "    \"number_of_units\",\n",
    "    \"population\",\n",
    "    \"aus_born_perc\",\n",
    "    \"median_income\",\n",
    "]\n",
    "TARGET_COL = \"median_house_price\"\n",
    "\n",
    "SCALING_METHODS = [\"minmax\", \"robust\"]   # choose one for all features per experiment\n",
    "LAMBDAS = [-1.0, -0.5, 0.0, 0.5, 1.0]    # box-cox lambdas to choose from (per feature)\n",
    "CV_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "N_JOBS = 1   # set >1 if you want parallelization (not used here, but could be)\n",
    "OUTPUT_CSV = \"boxcox_grid_results.csv\"\n",
    "# ------------- end settings ----------------\n",
    "\n",
    "rng = check_random_state(RANDOM_STATE)\n",
    "\n",
    "# ---------- helper functions ----------\n",
    "def safe_shift_array(x, min_allowed=1e-6):\n",
    "    \"\"\"\n",
    "    Return shifted array and the shift value so that min(x_shifted) > 0.\n",
    "    We choose shift = (min_allowed - min_x) if min_x <= min_allowed else 0.\n",
    "    This ensures positivity for Box-Cox.\n",
    "    \"\"\"\n",
    "    min_x = np.min(x)\n",
    "    if min_x <= min_allowed:\n",
    "        shift = (min_allowed - min_x)\n",
    "        return x + shift, shift\n",
    "    else:\n",
    "        return x.copy(), 0.0\n",
    "\n",
    "def boxcox_transform(x, lam):\n",
    "    \"\"\"\n",
    "    Apply Box-Cox style transform with explicit lambda to a positive array x (>0).\n",
    "    Uses formula:\n",
    "      if lambda != 0: (x**lambda - 1) / lambda\n",
    "      else:            log(x)\n",
    "    Note: we do not standardize after this function; caller can do that.\n",
    "    \"\"\"\n",
    "    if lam == 0.0:\n",
    "        return np.log(x)\n",
    "    else:\n",
    "        return (np.power(x, lam) - 1.0) / lam\n",
    "\n",
    "def scale_matrix(X_df, method):\n",
    "    \"\"\"\n",
    "    Scale a pandas DataFrame (columns are features) using the same method for all columns.\n",
    "    method: 'minmax' or 'robust' (as requested by you)\n",
    "    Returns scaled_df, plus dictionary of parameters used (min,max or median,IQR) for info.\n",
    "    \"\"\"\n",
    "    X = X_df.copy()\n",
    "    params = {}\n",
    "    if method == \"minmax\":\n",
    "        for c in X.columns:\n",
    "            xmin = X[c].min()\n",
    "            xmax = X[c].max()\n",
    "            if xmax == xmin:\n",
    "                # constant column -> set to 0.0\n",
    "                X[c] = 0.0\n",
    "                params[c] = {\"xmin\": xmin, \"xmax\": xmax}\n",
    "            else:\n",
    "                X[c] = (X[c] - xmin) / (xmax - xmin)\n",
    "                params[c] = {\"xmin\": xmin, \"xmax\": xmax}\n",
    "    elif method == \"robust\":\n",
    "        # robust scaling as you specified: (x - median) / IQR\n",
    "        for c in X.columns:\n",
    "            med = X[c].median()\n",
    "            q75 = np.percentile(X[c], 75)\n",
    "            q25 = np.percentile(X[c], 25)\n",
    "            iqr = q75 - q25\n",
    "            if iqr == 0:\n",
    "                # avoid divide by zero\n",
    "                X[c] = 0.0\n",
    "                params[c] = {\"median\": med, \"iqr\": iqr}\n",
    "            else:\n",
    "                X[c] = (X[c] - med) / iqr\n",
    "                params[c] = {\"median\": med, \"iqr\": iqr}\n",
    "    else:\n",
    "        raise ValueError(\"Unknown scaling method: \" + str(method))\n",
    "    return X, params\n",
    "\n",
    "# ---------- load data ----------\n",
    "fn = Path(INPUT_FILE)\n",
    "if not fn.exists():\n",
    "    raise FileNotFoundError(f\"Input file {INPUT_FILE} not found in working directory. Place your suburb_info.xlsx there.\")\n",
    "\n",
    "df = pd.read_excel(fn, sheet_name=SHEET_NAME)\n",
    "\n",
    "# Basic checks\n",
    "missing_cols = [c for c in FEATURE_COLS + [TARGET_COL] if c not in df.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing required columns in Excel file: {missing_cols}\")\n",
    "\n",
    "X_raw = df[FEATURE_COLS].copy()\n",
    "y = df[TARGET_COL].values\n",
    "\n",
    "# Remove rows with missing target or any missing feature rows (or you can impute beforehand)\n",
    "mask_complete = (~X_raw.isna().any(axis=1)) & (~pd.isna(y))\n",
    "if mask_complete.sum() != len(df):\n",
    "    print(f\"Warning: dropping {len(df) - mask_complete.sum()} rows with NA in features/target.\")\n",
    "X_raw = X_raw.loc[mask_complete].reset_index(drop=True)\n",
    "y = y[mask_complete]\n",
    "\n",
    "# ---------- prepare grid ----------\n",
    "# we will enumerate lambdas for each feature in the same order as FEATURE_COLS\n",
    "lambda_combinations = list(itertools.product(LAMBDAS, repeat=len(FEATURE_COLS)))\n",
    "total_runs = len(SCALING_METHODS) * len(lambda_combinations)\n",
    "print(f\"Total permutations to run: {total_runs} ({len(SCALING_METHODS)} scaling methods * {len(lambda_combinations)} lambda combos)\")\n",
    "\n",
    "# ---------- iterate and evaluate ----------\n",
    "results = []\n",
    "kf = KFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# We'll use a progress bar:\n",
    "for scaling_method in SCALING_METHODS:\n",
    "    # First scale (same scaling for all features) -> returns DataFrame\n",
    "    X_scaled, scaling_params = scale_matrix(X_raw, scaling_method)\n",
    "\n",
    "    # For each lambda-tuple, apply boxcox per column (with shift if needed), then evaluate CV\n",
    "    # Note: shifting is done using the values after scaling. Shifts are computed per-feature so box-cox input >0.\n",
    "    for lambdas in tqdm(lambda_combinations, desc=f\"Scaling={scaling_method}\", leave=False):\n",
    "        # Copy scaled data for transformation\n",
    "        X_trans = X_scaled.copy()\n",
    "        shifts = {}\n",
    "        # Apply per-column boxcox with specified lambda\n",
    "        # # Apply Box–Cox first\n",
    "        # for i, col in enumerate(FEATURE_COLS):\n",
    "        #     lam = lambdas[i]\n",
    "        #     X_trans[col] = boxcox_transform(X_raw[col].values, lam)\n",
    "\n",
    "        # # Then scale once (same method for all 5 transformed columns)\n",
    "        # X_scaled, _ = scale_matrix(X_trans, scaling_method)\n",
    "\n",
    "        for i, col in enumerate(FEATURE_COLS):\n",
    "            lam = lambdas[i]\n",
    "            arr = X_trans[col].values.astype(float)\n",
    "            arr_shifted, shift = safe_shift_array(arr, min_allowed=1e-6)\n",
    "            # keep shift noted so you can backtrack if desired\n",
    "            shifts[col] = shift\n",
    "            # apply boxcox formula on arr_shifted\n",
    "            transformed = boxcox_transform(arr_shifted, lam)\n",
    "            # If the transformed column has NaNs or infs, handle:\n",
    "            if np.any(np.isinf(transformed)) or np.any(np.isnan(transformed)):\n",
    "                # skip this configuration as invalid\n",
    "                mean_r2 = np.nan\n",
    "                std_r2 = np.nan\n",
    "                mean_rmse = np.nan\n",
    "                std_rmse = np.nan\n",
    "                results.append({\n",
    "                    \"scaling\": scaling_method,\n",
    "                    \"lambdas\": tuple(lambdas),\n",
    "                    \"shifts\": shifts,\n",
    "                    \"mean_R2\": mean_r2,\n",
    "                    \"std_R2\": std_r2,\n",
    "                    \"mean_RMSE\": mean_rmse,\n",
    "                    \"std_RMSE\": std_rmse,\n",
    "                    \"valid\": False,\n",
    "                })\n",
    "                break\n",
    "            # replace column\n",
    "            X_trans[col] = transformed\n",
    "        else:\n",
    "            # All columns transformed properly; evaluate linear regression with CV\n",
    "            model = LinearRegression()\n",
    "            # cross_val_score for R^2\n",
    "            r2_scores = cross_val_score(model, X_trans.values, y, cv=kf, scoring=\"r2\")\n",
    "            # cross_val_score for neg MSE -> convert to RMSE\n",
    "            neg_mse_scores = cross_val_score(model, X_trans.values, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "            # convert\n",
    "            mse_scores = -neg_mse_scores\n",
    "            rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "            results.append({\n",
    "                \"scaling\": scaling_method,\n",
    "                \"lambdas\": tuple(lambdas),\n",
    "                \"shifts\": shifts,\n",
    "                \"mean_R2\": float(np.mean(r2_scores)),\n",
    "                \"std_R2\": float(np.std(r2_scores, ddof=1)),\n",
    "                \"mean_RMSE\": float(np.mean(rmse_scores)),\n",
    "                \"std_RMSE\": float(np.std(rmse_scores, ddof=1)),\n",
    "                \"valid\": True,\n",
    "            })\n",
    "\n",
    "# ---------- save results ----------\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values([\"mean_R2\"], ascending=False, na_position=\"last\").reset_index(drop=True)\n",
    "results_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Results saved to {OUTPUT_CSV}\")\n",
    "\n",
    "# ---------- print best config ----------\n",
    "if results_df[\"valid\"].any():\n",
    "    best_row = results_df.loc[results_df[\"valid\"]].iloc[0]\n",
    "    print(\"\\nBest configuration by mean R^2:\")\n",
    "    print(f\"Scaling method: {best_row['scaling']}\")\n",
    "    print(f\"Box-Cox lambdas (in order of features): {best_row['lambdas']}\")\n",
    "    print(\"Feature order: \", FEATURE_COLS)\n",
    "    print(f\"Mean R^2: {best_row['mean_R2']:.5f} (std {best_row['std_R2']:.5f})\")\n",
    "    print(f\"Mean RMSE: {best_row['mean_RMSE']:.5f} (std {best_row['std_RMSE']:.5f})\")\n",
    "else:\n",
    "    print(\"No valid configurations found (all failed). Check data for problematic values.\")\n",
    "\n",
    "# Optionally show top N\n",
    "print(\"\\nTop 5 configs (by mean R^2):\")\n",
    "print(results_df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e02fb09",
   "metadata": {},
   "source": [
    "I have a data file, suburb_info.xlsx, which contain the following non-zero positive numeric columns: number_of_houses, number_of_units, population, aus_born_perc, median_income, median_house_price. I want to make a linear model to predict median_house_price using the other 5 attributes.  for this, i want the features to be on the same scale, and to have as much linear relationship with median_house_price as possible.  \n",
    "\n",
    "to do this, i want to create the following framework:  \n",
    "each individual attribute should be transformed with box-cox power transformation with varying values of lambda (the 5 common values, -1, -0.5, 0, 0.5, 1 will do).  \n",
    "then, all 5 attributes should be scaled (with the same scale) of either:   \n",
    "1. min-max scaling to [0, 1] = $$x_{scaled} = \\frac{x - x_{min}}{x_{max} - x_{min}}$$   \n",
    "2. robust scaling: $$x_{scaled} = \\frac{x - x_{median}}{IQR(x)}$$   \n",
    "\n",
    "the framework should run a simple linear model on every permutation of picking one scaling method for all 5 attributes, and then varying lambda values for box-cox transformation for each of the 5 attributes.  \n",
    "save the RMSE and R^2 metrics for each permutation, and denote which scaling and box-cox lambda parameters yields the best R^2 value.  \n",
    "to optimize performance, use only 3-fold CV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb4a74d",
   "metadata": {},
   "source": [
    "I have a data file, suburb_info.xlsx, which contain the following numeric columns: number_of_houses, number_of_units, population, aus_born_perc, median_income, median_house_price. I want to make a linear model to predict median_house_price using the other 5 attributes. for this, i want the features to be on the same scale, and to have as much linear relationship with median_house_price as possible.  \n",
    "to do this, i want to create the following framework:  \n",
    "first, all 5 attributes should be scaled (with the same scale) of either: 1. min-max scaling to [0, 1] = $$x_{scaled} = \\frac{x - x_{min}}{x_{max} - x_{min}}$$ 2. robust scaling: $$x_{scaled} = \\frac{x - x_{median}}{IQR(x)}$$ then, each individual attribute should be transformed with box-cox power transformation with varying values of lambda (the 5 common values, -1, -0.5, 0, 0.5, 1 will do). the framework should run a simple linear model on every permutation of picking one scaling method for all 5 attributes, and then varying lambda values for box-cox transformation for each of the 5 attributes. save the RMSE and R^2 metrics for each permutation, and denote which scaling and box-cox lambda parameters yields the best R^2 value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
