{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d1d825",
   "metadata": {},
   "source": [
    "# Optimizers and Practical Skills\n",
    "## Deep Learning Toolbox\n",
    "### Data processing\n",
    "Data augmentation  \n",
    "- Flip, rotate, random crop, colour shift, noise addition, information loss, contrast change  \n",
    "- Batch normalization  \n",
    "\n",
    "Training neural network parameters  \n",
    "- Epoch  \n",
    "- Mini-batch gradient descent  \n",
    "- Loss function  \n",
    "    - Cross-entropy loss\n",
    "\n",
    "Finding optimal weights  \n",
    "- Backpropagation weight update  \n",
    "\n",
    "Parameter tuning - Weights initialization  \n",
    "- Xavier initialization  \n",
    "    - Instead of random initialization, initialize to take into account characteristics unique to the architecture  \n",
    "- Transfer learning\n",
    "    - Can freeze all layers and train only on classifier/last layers and classifier or retrain all depending on how much training we have  \n",
    "\n",
    "Optimizing convergence  \n",
    "- Learning rate  \n",
    "- Adaptive learning rates  \n",
    "\n",
    "Regularization  \n",
    "- Dropout  \n",
    "- Weight regularization  \n",
    "    - Lasso: L1 regularization, shrinks coefficients to 0  \n",
    "    - Ridge: L2 regularization, makes coefficients smaller  \n",
    "    - Elastic Net: L1+L2, trade off being variable selection and small coefficients  \n",
    "- Early stopping  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b09b5",
   "metadata": {},
   "source": [
    "# ðŸ§  Neural Network Debugging Checklist (Quick Notes)\n",
    "\n",
    "## 0. First Response\n",
    "- âœ… Use simple baseline model (e.g., VGG for images).  \n",
    "- âœ… Standard loss, no custom functions.  \n",
    "- âœ… Disable regularization & augmentation.  \n",
    "- âœ… Check preprocessing (esp. for finetuning).  \n",
    "- âœ… Verify input data visually.  \n",
    "- âœ… Overfit on a tiny dataset (2â€“20 samples).  \n",
    "- âœ… Add complexity back gradually.  \n",
    "\n",
    "---\n",
    "\n",
    "## I. Dataset Issues\n",
    "- ðŸ“¸ Check input/labels (e.g., swapped dims, wrong batch, all zeroes).  \n",
    "- ðŸŽ² Feed random input â†’ if same error, data not used properly.  \n",
    "- ðŸ› ï¸ Validate data loader â†’ inspect first layerâ€™s input.  \n",
    "- ðŸ”— Ensure correct label mapping & shuffling.  \n",
    "- â“ Check if inputâ€“output relationship is meaningful.  \n",
    "- ðŸ”Š Inspect dataset noise & mislabels.  \n",
    "- ðŸ”€ Shuffle dataset properly.  \n",
    "- âš–ï¸ Handle class imbalance (loss balancing, resampling).  \n",
    "- ðŸ“ˆ Enough training examples? (~1k images/class for scratch training).  \n",
    "- ðŸ—‚ï¸ Ensure batches arenâ€™t single-label.  \n",
    "- ðŸ“¦ Reduce batch size if too large.  \n",
    "- ðŸ·ï¸ Use standard datasets first (MNIST, CIFAR-10) to validate pipeline.  \n",
    "\n",
    "---\n",
    "\n",
    "## II. Data Normalization / Augmentation\n",
    "- ðŸ“ Standardize features (zero mean, unit variance).  \n",
    "- ðŸ”„ Avoid excessive augmentation â†’ underfitting risk.  \n",
    "- ðŸ–¼ï¸ Match pretrained model preprocessing ([0,1], [-1,1], [0,255]).  \n",
    "- ðŸ“Š Train/val/test preprocessing split correctly (train-only stats).  \n",
    "\n",
    "---\n",
    "\n",
    "## III. Implementation Issues\n",
    "- ðŸ§© Solve simpler subproblem first.  \n",
    "- ðŸŽ¯ Check loss â€œat chanceâ€ (e.g., 10 classes â†’ CE loss â‰ˆ 2.302).  \n",
    "- âš ï¸ Verify loss function (bugs in custom loss?).  \n",
    "- ðŸ›‘ Ensure correct inputs to loss (NLLLoss vs CrossEntropyLoss).  \n",
    "- âš–ï¸ Balance multi-loss weights.  \n",
    "- ðŸ“Š Track multiple metrics (not just loss).  \n",
    "- ðŸ§ª Unit test custom layers.  \n",
    "- ðŸ”’ Check for unintentionally frozen layers.  \n",
    "- ðŸ—ï¸ Increase network size if too weak.  \n",
    "- ðŸ”¢ Use unusual dims (primes) to detect shape errors.  \n",
    "- ðŸ§® Gradient checking (if manual backprop).  \n",
    "\n",
    "---\n",
    "\n",
    "## IV. Training Issues\n",
    "- ðŸ” Overfit tiny subset (1â€“2 samples).  \n",
    "- ðŸŽ² Try different weight inits (Xavier, He).  \n",
    "- ðŸ”§ Tune hyperparams (grid/random search).  \n",
    "- ðŸš« Reduce reg. if underfitting (dropout, weight decay, BN).  \n",
    "- â³ Allow more training time if loss steadily â†“.  \n",
    "- ðŸ”€ Switch Train â†” Test mode correctly (BN, dropout).  \n",
    "- ðŸ‘ï¸ Visualize training (weights, activations, updates, TensorBoard).  \n",
    "- ðŸ“‰ Check activations (std ~ 0.5â€“2.0) for vanishing/exploding.  \n",
    "- âš¡ Try different optimizer (Adam, SGD+momentum).  \n",
    "- ðŸŽšï¸ Adjust learning rate (Ã—0.1 or Ã—10).  \n",
    "- ðŸš« Debug NaNs (reduce LR, check div/0, log(â‰¤0), trace layer by layer).  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5370eab8",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "## Quiz Questions Explained\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1: Gradient Norm and Critical Points\n",
    "\n",
    "* **The Question:** This question asks what it means for the training process when the gradient norm, $||g||_{2}$, which represents the overall magnitude of the gradient of the loss function, approaches zero. ðŸ“‰\n",
    "* **Correct Answer Explained:**\n",
    "    * **D. One of A, B, C.** A gradient of zero is the definition of a **critical point** on the loss surface. A critical point is a location where the surface is flat. This can be a **local minimum** (a \"valley\" that we want to find), a **local maximum** (a \"peak\" that we want to avoid), or a **saddle point** (a point that looks like a minimum in some directions and a maximum in others). Since the training process stops at any of these, the correct answer is that it could be any of the three.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2: Xavier Initialization\n",
    "\n",
    "* **The Question:** This asks which activation functions are suitable for Xavier (or Glorot) weight initialization.\n",
    "* **Correct Answers Explained:**\n",
    "    * **A. Sigmoid** and **B. Tanh.** Xavier initialization was designed to keep the variance of activations and gradients constant across layers. Its mathematical derivation works best for activation functions that are symmetric around zero and are roughly linear in that region. **Tanh** is a perfect fit. **Sigmoid** also works reasonably well, although it's not zero-centered. Xavier is less suitable for ReLU.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3: He Initialization\n",
    "\n",
    "* **The Question:** This asks which activation function is the primary target for He initialization.\n",
    "* **Correct Answer Explained:**\n",
    "    * **C. ReLU.** The ReLU activation function is not symmetric and zeroes out all negative values. He initialization was specifically developed to address this, adjusting the initialization variance to account for the fact that roughly half the neurons will be inactive. This prevents the gradients from vanishing or exploding when using ReLU and its variants (like Leaky ReLU).\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4: Vanishing Gradient Problem\n",
    "\n",
    "* **The Question:** This asks for the definition of the vanishing gradient problem.\n",
    "* **Correct Answer Explained:**\n",
    "    * **C. Too small gradient at any layer of model.** The vanishing gradient problem occurs in deep networks when gradients become extremely small as they are propagated backward from the output layer to the earlier layers. While the effect is most severe in the layers closest to the input, the core issue is the diminishing gradient signal throughout the network, which causes learning to slow down or stop entirely. \n",
    "\n",
    "---\n",
    "\n",
    "### Question 5: Exploding Gradient Problem\n",
    "\n",
    "* **The Question:** This asks for the definition of the exploding gradient problem.\n",
    "* **Correct Answer Explained:**\n",
    "    * **A. Too big gradient at any layer of model.** This is the opposite problem. Gradients grow exponentially as they are backpropagated, resulting in excessively large weight updates. This makes the training process unstable, often causing the loss to become `NaN` (Not a Number) and preventing the model from converging. \n",
    "\n",
    "---\n",
    "\n",
    "### Question 6: Mitigating Vanishing Gradients\n",
    "\n",
    "* **The Question:** This asks which architectural components or techniques can help solve the vanishing gradient problem.\n",
    "* **Correct Answers Explained:**\n",
    "    * **E. Batch normalization layer:** By normalizing the activations at each layer, Batch Norm ensures they don't fall into the saturating regions of activation functions (like sigmoid/tanh), which helps maintain a healthier gradient flow. \n",
    "    * **F. Skip connection layer:** Popularized by ResNet, skip connections create a direct \"highway\" for the gradient to flow backward through the network, bypassing layers that might otherwise diminish it. \n",
    "    * **G. ReLU Activation:** Unlike sigmoid and tanh, ReLU has a constant gradient of 1 for all positive inputs. This prevents the multiplicative shrinking of the gradient as it passes through many layers. \n",
    "\n",
    "---\n",
    "\n",
    "### Question 7: Underfitting\n",
    "\n",
    "* **The Question:** This asks for the correct characteristics of underfitting.\n",
    "* **Correct Answers Explained:**\n",
    "    * **A. We use a simple model family to characterize and learn from more complex data:** Underfitting occurs when a model has insufficient capacity (it's too simple) to capture the underlying patterns in the dataset. \n",
    "    * **E. Both training and valid accuracies are low:** This is the tell-tale sign of underfitting. The model performs poorly not just on new data but also on the data it was trained on, indicating it failed to learn the task adequately. \n",
    "\n",
    "---\n",
    "\n",
    "### Question 8: Overfitting\n",
    "\n",
    "* **The Question:** This asks for the correct characteristics of overfitting.\n",
    "* **Correct Answers Explained:**\n",
    "    * **B. We use powerful deep nets to learn from simple data:** Overfitting often happens when a model is too complex for the amount of data available. It starts to memorize the training data, including its noise, instead of learning the generalizable patterns. \n",
    "    * **C. The training accuracy is high and the valid accuracy is low:** This is the classic symptom. The model excels on the data it has seen but fails to generalize to new, unseen data, creating a large performance gap. \n",
    "\n",
    "---\n",
    "\n",
    "### Question 9: Identifying Overfitting in Practice\n",
    "\n",
    "* **The Question:** Given a baseline of >90% accuracy for MNIST, which scenario shows overfitting?\n",
    "* **Correct Answer Explained:**\n",
    "    * **A. Training accuracy: 99%, Testing accuracy: 50%.** This demonstrates a massive gap between training and testing performance. The model has clearly memorized the training set (99% accuracy) but is unable to generalize its knowledge to the test set (only 50% accuracy), which is a clear case of severe overfitting. \n",
    "\n",
    "---\n",
    "\n",
    "### Question 10: Identifying Underfitting in Practice\n",
    "\n",
    "* **The Question:** In the same context, which scenarios show underfitting?\n",
    "* **Correct Answers Explained:**\n",
    "    * **C. Training accuracy: 70%, Testing accuracy: 40%** and **D. Training accuracy: 30%, Testing accuracy: 40%.** In both of these cases, the training accuracy (70% and 30%) is far below the achievable baseline of >90%.  This indicates that the model has failed to even learn the training data properly, which is the definition of underfitting. \n",
    "\n",
    "---\n",
    "\n",
    "### Question 11: Conditions for Overfitting\n",
    "\n",
    "* **The Question:** Which situation is more likely to lead to overfitting?\n",
    "* **Correct Answer Explained:**\n",
    "    * **A. Very big model with few images.** A high-capacity (\"big\") model has the flexibility to learn extremely complex functions. When given only a small dataset (\"few images\"), it can easily achieve low training error by essentially memorizing the individual examples instead of learning the underlying, generalizable pattern. \n",
    "\n",
    "---\n",
    "\n",
    "### Question 12: Visualizing Overfitting\n",
    "\n",
    "* **The Question:** By comparing two training plots, determine which one shows less overfitting.\n",
    "* * **Correct Answer Explained:**\n",
    "    * **B. B is less overfitting than A.** Overfitting is visually identified by the **gap** between the training accuracy curve and the validation/testing accuracy curve. Plot A shows a large gap between the final training accuracy (87%) and validation accuracy (57%). Plot B shows a much smaller gap (88% vs 62%). A smaller gap indicates better generalization and less overfitting. \n",
    "\n",
    "---\n",
    "\n",
    "### Question 13: Techniques to Reduce Overfitting\n",
    "\n",
    "* **The Question:** This asks which common techniques are used to combat overfitting.\n",
    "* **Correct Answers Explained:**\n",
    "    * **B. Early stopping:** This technique involves monitoring the validation loss and stopping the training process when it stops improving, even if the training loss is still decreasing. This prevents the model from overfitting in later epochs. \n",
    "    * **C. Adding more data:** Providing more diverse training examples is often the best way to combat overfitting, as it makes it harder for the model to simply memorize the data. \n",
    "    * **D. Weight regularization:** Methods like L1 and L2 regularization add a penalty to the loss function based on the size of the model's weights, encouraging simpler models that are less likely to overfit. \n",
    "    * **F. Using Dropout:** Dropout is a regularization technique where a random fraction of neurons are temporarily \"dropped out\" (ignored) during each training step. This forces the network to learn more robust features. \n",
    "\n",
    "---\n",
    "\n",
    "### Question 14: Batch Normalization Parameters\n",
    "\n",
    "* **The Question:** In the batch normalization algorithm, which variables are learnable parameters?\n",
    "* **Correct Answers Explained:**\n",
    "    * **C. Scaling parameter $\\gamma$** and **D. Shifting parameter $\\beta$.** The minibatch mean ($\\mu_B$) and standard deviation ($\\sigma_B$) are **calculated** from the current batch of data; they are not learned via gradient descent. After an input is normalized, it is then scaled by a learnable parameter $\\gamma$ and shifted by a learnable parameter $\\beta$. These two parameters allow the network to learn the optimal scale and shift for the features at that layer, giving it the flexibility to even reverse the normalization if that proves beneficial. \n",
    "\n",
    "---\n",
    "\n",
    "### Question 15: Data Augmentation\n",
    "\n",
    "* **The Question:** Given a training set of only blue cars and a test set of multi-colored cars, what data augmentation strategies are appropriate?\n",
    "* * **Correct Answer Explained:**\n",
    "    * **C. Horizontally flipping and color shift.** The training data has a clear bias: all cars are blue.  The test data, however, contains cars of various colors (yellow, red, gray).  If the model is trained only on blue cars, it might learn that \"blue\" is a key feature for identifying a car, which is incorrect. To fix this, **color shift** (or color jitter) augmentation is essential to teach the model to ignore color and focus on shape. **Horizontally flipping** is also a sensible augmentation because a car is still a car if its image is mirrored. \n",
    "\n",
    "## Revision Notes: Key Takeaways\n",
    "\n",
    "### 1. Training Dynamics\n",
    "* **Critical Points:** When the gradient norm $||g||_2 \\to 0$, training has stopped at a critical point, which can be a **local minimum**, **local maximum**, or **saddle point**.\n",
    "* **Vanishing Gradients:** Gradients become too small, preventing early layers from learning.\n",
    "* **Exploding Gradients:** Gradients become too large, making training unstable.\n",
    "* **Solutions for Gradients:**\n",
    "    * **Weight Initialization:** Use **Xavier/Glorot** for `tanh`/`sigmoid` and **He** for `ReLU`.\n",
    "    * **Architectural Choices:** Use **ReLU** activation, **Batch Normalization**, and **Skip Connections** (ResNet).\n",
    "\n",
    "### 2. Overfitting vs. Underfitting\n",
    "* **Underfitting:**\n",
    "    * **Cause:** Model is too simple for the data.\n",
    "    * **Symptom:** Both **training and validation accuracy are low**. The model fails to learn the data.\n",
    "* **Overfitting:**\n",
    "    * **Cause:** Model is too complex for the amount of data (e.g., big model, small dataset).\n",
    "    * **Symptom:** **High training accuracy** but **low validation accuracy**. There's a large gap between the two. The model memorizes the training data but doesn't generalize.\n",
    "\n",
    "### 3. Regularization (Fighting Overfitting)\n",
    "* **Get More Data:** The most effective solution is often to increase the size and diversity of the training set.\n",
    "* **Data Augmentation:** Create more training data by applying realistic transformations (e.g., **horizontal flipping**, **color shifts**). Choose augmentations that reflect real-world variations.\n",
    "* **Model Simplification:** Use a smaller model (fewer layers/neurons).\n",
    "* **Regularization Techniques:**\n",
    "    * **Early Stopping:** Stop training when validation performance starts to worsen.\n",
    "    * **Weight Regularization (L1/L2):** Penalize large weights to encourage a simpler model.\n",
    "    * **Dropout:** Randomly ignore a fraction of neurons during training to force the network to learn robust features.\n",
    "\n",
    "### 4. Batch Normalization\n",
    "* **Goal:** Stabilizes and accelerates training by normalizing the inputs to each layer.\n",
    "* **Process:** For each mini-batch, it calculates the mean and standard deviation and uses them to normalize the data.\n",
    "* **Trainable Parameters:** It introduces two learnable parameters per feature: a scaling factor **gamma ($\\gamma$)** and a shifting factor **beta ($\\beta$)**. These allow the network to learn the optimal distribution for each layer's activations."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
