{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM3_3zdIK150"
      },
      "source": [
        "# <span style=\"color:#0b486b\">  FIT3181/5215: Deep Learning (2025)</span>\n",
        "***\n",
        "*CE/Lecturer (Clayton):*  **Dr Trung Le** | trunglm@monash.edu <br/>\n",
        "*Lecturer (Clayton):* **A/Prof Zongyuan Ge** | zongyuan.ge@monash.edu <br/>\n",
        "*Lecturer (Malaysia):*  **Dr Arghya Pal** | arghya.pal@monash.edu <br/>\n",
        " <br/>\n",
        "*Head Tutor 3181:*  **Ms Ruda Nie H** |  \\[RudaNie.H@monash.edu \\] <br/>\n",
        "*Head Tutor 5215:*  **Ms Leila Mahmoodi** |  \\[leila.mahmoodi@monash.edu \\]\n",
        "\n",
        "<br/> <br/>\n",
        "Faculty of Information Technology, Monash University, Australia\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP70kaB6K153"
      },
      "source": [
        "# <span style=\"color:#0b486b\">Tutorial 09b: Seq2seq for Machine Translation</span><span style=\"color:red\">****</span>\n",
        "\n",
        "**This tutorial shows you a famous application of seq2seq which is machine translation. Basically, we build up a seq2seq model to translate English to French in which the source sentences are English sentences, whereas the target sentences are French ones. More specifically, we explore**\n",
        "- Seq2seq machine translation without attention mechanism.\n",
        "-  Seq2seq machine translation with attention mechanism."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYT04_-3K153"
      },
      "source": [
        "**References and additional reading and resources**\n",
        "- Here is the link for a tutorial on image captioning application [link](https://www.tensorflow.org/tutorials/text/image_captioning).\n",
        "- A blog that explains the BLEU score and how to compute this score [link](https://machinelearningmastery.com/calculate-bleu-score-for-text-python/).\n",
        "- The reference if you want to explore BERT, a SOTA deep learning model for sequential data with self-attention mechanism [link](http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/).\n",
        "\n",
        "*Acknowledgment: this tutorial was developed based on the Chapter 8 materials from the book `Deep Learning with TensorFlow 2 and Keras (TF 2.x edition)`.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:#0b486b\"> 0. Set up</span> <span style=\"color:red\"></span>\n",
        "You need to download relevant files to run this notebook on Google Colab."
      ],
      "metadata": {
        "id": "PcjjRXro08wS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1J6ldngMZ-84Et5IPHG8S-mYE2BBJMz48"
      ],
      "metadata": {
        "id": "GtjUsUojvKSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4085e2eb-d2b7-4e09-ac30-0ea3e738889c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1J6ldngMZ-84Et5IPHG8S-mYE2BBJMz48\n",
            "From (redirected): https://drive.google.com/uc?id=1J6ldngMZ-84Et5IPHG8S-mYE2BBJMz48&confirm=t&uuid=fbfb5507-125e-4051-b6ad-d44cf27ff734\n",
            "To: /content/Tut11_data.zip\n",
            "100% 223M/223M [00:02<00:00, 90.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q Tut11_data.zip"
      ],
      "metadata": {
        "id": "PXIPYPByvypL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nus9SyYlK155"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import math\n",
        "import copy\n",
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "import shutil\n",
        "import os\n",
        "import unicodedata\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPdI5hDZK156"
      },
      "source": [
        "It is the time to set random seeds for PyTorch and numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtNa0A4UK156"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(6789)\n",
        "np.random.seed(6789)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iBtuCIhK156"
      },
      "source": [
        "## <span style=\"color:#0b486b\">I. Introduction of Dataset</span> ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqiH0KJJK156"
      },
      "source": [
        "We use the French-English bilingual dataset from the Tatoeba Project (1997-2019). The dataset contains approximately $167,000$ sentence pairs. To make our training go faster, we will only consider the first $1,000$ sentence pairs for our training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEFXLv96K157"
      },
      "source": [
        "## <span style=\"color:#0b486b\">II. Neural Machine Translation Without Attention Mechanism</span> <span style=\"color:red\">****</span> ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUZbmei2K157"
      },
      "source": [
        "The following function supports preprocessing input sentences. We employ regular expressions for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jcc7ak9AK157"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sent):\n",
        "    sent = \"\".join([c for c in unicodedata.normalize(\"NFD\", sent) if unicodedata.category(c) != \"Mn\"])\n",
        "    sent = re.sub(r\"([!.?])\", r\" \\1\", sent)\n",
        "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
        "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "    sent = sent.lower()\n",
        "    return sent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfgrNnKAK157"
      },
      "source": [
        "The following function assists us in reading sentences from a file located on the hard disk. This function returns three lists of sentences:\n",
        "- `en_sents` contains the list of English input sentences.\n",
        "- `fr_sents_in` contains the list of French sentences starting with the specific symbol **BOS**, meaning `Beginning Of Sentence`. To form a sentence in fr_sents_in, we start from a sentence in French list and insert BOS at the begining.\n",
        "- `fr_sents_out` contains the list of French sentences ending with the specific symbol **EOS**, meaning `End Of Sentence`. To form a sentence in fr_sents_out, we start from a sentence in French list and insert EOS at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VMf7rgcK157"
      },
      "outputs": [],
      "source": [
        "def read_data(num_sent_pairs =20000):\n",
        "    en_sents, fr_sents_in, fr_sents_out = [], [], []\n",
        "    local_file = os.path.join(\"datasets\", \"fra.txt\")\n",
        "    with open(local_file, \"r\") as fin:\n",
        "        for i, line in enumerate(fin):\n",
        "            en_sent, fr_sent, _ = line.strip().split('\\t')\n",
        "            en_sent = [w for w in preprocess_sentence(en_sent).split()]\n",
        "            fr_sent = preprocess_sentence(fr_sent)\n",
        "            fr_sent_in = [w for w in (\"BOS \" + fr_sent).split()]\n",
        "            fr_sent_out = [w for w in (fr_sent + \" EOS\").split()]\n",
        "            en_sents.append(en_sent)\n",
        "            fr_sents_in.append(fr_sent_in)\n",
        "            fr_sents_out.append(fr_sent_out)\n",
        "            if i >= num_sent_pairs - 1:\n",
        "                break\n",
        "    return en_sents, fr_sents_in, fr_sents_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzA4jvqkK157"
      },
      "source": [
        "We set `NUM_SENT_PAIRS= 1000` to read $1,000$ bilingual sentences from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCojLNlfK157"
      },
      "outputs": [],
      "source": [
        "NUM_SENT_PAIRS = 1000\n",
        "sents_en, sents_fr_in, sents_fr_out = read_data(NUM_SENT_PAIRS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74u6-XS3K157"
      },
      "source": [
        "We print the first five sentences in `fr_sent_in`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA-jI9pTK157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96305131-33c4-4da3-c7b4-4050faaba2e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['BOS', 'va', '!'], ['BOS', 'salut', '!'], ['BOS', 'salut', '.'], ['BOS', 'cours', '!'], ['BOS', 'courez', '!']]\n"
          ]
        }
      ],
      "source": [
        "print(sents_fr_in[0:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKVmqhbrK157"
      },
      "source": [
        "We print the first five sentences in `fr_sent_out`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4hSvCscK157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98492a78-fe9e-4641-ae6c-26eb2c96db3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['va', '!', 'EOS'], ['salut', '!', 'EOS'], ['salut', '.', 'EOS'], ['cours', '!', 'EOS'], ['courez', '!', 'EOS']]\n"
          ]
        }
      ],
      "source": [
        "print(sents_fr_out[0:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXWIaocUK158"
      },
      "source": [
        "We now create vocabularies, dictionaries, and numeric datasets from three lists of sentences. Specifically, we achieve\n",
        "- `data_en` contains sequences of indices for sents_en.\n",
        "- `data_fr_in` contains sequences of indices for sents_fr_in.\n",
        "- `data_fr_out` contains sequences of indices for sents_fr_out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHzzkQJCK158"
      },
      "source": [
        "We then build up dictionaries and vocabularies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qw-xjjEyK158",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70bf94a6-80d3-487e-f493-6b3922b8084e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "Um0317IA0lHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`The build_vocab_from_iterator function` creates a vocabulary from a sequence of token lists by counting the frequency of each token using the Counter class. It first updates the token counts from the provided iterator. After counting, it sorts the tokens by their frequency, placing the special tokens (if provided) at the beginning of the sorted list. It then constructs a dictionary where each token is mapped to a unique index based on its position in the sorted list, with special tokens receiving indices before other tokens. This vocabulary dictionary is returned, mapping each token to its corresponding index in the vocabulary."
      ],
      "metadata": {
        "id": "EUurs1Jlf6ID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build vocabulary using Counter and add special tokens\n",
        "def build_vocab_from_iterator(iterator, specials=None):\n",
        "    word_freq = Counter()\n",
        "    for tokens in iterator:\n",
        "        word_freq.update(tokens)\n",
        "\n",
        "    # sort words by frequency (most common first) and include special tokens\n",
        "    sorted_vocab = specials + [word for word, freq in word_freq.most_common()]\n",
        "    vocab = {word: idx for idx, word in enumerate(sorted_vocab)}\n",
        "\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "EovnlC2Q0ocT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import islice\n",
        "# build the vocabulary\n",
        "en_vocab = build_vocab_from_iterator(sents_en, specials=[\"<pad>\"])\n",
        "\n",
        "# print the vocabulary and default index\n",
        "print(\"English Vocabulary:\", dict(islice(en_vocab.items(),10)))\n",
        "\n",
        "word2idx_en = en_vocab\n",
        "idx2word_en = {idx: word for word, idx in en_vocab.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDmpjr6m0r1L",
        "outputId": "0a65d472-9228-406b-ad39-4ba2e858f479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Vocabulary: {'<pad>': 0, '.': 1, 'i': 2, '!': 3, 'm': 4, 'it': 5, 's': 6, 'go': 7, 'tom': 8, '?': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the vocabulary\n",
        "fr_vocab = build_vocab_from_iterator(sents_fr_in, specials=[\"<pad>\",\"EOS\"])\n",
        "\n",
        "# print the vocabulary and default index\n",
        "print(\"French Vocabulary:\", dict(islice(fr_vocab.items(),10)))\n",
        "\n",
        "word2idx_fr = fr_vocab\n",
        "idx2word_fr = {idx: word for word, idx in fr_vocab.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Owcu2x1T01Ta",
        "outputId": "019e42ac-38ed-4695-a428-0b2dd2b1abf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French Vocabulary: {'<pad>': 0, 'EOS': 1, 'BOS': 2, '.': 3, '!': 4, 'je': 5, 'suis': 6, 'est': 7, 'j': 8, 'ai': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_lengths = np.array([len(s) for s in sents_en])\n",
        "print([(p, np.percentile(seq_lengths, p)) for p in [75, 80, 90, 95, 99, 100]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA_EZ-_j1I_T",
        "outputId": "83d65b97-b990-4847-d839-9e4010089e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(75, 4.0), (80, 4.0), (90, 4.0), (95, 4.0), (99, 4.0), (100, 5.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_lengths = np.array([len(s) for s in sents_fr_in])\n",
        "print([(p, np.percentile(seq_lengths, p)) for p in [75, 80, 90, 95, 99, 100]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW2ANp3x1M7k",
        "outputId": "ea5f5146-0c20-4595-b71a-05b174bb29fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(75, 5.0), (80, 5.0), (90, 6.0), (95, 7.0), (99, 9.0), (100, 10.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY-XR_QtK158"
      },
      "source": [
        "\n",
        "We now transform texts to sequences of indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpzJWiejK158"
      },
      "outputs": [],
      "source": [
        "en_seq_len = 5\n",
        "fr_seq_len = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`The create_pad_sequences function` converts sentences into sequences of indices, pads or truncates them to a specified length, and returns them as a tensor. It first transforms each sentence into a list of token indices using a vocabulary dictionary. Each sequence is then truncated to a maximum length if it exceeds the specified seq_len, and padded with zeros if it is shorter. Finally, the function converts the list of padded and truncated sequences into a PyTorch tensor of type long for further processing."
      ],
      "metadata": {
        "id": "U5lCTg1XgPfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def create_pad_sequences(sents, vocab, seq_len):\n",
        "  # transform sentences to sequences of indices (list of lists of indices)\n",
        "  sentences_as_ints = [[vocab[token] for token in tokens] for tokens in sents]\n",
        "  # pad and truncate sequences\n",
        "  padded_sequences = []\n",
        "  for seq in sentences_as_ints:\n",
        "    if len(seq) > seq_len:\n",
        "      seq = seq[: seq_len]\n",
        "    # pad sequence to max_sequence_length\n",
        "    padding_length = seq_len - len(seq)\n",
        "    if padding_length > 0:\n",
        "        seq.extend([0] * padding_length)  # extend with padding values\n",
        "    padded_sequences.append(seq)\n",
        "  # convert list of lists to tensor\n",
        "  truncated_padded_sequences = torch.tensor(padded_sequences, dtype=torch.long)\n",
        "  return truncated_padded_sequences"
      ],
      "metadata": {
        "id": "s4saE3GN2Sdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a PyTorch dataset with three components: `data_en, data_fr_in, data_fr_out` and a train_loader for this dataset."
      ],
      "metadata": {
        "id": "ZynbOCMX2oOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "en_padded_sequences = create_pad_sequences(sents_en, en_vocab, en_seq_len)\n",
        "fr_in_padded_sequences = create_pad_sequences(sents_fr_in, fr_vocab, fr_seq_len)\n",
        "dataset = TensorDataset(en_padded_sequences, fr_in_padded_sequences)\n",
        "fr_out_padded_sequences = create_pad_sequences(sents_fr_out, fr_vocab, fr_seq_len)\n",
        "dataset = TensorDataset(en_padded_sequences, fr_in_padded_sequences, fr_out_padded_sequences)"
      ],
      "metadata": {
        "id": "x7UK2ADx2dzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "DD7NvvUs2kW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7o7jXbrK158"
      },
      "source": [
        "We now declare  `Encoder` which is the first component of a seq2seq model with the aim to encode an input sentence to a fix-length encode or context vector. Please pay attention to the code of the `call` method.\n",
        "- We first embed the input `x` (a sequence of indices) to a 2D tensor using an embedding layer. In addition, when training we input to an embedding layer a 2D tensor x with the shape $[batch\\_size, seq\\_len]$ and receive output as a 3D tensor with the shape $[batch\\_size, seq\\_len, embed\\_size]$ (embedding_dim in our code).\n",
        "- Next, we feed the output from the embedding layer to a GRU recurrent layer and receive a 2D tensor with the shape $[batch\\_size, encoder\\_dim]$ (`return_sequences=False`) which is the last hidden state considered as the encode or context vector.\n",
        "- Note that the encoder returns `x` as a 2D tensor and `state` as a 2D tensor with the shape $[batch\\_size, encoder\\_dim]$ which stands for the last hidden state of the GRU recurrent layer (they are identical). The last hidden state can be regarded as the encoding of the entire input sentence."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, encoder_dim, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.encoder_dim = encoder_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.gru = nn.GRU(embed_size, encoder_dim, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        all_hiddens, last_hidden = self.gru(embedded)\n",
        "        return all_hiddens, last_hidden"
      ],
      "metadata": {
        "id": "K0iPUKYM3BtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1Wq1ouMK158"
      },
      "source": [
        "The second component of a seq2seq model is a decoder. Our decoder takes input x as a batch in `data_fr_in` with the shape $[batch\\_size, seq\\_len]$.\n",
        "- x is inputted to an embedding layer and outputs a 3D tensor with shape $[batch\\_size, seq\\_len, embedding\\_dim]$.\n",
        "- The above 3D tensor output is then fed to a GRU recurrent layer. Note that the statement  `x, state = self.rnn(x, state)` means that we initialize the first hidden state of our GRU recurrent layer with `state` (later we will know it is the last hidden state or encoded from the encoder) and this returns a 3D tensor output and the last hidden state of this GRU recurrent layer.\n",
        "- Finally, on the top of each hidden layer in x, we conduct a dense layer with $vocab\\_size$ used to predict the next word in a French sentence."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, decoding_dim):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.gru = nn.GRU(embed_size, decoding_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(decoding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_state, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(fr_vocab['BOS'])\n",
        "        decoder_state = encoder_state\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(fr_seq_len):\n",
        "            decoder_output, decoder_state  = self.forward_step(decoder_input, decoder_state)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs, decoder_state\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        embeded = self.embedding(input)\n",
        "        output, hidden = self.gru(embeded, hidden)\n",
        "        output = self.fc(output)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "6BvnoBXi39JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LPuldkDK158"
      },
      "source": [
        "We now declare `encoder` as an Encoder and `decoder` as a Decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2y9_ubyK158"
      },
      "outputs": [],
      "source": [
        "embed_size = 256\n",
        "encoder_dim, decoder_dim = 512, 512\n",
        "encoder = EncoderRNN(len(en_vocab), embed_size, encoder_dim).to(device)\n",
        "decoder = DecoderRNN(len(fr_vocab), embed_size, decoder_dim).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL-0yOBKK158"
      },
      "source": [
        "This code shows you the flow of how to feed an  English sentence to the encoder and a French sentence to the decoder. Note that when we run `encoder(encoder_in, encoder_state)`, the method `call` is really invoked and the input batch and encoder_state (a zero 2D tensor) are passed to the encoder.\n",
        "\n",
        "In addition, when we run `decoder(decoder_in, decoder_state)`, the method `call` is really invoked and we pass to this method a batch of French sentences in `data_fr_in`. Note that the first hidden state of the decoder is initialized with the last hidden state of the encoder."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for en_data, fr_in_data, fr_out_data  in train_loader:\n",
        "    en_data, fr_in_data, fr_out_data = en_data.to(device), fr_in_data.to(device), fr_out_data.to(device)\n",
        "    break\n",
        "encoder_out, encoder_state = encoder(en_data)\n",
        "decoder_pred, decoder_state = decoder(encoder_out, encoder_state, fr_out_data)\n",
        "\n",
        "print(\"encoder input :\", en_data.shape)\n",
        "print(\"encoder output :\", encoder_out.shape, \"state:\", encoder_state.shape)\n",
        "print(\"decoder output (logits):\", decoder_pred.shape, \"state:\", decoder_state.shape)\n",
        "print(\"decoder output (labels):\", decoder_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09LQSceYxCqe",
        "outputId": "61276f98-c038-4339-ec83-4989b5a71b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder input : torch.Size([32, 5])\n",
            "encoder output : torch.Size([32, 5, 512]) state: torch.Size([1, 32, 512])\n",
            "decoder output (logits): torch.Size([32, 10, 710]) state: torch.Size([1, 32, 512])\n",
            "decoder output (labels): torch.Size([1, 32, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)"
      ],
      "metadata": {
        "id": "MasPeIBAQsmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def predict(encoder, decoder, en_vocab, sents_en, sents_fr_out, word2idx_fr, idx2word_fr, en_seq_len, fr_seq_len):\n",
        "    random_id = np.random.choice(len(sents_en))\n",
        "    print(\"input : \", \" \".join(sents_en[random_id]))\n",
        "    print(\"label : \", \" \".join(sents_fr_out[random_id]))\n",
        "\n",
        "    # Prepare encoder input and initial state\n",
        "    seq_ints = [en_vocab[token] for token in sents_en[random_id]]\n",
        "    if len(seq_ints) > en_seq_len:\n",
        "        seq_ints = seq_ints[:en_seq_len]\n",
        "    else:\n",
        "        padding_length = en_seq_len - len(seq_ints)\n",
        "        if padding_length > 0:\n",
        "            seq_ints.extend([0] * padding_length)\n",
        "    encoder_in = torch.unsqueeze(torch.tensor(seq_ints), dim=0).to(device)\n",
        "\n",
        "    # Forward pass through the encoder\n",
        "    encoder_out, encoder_state = encoder(encoder_in)\n",
        "\n",
        "    # Prepare decoder input and initial state\n",
        "    decoder_state = encoder_state\n",
        "    decoder_in = torch.tensor([[word2idx_fr[\"BOS\"]]], dtype=torch.long).to(device)\n",
        "\n",
        "    pred_sent_fr = []\n",
        "    decoding_step = 0\n",
        "\n",
        "    while decoding_step < fr_seq_len:\n",
        "        # Forward pass through the decoder\n",
        "        decoder_pred, decoder_state = decoder(decoder_in, decoder_state)\n",
        "        decoder_pred = decoder_pred[0,-1,:]\n",
        "        # Get the word index with the highest probability\n",
        "        decoder_pred = torch.argmax(decoder_pred, dim=-1)\n",
        "        # Convert the predicted index to a word\n",
        "        pred_word = idx2word_fr[decoder_pred.item()]\n",
        "        pred_sent_fr.append(pred_word)\n",
        "        # If EOS is predicted, stop decoding\n",
        "        if pred_word == \"EOS\":\n",
        "            break\n",
        "        # Prepare next decoder input\n",
        "        decoder_in = torch.cat((decoder_in, decoder_pred.unsqueeze(0).unsqueeze(0)), dim=1)\n",
        "        decoding_step += 1\n",
        "\n",
        "    print(\"predicted: \", \" \".join(pred_sent_fr))\n",
        "\n",
        "# Example usage with PyTorch models (encoder, decoder)\n",
        "# Note: `encoder` and `decoder` should be instances of your PyTorch model classes."
      ],
      "metadata": {
        "id": "PmlaglwPk4ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseTrainer:\n",
        "    def __init__(self, encoder, decoder, criterion, enc_optimizer, dec_optimizer, train_loader):\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.criterion = criterion  #the loss function\n",
        "        self.enc_optimizer = enc_optimizer  #the optimizer\n",
        "        self.dec_optimizer = dec_optimizer  #the optimizer\n",
        "        self.train_loader = train_loader  #the train loader\n",
        "\n",
        "    #the function to train the model in many epochs\n",
        "    def fit(self, num_epochs):\n",
        "        self.num_batches = len(self.train_loader)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "\n",
        "            train_loss = self.train_one_epoch()\n",
        "            print(\n",
        "                f'{self.num_batches}/{self.num_batches} - loss: {train_loss:.4f} '\n",
        "            )\n",
        "            predict(encoder = encoder, decoder = decoder, en_vocab = en_vocab,\n",
        "                    sents_en = sents_en, sents_fr_out = sents_fr_out, word2idx_fr=word2idx_fr,\n",
        "                    idx2word_fr=idx2word_fr, en_seq_len=en_seq_len, fr_seq_len=fr_seq_len)\n",
        "\n",
        "    #train in one epoch\n",
        "    def train_one_epoch(self):\n",
        "        self.encoder.train()\n",
        "        self.decoder.train()\n",
        "        running_loss  = 0.0\n",
        "\n",
        "        for en_data, fr_in_data, fr_out_data  in train_loader:\n",
        "          en_data, fr_in_data, fr_out_data = en_data.to(device), fr_in_data.to(device), fr_out_data.to(device)\n",
        "          encoder_out, encoder_state = self.encoder(en_data)\n",
        "          decoder_pred, decoder_state = self.decoder(encoder_out, encoder_state, fr_out_data)\n",
        "          output = decoder_pred.contiguous().view(-1, len(fr_vocab))\n",
        "          loss = criterion(output, fr_out_data.contiguous().view(-1))\n",
        "          loss.backward()\n",
        "          self.enc_optimizer.zero_grad()\n",
        "          self.dec_optimizer.zero_grad()\n",
        "          self.enc_optimizer.step()\n",
        "          self.dec_optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "\n",
        "        train_loss = running_loss / self.num_batches\n",
        "        return train_loss"
      ],
      "metadata": {
        "id": "DCQNSmaKRuhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now train our seq2seq and observe the outputs."
      ],
      "metadata": {
        "id": "p1fU1bI_vKLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = BaseTrainer(encoder, decoder, criterion, encoder_optimizer, decoder_optimizer, train_loader)\n",
        "trainer.fit(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_f-996IT8Z-",
        "outputId": "22f63a86-7b82-4d30-d072-fbf8fbc7f5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 - loss: 6.5536 \n",
            "input :  use this .\n",
            "label :  utilisez ceci . EOS\n",
            "predicted:  plierai pris tele parlerai rattrape attendez pris tele les sien\n",
            "Epoch 2/20\n",
            "32/32 - loss: 6.5531 \n",
            "input :  he s a dj .\n",
            "label :  il est dj . EOS\n",
            "predicted:  detendu revoila touche chaude tele refuse court fini tele refuse\n",
            "Epoch 3/20\n",
            "32/32 - loss: 6.5527 \n",
            "input :  i dozed .\n",
            "label :  je me suis assoupie . EOS\n",
            "predicted:  pouvons soul pige tele parlerai rattrape attendez pris tele les\n",
            "Epoch 4/20\n",
            "32/32 - loss: 6.5529 \n",
            "input :  i m fast .\n",
            "label :  je suis rapide . EOS\n",
            "predicted:  tele parlerai rattrape attendez pris tele les sien venue pris\n",
            "Epoch 5/20\n",
            "32/32 - loss: 6.5525 \n",
            "input :  it s ours .\n",
            "label :  c est a nous . EOS\n",
            "predicted:  occupe tele parlerai rattrape attendez pris tele les sien venue\n",
            "Epoch 6/20\n",
            "32/32 - loss: 6.5522 \n",
            "input :  take this .\n",
            "label :  prenez ca . EOS\n",
            "predicted:  plierai gagne pris chanceux tele parlerai rattrape attendez pris tele\n",
            "Epoch 7/20\n",
            "32/32 - loss: 6.5534 \n",
            "input :  oh please !\n",
            "label :  je vous en prie ! EOS\n",
            "predicted:  nu s ton pris tele les sien venue pris parlerai\n",
            "Epoch 8/20\n",
            "32/32 - loss: 6.5520 \n",
            "input :  help me .\n",
            "label :  aidez moi . EOS\n",
            "predicted:  vos bon tele refuse court fini tele refuse court fini\n",
            "Epoch 9/20\n",
            "32/32 - loss: 6.5529 \n",
            "input :  beats me .\n",
            "label :  aucune idee . EOS\n",
            "predicted:  pouvons soul pige tele parlerai rattrape attendez pris tele les\n",
            "Epoch 10/20\n",
            "32/32 - loss: 6.5531 \n",
            "input :  of course !\n",
            "label :  pardi ! EOS\n",
            "predicted:  plierai gagne pris chanceux tele parlerai rattrape attendez pris tele\n",
            "Epoch 11/20\n",
            "32/32 - loss: 6.5525 \n",
            "input :  i m drunk .\n",
            "label :  je suis saoul . EOS\n",
            "predicted:  savais tele parlerai rattrape attendez pris tele les sien venue\n",
            "Epoch 12/20\n",
            "32/32 - loss: 6.5533 \n",
            "input :  i m busy .\n",
            "label :  je suis occupe . EOS\n",
            "predicted:  savais tele parlerai rattrape attendez pris tele les sien venue\n",
            "Epoch 13/20\n",
            "32/32 - loss: 6.5524 \n",
            "input :  i m .\n",
            "label :  j ai ans . EOS\n",
            "predicted:  pouvons soul pige tele parlerai rattrape attendez pris tele les\n",
            "Epoch 14/20\n",
            "32/32 - loss: 6.5535 \n",
            "input :  kiss me .\n",
            "label :  embrasse moi . EOS\n",
            "predicted:  plierai pris tele parlerai rattrape attendez pris tele les sien\n",
            "Epoch 15/20\n",
            "32/32 - loss: 6.5526 \n",
            "input :  let me go !\n",
            "label :  laisse moi y aller ! EOS\n",
            "predicted:  ont tele refuse court fini tele refuse court fini tele\n",
            "Epoch 16/20\n",
            "32/32 - loss: 6.5529 \n",
            "input :  go get it .\n",
            "label :  va le chercher ! EOS\n",
            "predicted:  pouvons soul pige tele parlerai rattrape attendez pris tele les\n",
            "Epoch 17/20\n",
            "32/32 - loss: 6.5531 \n",
            "input :  catch tom .\n",
            "label :  attrapez tom . EOS\n",
            "predicted:  emploie sortie parlerai rattrape attendez pris tele les sien venue\n",
            "Epoch 18/20\n",
            "32/32 - loss: 6.5542 \n",
            "input :  go on .\n",
            "label :  poursuis . EOS\n",
            "predicted:  nu s ton pris tele les sien venue pris parlerai\n",
            "Epoch 19/20\n",
            "32/32 - loss: 6.5527 \n",
            "input :  they swam .\n",
            "label :  ils nagerent . EOS\n",
            "predicted:  emploie sortie parlerai rattrape attendez pris tele les sien venue\n",
            "Epoch 20/20\n",
            "32/32 - loss: 6.5534 \n",
            "input :  catch tom .\n",
            "label :  attrape tom . EOS\n",
            "predicted:  cuisine fini tele parlerai rattrape attendez pris tele les sien\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1vj7nlFK16E"
      },
      "source": [
        "**<span style=\"color:red\">Exercise 1</span>**: Swap the input and target languages to build up a seq2seq model allowing us to translate from French to English."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9619d3xuK16E"
      },
      "source": [
        "## <span style=\"color:#0b486b\">II. Neural Machine Translation With Attention Mechanism </span> <span style=\"color:red\">****</span> ##"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    #query is the current hidden state, while keys specify the\n",
        "    def forward(self, d_state, e_states):\n",
        "        scores = self.Va(torch.tanh(self.Wa(d_state) + self.Ua(e_states)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, e_states)\n",
        "\n",
        "        return context, weights"
      ],
      "metadata": {
        "id": "xzq29xxzwgab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SHF0hfqK16E"
      },
      "source": [
        "We now test our `BahdanauAttention`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoTVjPvmK16E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c2cc731-85df-4bb2-8044-190957b39704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bahdanau: context.shape: torch.Size([64, 1, 200]) attention_weight.shape: torch.Size([64, 1, 100])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "num_timesteps = 100\n",
        "num_units = 200\n",
        "d_state = torch.rand(batch_size, 1, num_units, dtype=torch.float32)\n",
        "e_states = torch.rand(batch_size, num_timesteps, num_units, dtype=torch.float32)\n",
        "# check out dimensions for Bahdanau attention\n",
        "b_attn = BahdanauAttention(num_units)\n",
        "context, attention_weight = b_attn(d_state, e_states)\n",
        "print(\"Bahdanau: context.shape:\", context.shape, \"attention_weight.shape:\", attention_weight.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAtOBdG7K16F"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, decoder_dim, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.attention = BahdanauAttention(decoder_dim)\n",
        "        self.gru = nn.GRU(decoder_dim + embed_size, decoder_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(decoder_dim, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_state, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(fr_vocab['BOS'])\n",
        "        decoder_state = encoder_state\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(fr_seq_len):\n",
        "            decoder_output, decoder_state = self.forward_step(\n",
        "                decoder_input, decoder_state, encoder_outputs)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            #attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        #attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_state\n",
        "\n",
        "    def forward_step(self, decoder_input, decoder_state, encoder_outputs):\n",
        "        embedded =  self.dropout(self.embedding(decoder_input))\n",
        "        query = decoder_state.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "        output, decoder_state = self.gru(input_gru, decoder_state)\n",
        "        output = self.fc(output)\n",
        "        return output, decoder_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPJx9mB6K16F"
      },
      "source": [
        "We now declare encoder and decoder."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 256\n",
        "encoder_dim, decoder_dim = 512, 512\n",
        "encoder = EncoderRNN(len(en_vocab), embed_size, encoder_dim).to(device)\n",
        "attn_decoder = AttnDecoderRNN(len(fr_vocab), embed_size, decoder_dim).to(device)"
      ],
      "metadata": {
        "id": "Y3c4QcwQySHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for en_data, fr_in_data, fr_out_data  in train_loader:\n",
        "    en_data, fr_in_data, fr_out_data = en_data.to(device), fr_in_data.to(device), fr_out_data.to(device)\n",
        "    break\n",
        "encoder_out, encoder_state = encoder(en_data)\n",
        "decoder_pred, decoder_state = attn_decoder(encoder_out, encoder_state, fr_out_data)\n",
        "\n",
        "print(\"encoder input :\", en_data.shape)\n",
        "print(\"encoder output :\", encoder_out.shape, \", state:\", encoder_state.shape)\n",
        "print(\"decoder output (logits):\", decoder_pred.shape, \", state:\", decoder_state.shape)\n",
        "print(\"decoder output (labels):\", decoder_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMkqJHXxxAbn",
        "outputId": "71288f0e-3e74-4d48-8b73-9ed158d36d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder input : torch.Size([32, 5])\n",
            "encoder output : torch.Size([32, 5, 512]) , state: torch.Size([1, 32, 512])\n",
            "decoder output (logits): torch.Size([32, 10, 710]) , state: torch.Size([1, 32, 512])\n",
            "decoder output (labels): torch.Size([1, 32, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyQzAxOkK16F"
      },
      "source": [
        "We now train our seq2seq model with `BahdanauAttention`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
        "decoder_optimizer = optim.Adam(attn_decoder.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)"
      ],
      "metadata": {
        "id": "TEaJqOwZ57wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = BaseTrainer(encoder, attn_decoder, criterion, encoder_optimizer, decoder_optimizer, train_loader)\n",
        "trainer.fit(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0VAvnAS6Dj5",
        "outputId": "3a27b6c4-55fd-495f-9634-841f676ae0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 - loss: 6.5555 \n",
            "input :  call me .\n",
            "label :  appelez moi ! EOS\n",
            "predicted:  refuse court fini tele refuse court fini tele refuse court\n",
            "Epoch 2/20\n",
            "32/32 - loss: 6.5566 \n",
            "input :  let s see .\n",
            "label :  voyons voir ! EOS\n",
            "predicted:  parle cours fini tele parlerai rattrape attendez pris tele les\n",
            "Epoch 3/20\n",
            "32/32 - loss: 6.5559 \n",
            "input :  it stinks .\n",
            "label :  ca pue . EOS\n",
            "predicted:  magnez trop detendu revoila touche chaude tele refuse court fini\n",
            "Epoch 4/20\n",
            "32/32 - loss: 6.5581 \n",
            "input :  open up .\n",
            "label :  ouvre moi ! EOS\n",
            "predicted:  fauche bizarre restez pris chanceux tele parlerai rattrape attendez pris\n",
            "Epoch 5/20\n",
            "32/32 - loss: 6.5579 \n",
            "input :  i m right .\n",
            "label :  j ai raison . EOS\n",
            "predicted:  fauche bizarre restez pris chanceux tele parlerai rattrape attendez pris\n",
            "Epoch 6/20\n",
            "32/32 - loss: 6.5560 \n",
            "input :  they fell .\n",
            "label :  ils sont tombes . EOS\n",
            "predicted:  refuse court fini tele refuse court fini tele refuse court\n",
            "Epoch 7/20\n",
            "32/32 - loss: 6.5564 \n",
            "input :  see you !\n",
            "label :  a la prochaine ! EOS\n",
            "predicted:  refuse court fini tele refuse court fini tele refuse court\n",
            "Epoch 8/20\n",
            "32/32 - loss: 6.5571 \n",
            "input :  i retired .\n",
            "label :  j ai pris ma retraite . EOS\n",
            "predicted:  chanterai tele refuse court fini tele refuse court fini tele\n",
            "Epoch 9/20\n",
            "32/32 - loss: 6.5566 \n",
            "input :  it was ok .\n",
            "label :  c etait ok . EOS\n",
            "predicted:  fauche bizarre restez pris chanceux tele parlerai rattrape attendez pris\n",
            "Epoch 10/20\n",
            "32/32 - loss: 6.5542 \n",
            "input :  i m home .\n",
            "label :  je suis chez moi . EOS\n",
            "predicted:  tele les sien venue pris parlerai rattrape attendez pris tele\n",
            "Epoch 11/20\n",
            "32/32 - loss: 6.5569 \n",
            "input :  i phoned .\n",
            "label :  j ai telephone . EOS\n",
            "predicted:  chanterai tele refuse court fini tele refuse court fini tele\n",
            "Epoch 12/20\n",
            "32/32 - loss: 6.5567 \n",
            "input :  i m going .\n",
            "label :  je pars . EOS\n",
            "predicted:  chanterai tele refuse court fini tele refuse court fini tele\n",
            "Epoch 13/20\n",
            "32/32 - loss: 6.5580 \n",
            "input :  i failed .\n",
            "label :  j ai echoue . EOS\n",
            "predicted:  chanterai tele refuse court fini tele refuse court fini tele\n",
            "Epoch 14/20\n",
            "32/32 - loss: 6.5575 \n",
            "input :  i helped .\n",
            "label :  j ai aide . EOS\n",
            "predicted:  chanterai tele refuse court fini tele refuse court fini tele\n",
            "Epoch 15/20\n",
            "32/32 - loss: 6.5574 \n",
            "input :  don t die .\n",
            "label :  ne meurs pas ! EOS\n",
            "predicted:  pris chanceux tele parlerai rattrape attendez pris tele les sien\n",
            "Epoch 16/20\n",
            "32/32 - loss: 6.5574 \n",
            "input :  i m wet .\n",
            "label :  je suis mouille . EOS\n",
            "predicted:  refuse court fini tele refuse court fini tele refuse court\n",
            "Epoch 17/20\n",
            "32/32 - loss: 6.5559 \n",
            "input :  beats me .\n",
            "label :  aucune idee . EOS\n",
            "predicted:  magnez trop detendu revoila touche chaude tele refuse court fini\n",
            "Epoch 18/20\n",
            "32/32 - loss: 6.5564 \n",
            "input :  we lost .\n",
            "label :  nous avons ete battues . EOS\n",
            "predicted:  l pris parlerai rattrape attendez pris tele les sien venue\n",
            "Epoch 19/20\n",
            "32/32 - loss: 6.5575 \n",
            "input :  i m shy .\n",
            "label :  je suis timide . EOS\n",
            "predicted:  fauche bizarre restez pris chanceux tele parlerai rattrape attendez pris\n",
            "Epoch 20/20\n",
            "32/32 - loss: 6.5580 \n",
            "input :  head west .\n",
            "label :  dirigez vous vers l ouest . EOS\n",
            "predicted:  deteste fini tele refuse court fini tele refuse court fini\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "704NpI7JK16F"
      },
      "source": [
        "---\n",
        "### <span style=\"color:#0b486b\"> <div  style=\"text-align:center\">**THE END**</div> </span>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}