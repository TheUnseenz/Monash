{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHNAq9QI7vQn"
      },
      "source": [
        "# FIT5215/FIT3181: In-class Kaggle Competition\n",
        "\n",
        "# <span style=\"color:#0b486b\"> Week 2 </span>\n",
        "\n",
        "**Your roles:**\n",
        "- Implement a feedforward neural net for a multi-class classfication problem using PyTorch\n",
        "- Train models, finetune hyper-parameters\n",
        "- Predict trained model on the test set and submit your solution to Kaggle.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIg_vVMU_pU4"
      },
      "source": [
        "### <span style=\"color:#0b486b\"> II.0 Running on Google Colab</span> <span style=\"color:red\"></span>\n",
        "You will need to download relevant files to run this notebook on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUu6Lil9FUsi"
      },
      "outputs": [],
      "source": [
        "# !gdown https://drive.google.com/file/d/1UxKyCyMxTfew8zNcbel6GJOHja2gIuSs/view?usp=sharing --fuzzy -O Data_kaggle_week2.zip  # Comment out this line of code if you have already run it once\n",
        "# backup urls\n",
        "\n",
        "# !gdown https://drive.google.com/file/d/1T-tM1CT6TkpZhWwF-cjyOr-xwc03X3lI/view?usp=sharing --fuzzy -O Data_kaggle_week2.zip\n",
        "\n",
        "# !gdown https://drive.google.com/file/d/13zoGHKtAOvi5vMnDZalqMRoA849JhXhJ/view?usp=sharing --fuzzy -O Data_kaggle_week2.zip\n",
        "\n",
        "# !gdown https://drive.google.com/file/d/1SNlYnnT-lRl7ly73WVK5vs2dnjak5OY0/view?usp=sharing --fuzzy -O Data_kaggle_week2.zip\n",
        "\n",
        "# !gdown https://drive.google.com/file/d/1cAyNRb_tqDEImUOCMh3w2rZw44hobl1r/view?usp=sharing --fuzzy -O Data_kaggle_week2.zip\n",
        "\n",
        "# !gdown https://drive.google.com/file/d/1r3PZLRVOLk8Z5sh3wZgBD8M86rIInnxL/view?usp=sharing --fuzzy -O Data_kaggle_week2.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ikNF3Vj_0nT"
      },
      "outputs": [],
      "source": [
        "# !unzip -q Data_kaggle_week2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn9fOkEguNwv"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7KHBNFSH0WM"
      },
      "source": [
        "### Data Description:\n",
        "\n",
        "The database consists of the multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood. The aim is to predict this classification, given the multi-spectral values. In the sample database, the class of a pixel is coded as a number.\n",
        "\n",
        "The database is a (tiny) sub-area of a scene, consisting of 82 x 100 pixels. Each line of data corresponds to a 3x3 square neighbourhood of pixels completely contained within the 82x100 sub-area. Each line contains the pixel values in the four spectral bands (converted to ASCII) of each of the 9 pixels in the 3x3 neighbourhood and a number indicating the classification label of the central pixel.\n",
        "\n",
        "Each pixel is categorized as one of the following classes:\n",
        "- 1 red soil\n",
        "- 2 cotton crop\n",
        "- 3 grey soil\n",
        "- 4 damp grey soil\n",
        "- 5 soil with vegetation stubble\n",
        "- 6 very damp grey soil\n",
        "\n",
        "#### Attribute information\n",
        "\n",
        "There are 36 predictive attributes (= 4 spectral bands x 9 pixels in neighborhood). In each line of data the four spectral values for the top-left pixel are given first followed by the four spectral values for the top-middle pixel and then those for the top-right pixel, and so on with the pixels read out in sequence left-to-right and top-to-bottom. Thus, the four spectral values for the central pixel are given by attributes 17,18,19 and 20. **If you like you can use only these four attributes, while ignoring the others.** This avoids the problem which arises when a 3x3 neighbourhood straddles a boundary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gOafwlzDKOs",
        "tags": []
      },
      "source": [
        "#### <span style=\"color:#0b486b\">1. Data Processing </span>\n",
        "\n",
        "We use `sklearn` to load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rwTUzYB7_8Ec"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_svmlight_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8b7i8gsdZbA"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def seed_all(seed=1029):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_all(1029)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJZYOkYKFUsj"
      },
      "source": [
        "#### Load Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA7JBIeyDUaL",
        "outputId": "a3aad00f-cc81-4341-d937-9460134f5215"
      },
      "outputs": [],
      "source": [
        "data_file_name= \"dataset.libsvm\"\n",
        "data_file = os.path.abspath(\"./Data_kaggle_week2/\" + data_file_name)\n",
        "X_data, y_data = load_svmlight_file(data_file)\n",
        "X_data= X_data.toarray()\n",
        "y_data= y_data.reshape(y_data.shape[0],-1)\n",
        "print(\"X data shape: {}\".format(X_data.shape))\n",
        "print(\"y data shape: {}\".format(y_data.shape))\n",
        "print(\"# classes: {}\".format(len(np.unique(y_data))))\n",
        "print(np.unique(y_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94QPzvONDeXn"
      },
      "source": [
        "We use `sklearn` to split the dataset into the train and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SQRKrWYDfDB"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "def train_valid_split(data, target, valid_size):\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(data, target, test_size = valid_size, random_state= 33)\n",
        "    return X_train, X_valid, y_train, y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHPaCsCEDieq"
      },
      "outputs": [],
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y_data.ravel())\n",
        "y_data= le.transform(y_data.ravel())\n",
        "y_data = y_data.ravel()\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_valid_split(X_data, y_data, valid_size=0.3)\n",
        "y_train= y_train.reshape(-1)\n",
        "y_valid= y_valid.reshape(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXXeRuOCFUsk"
      },
      "source": [
        "#### Load Unlabelled Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIVgMdT9FUsk",
        "outputId": "918ccac5-c42a-419d-a454-f474f46ba21c"
      },
      "outputs": [],
      "source": [
        "data_file_name= \"test_unlabelled.libsvm\"\n",
        "data_file = os.path.abspath(\"./Data_kaggle_week2/\" + data_file_name)\n",
        "X_test, _ = load_svmlight_file(data_file)\n",
        "X_test= X_test.toarray()\n",
        "print(\"Test data shape: {}\".format(X_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkTrTUk1FUsk",
        "outputId": "a3ee12f8-b56a-4967-931f-5ae625272911"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape, X_valid.shape)\n",
        "print(y_train.shape, y_valid.shape)\n",
        "print(\"lables: {}\".format(np.unique(y_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-1aTLG9OlDY"
      },
      "source": [
        "#### Batching Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsctBVoZOxfI"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, labels=None):\n",
        "        super(MyDataset, self).__init__()\n",
        "        self.data = torch.tensor(data, dtype = torch.float32)\n",
        "        if labels is None:\n",
        "            self.labels = torch.ones(self.data.shape[0], dtype = torch.float32)\n",
        "        else:\n",
        "            self.labels = torch.tensor(labels, dtype = torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM-maEstPJVs"
      },
      "outputs": [],
      "source": [
        "train_data = MyDataset(X_train, y_train)\n",
        "valid_data = MyDataset(X_valid, y_valid)\n",
        "test_data = MyDataset(X_test, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze6bpw7XPld4"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7R0wK3rD17J",
        "outputId": "8b3f5935-92a7-422c-a7a6-25399d89967c"
      },
      "outputs": [],
      "source": [
        "train_size= int(X_train.shape[0])\n",
        "n_features= int(X_train.shape[1])\n",
        "n_classes= len(np.unique(y_train))\n",
        "print(f\"Train size: {train_size}, # features: {n_features}, and number of classes: {n_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4DwRYFrD7Ph"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Linear, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lONGkEhfD8MT"
      },
      "source": [
        "#### <span style=\"color:#0b486b\">2. Build up the model </span>\n",
        "\n",
        "We build up a feedforward neural network in PyTorch. Note that we only return the logits because the cross-entropy loss we use later includes the softmax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0QiW3knFPFG"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# dnn_model = Sequential(Linear(n_features,10), nn.ReLU(),\n",
        "#                        Linear(10,20), nn.ReLU(),\n",
        "#                        Linear(20,15), nn.ReLU(),\n",
        "#                        Linear(15, n_classes)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d-bvn6EhtZm"
      },
      "outputs": [],
      "source": [
        "def compute_loss(model, loss_fn, loader, device):\n",
        "\tloss = 0\n",
        "\tfor (batchX, batchY) in loader:\n",
        "\t\tbatchX, batchY = batchX.to(device), batchY.to(device)\n",
        "\t\tloss += loss_fn(model(batchX.type(torch.float32)), batchY.type(torch.long))\n",
        "\treturn float(loss)/len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1MF5boRiPeS"
      },
      "outputs": [],
      "source": [
        "def compute_acc(model, loader, device):\n",
        "\tmodel.eval()\n",
        "\t# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "\twith torch.no_grad():\n",
        "\t\tcorrects = 0\n",
        "\t\ttotals =0\n",
        "\t\tfor (batchX, batchY) in loader:\n",
        "\t\t\tbatchX, batchY = batchX.to(device), batchY.to(device)\n",
        "\t\t\toutputs = model(batchX.type(torch.float32)) #feed batch to the model\n",
        "\t\t\ttotals += batchY.size(0) #accumulate totals with the current batch size\n",
        "\t\t\tpredicted = torch.argmax(outputs.data, 1) #get the predicted class\n",
        "\t\t\tcorrects += (predicted == batchY.type(torch.long)).sum().item() #accumulate correct predictions\n",
        "\tacc = float(corrects)/totals #compute the accuracy\n",
        "\treturn acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMcynhEEFUsl",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "\tdnn_model = Sequential(Linear(n_features,64), nn.ReLU(), nn.Dropout(0.1),\n",
        "                         Linear(64,128), nn.ReLU(), nn.Dropout(0.4),\n",
        "                         Linear(128,32), nn.ReLU(), nn.Dropout(0.1),\n",
        "                         Linear(32, n_classes))\n",
        "\treturn dnn_model\n",
        "\n",
        "def fit(model= None, train_loader = None, valid_loader = None, loss_fn = None, optimizer = torch.optim.Adam,\n",
        "\t\t\t\tlearning_rate=0.001, num_epochs = 100, verbose = True, seed= 1234, device=None):\n",
        "\ttorch.manual_seed(seed)\n",
        "\toptim = optimizer(model.parameters(), lr = learning_rate)\n",
        "\thistory = dict()\n",
        "\thistory['val_loss'] = list()\n",
        "\thistory['val_acc'] = list()\n",
        "\thistory['train_loss'] = list()\n",
        "\thistory['train_acc'] = list()\n",
        "\tfor epoch in range(num_epochs):\n",
        "\t\tfor i, (X, y) in enumerate(train_loader):\n",
        "\t\t\t# Forward pass\n",
        "\t\t\tX, y = X.to(device), y.to(device)\n",
        "\t\t\toutputs = model(X.type(torch.float32))\n",
        "\t\t\tloss = loss_fn(outputs, y.type(torch.long))\n",
        "\t\t\t# Backward and optimize\n",
        "\t\t\toptim.zero_grad()\n",
        "\t\t\tloss.backward()\n",
        "\t\t\toptim.step()\n",
        "\t\t#losses and accuracies for epoch\n",
        "\t\tval_loss = compute_loss(model, loss_fn, valid_loader, device)\n",
        "\t\tval_acc = compute_acc(model, valid_loader, device)\n",
        "\t\ttrain_loss = compute_loss(model, loss_fn, train_loader, device)\n",
        "\t\ttrain_acc = compute_acc(model, train_loader, device)\n",
        "\t\ttest_acc = compute_acc(model, test_loader, device)\n",
        "\t\thistory['val_loss'].append(val_loss)\n",
        "\t\thistory['val_acc'].append(val_acc)\n",
        "\t\thistory['train_loss'].append(train_loss)\n",
        "\t\thistory['train_acc'].append(train_acc)\n",
        "\t\tif not verbose: #verbose = True means we do not show the training information during training\n",
        "\t\t\tprint(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\t\t\tprint(f\"train loss= {train_loss:.4f} - train acc= {train_acc*100:.2f}% - valid loss= {val_loss:.4f} - valid acc= {val_acc*100:.4f}%\")\n",
        "\treturn history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhS0V0V9omqD",
        "tags": []
      },
      "source": [
        "#### <span style=\"color:#0b486b\">4. Declaring the Loss, Optimizer, learning rate and Training the Model </span>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmPbreigIJ5t",
        "outputId": "fec40e8b-4a86-45a1-81d3-3df9ba8f25ab"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "optim_dict = {\"Adam\":optim.Adam, \"Adadelta\":optim.Adadelta, \"Adagrad\":optim.Adagrad,\n",
        "              \"Adamax\":optim.Adamax, \"AdamW\": optim.AdamW, \"ASGD\":optim.ASGD,\n",
        "              \"NAdam\":optim.NAdam, \"RMSprop\":optim.RMSprop, \"RAdam\":optim.RAdam,\n",
        "              \"Rprop\": optim.Rprop, \"SGD\":optim.SGD}\n",
        "\n",
        "dnn_model = create_model().to(device)\n",
        "history = fit(dnn_model, train_loader = train_loader, valid_loader= valid_loader, loss_fn = nn.CrossEntropyLoss(),\n",
        "    optimizer = optim_dict[\"AdamW\"], learning_rate = 0.0002, num_epochs =250, verbose= False, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3-WS91yTvEL"
      },
      "source": [
        "#### <span style=\"color:#0b486b\">5. Visualizing the Performance and Loss Objective Function </span>\n",
        "\n",
        "There are four keys in the history dictionary: `train_loss` and `val_loss` measure the loss on the training set and the validation set, respectively, while `train_acc` and `val_acc` measure the accuracy on the training set and the validation set.  \n",
        "The following figure visualize all four metrics with two y-axes, losses (blue lines, in descending) and accuracies (red lines, in asending)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "6ZVEdlONTuJR",
        "outputId": "8784ad71-2e0c-4a20-bbf5-f3387e51cb07"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "his = history\n",
        "fig = plt.figure(figsize=(8, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "ln1 = ax.plot(his['train_loss'], 'b--',label='loss')\n",
        "ln2 = ax.plot(his['val_loss'], 'b-',label='val_loss')\n",
        "ax.set_ylabel('loss', color='blue')\n",
        "ax.tick_params(axis='y', colors=\"blue\")\n",
        "\n",
        "ax2 = ax.twinx()\n",
        "ln3 = ax2.plot(his['train_acc'], 'r--',label='accuracy')\n",
        "ln4 = ax2.plot(his['val_acc'], 'r-',label='val_accuracy')\n",
        "ax2.set_ylabel('accuracy', color='red')\n",
        "ax2.tick_params(axis='y', colors=\"red\")\n",
        "\n",
        "lns = ln1 + ln2 + ln3 + ln4\n",
        "labels = [l.get_label() for l in lns]\n",
        "ax.legend(lns, labels, loc=7)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNjeT-EyiRx3"
      },
      "source": [
        "# Evaluate model on the testing set, get the csv file and upload to kaggle\n",
        " - Note: Do not modify this block of code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "180qpEBIFUsl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "def save_prediction_to_csv(model, loader, device, output_file=\"submission.csv\"):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    image_ids = []\n",
        "    df = {\n",
        "    \"ImageId\": [],\n",
        "    \"Label\": []\n",
        "    }\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (batchX, batchY) in enumerate(loader):\n",
        "            batchX, batchY = batchX.to(device), batchY.to(device)\n",
        "            outputs = model(batchX.float())  # Convert to float32 and feed batch to the model\n",
        "            predicted = torch.argmax(outputs, dim=1)  # Get the predicted class\n",
        "            total += predicted.size(0)\n",
        "            for ids, pred in enumerate(predicted):\n",
        "                df[\"Label\"].append(pred.cpu().item())\n",
        "    df[\"ImageId\"] = [i+1 for i in range(total)]\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(df)\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KR3gRHtsGTOm"
      },
      "outputs": [],
      "source": [
        "save_prediction_to_csv(dnn_model, test_loader, device) # should only modify the input model to this function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3UicCvcFUsl"
      },
      "source": [
        "# Submit result to kaggle competition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc9yWR-XFUsl"
      },
      "source": [
        "- Regsiter Kaggle account using your private gmail [Kaggle](https://https://www.kaggle.com/)\n",
        "\n",
        "- Lastly, you will need to download the `submission.csv` file and upload it to the Kaggle competition (url for competition is provided in Moodle).\n",
        "\n",
        "- Remember to change your display your team name on the Leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdQGl97zVF5Z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
