{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDUarAUSio5R"
      },
      "source": [
        "# <span style=\"color:#0b486b\">  FIT3181/5215: Deep Learning (2025)</span>\n",
        "***\n",
        "*CE/Lecturer (Clayton):*  **Dr Trung Le** | trunglm@monash.edu <br/>\n",
        "*Lecturer (Clayton):* **A/Prof Zongyuan Ge** | zongyuan.ge@monash.edu <br/>\n",
        "*Lecturer (Malaysia):*  **Dr Arghya Pal** | arghya.pal@monash.edu <br/>\n",
        " <br/>\n",
        "*Head Tutor 3181:*  **Ms Ruda Nie H** |  \\[RudaNie.H@monash.edu \\] <br/>\n",
        "*Head Tutor 5215:*  **Ms Leila Mahmoodi** |  \\[leila.mahmoodi@monash.edu \\]\n",
        "\n",
        "<br/> <br/>\n",
        "Faculty of Information Technology, Monash University, Australia\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFLW6ulGio5T"
      },
      "source": [
        "# <span style=\"color:#0b486b\">Tutorial 7c (Additional Reading): RNN for Text Generation</span> <span style=\"color:red\">***</span> #\n",
        "\n",
        "This tutorial is designed to show one of the applications of RNN in generating texts or sequences. Basically, we train an RNN using the maximum log-likelihood principle and then use this trained RNN to generate texts that imitate the existed texts in the dataset we trained our RNN on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muSXze6Nio5T"
      },
      "source": [
        "We first import the necessary modules."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCT35FLTio5T"
      },
      "source": [
        "## <span style=\"color:#0b486b\">I. Download and preprocess data</span> ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzaVm30wio5T"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_izTpQTio5U"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \".\"\n",
        "CHECKPOINT_DIR = os.path.join(DATA_DIR, \"checkpoints\")\n",
        "if not os.path.exists(CHECKPOINT_DIR):\n",
        "    os.mkdir(CHECKPOINT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfv9BGdiio5U"
      },
      "source": [
        "The below function helps to download the dataset at a specific URL and split the sentences into characters.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAa3eKxwio5U"
      },
      "outputs": [],
      "source": [
        "def download_and_read(urls):\n",
        "    import urllib3\n",
        "    import re\n",
        "\n",
        "    http = urllib3.PoolManager()\n",
        "    texts = []\n",
        "\n",
        "    for url in urls:\n",
        "        # Read the text from URL\n",
        "        resp = http.request(\"GET\", url) # it's a file like object and works just like a file\n",
        "        text = resp.data.decode(\"utf8\")\n",
        "\n",
        "        # remove byte order mark\n",
        "        text = text.replace(\"\\ufeff\", \"\")\n",
        "        # remove newlines\n",
        "        text = text.replace('\\n', ' ')\n",
        "        text = re.sub(r'\\s+', \" \", text)\n",
        "\n",
        "        # add it to the list\n",
        "        texts.extend(text)\n",
        "    return texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdIiVvPOio5U"
      },
      "source": [
        "We download the dataset and the variable *texts* is a list containing all characters of the sentences in this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV_UhwI-io5U"
      },
      "outputs": [],
      "source": [
        "texts = download_and_read([\"http://www.gutenberg.org/cache/epub/28885/pg28885.txt\", \"https://www.gutenberg.org/files/12/12-0.txt\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts[0:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cgi_XcCPiIM",
        "outputId": "953535aa-3715-4223-c31a-9dc67cf5c8aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['T', 'h', 'e', ' ', 'P', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'G', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'B', 'o', 'o', 'k', ' ', 'o', 'f', ' ', 'A', 'l', 'i', 'c', 'e', \"'\", 's', ' ', 'A', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ', 'i', 'n', ' ', 'W', 'o', 'n', 'd', 'e', 'r', 'l', 'a', 'n', 'd', ' ', 'T', 'h', 'i', 's', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'i', 's', ' ', 'f', 'o', 'r', ' ', 't', 'h', 'e', ' ', 'u', 's', 'e', ' ', 'o', 'f', ' ', 'a', 'n', 'y', 'o', 'n', 'e', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHsWgQU4io5V"
      },
      "source": [
        "We extract the vocabulary of all unique characters in this dataset and store in *vocab*. In addition, we have two dictionaries: *char2idx* and *idx2char* to convert between the characters and their indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tyka5oU0io5V",
        "outputId": "8695be6e-7444-44ad-e7e2-761ef1ab7fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size: 93\n"
          ]
        }
      ],
      "source": [
        "# create the vocabulary\n",
        "vocab = sorted(set(texts))\n",
        "print(\"vocab size: {:d}\".format(len(vocab)))\n",
        "# create mapping from vocab chars to ints\n",
        "char2idx = {c:i for i, c in enumerate(vocab)}\n",
        "idx2char = {i:c for c, i in char2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTTQckQaio5V"
      },
      "source": [
        "We transform the characters in *texts* to the indices in *texts_as_ints* and then chop the data into batch dataset *sequences* of length 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al-VMo3Nio5V"
      },
      "outputs": [],
      "source": [
        "# numericize the texts\n",
        "texts_as_ints = np.array([char2idx[c] for c in texts])\n",
        "\n",
        "# drop the remainder\n",
        "data_size = len(texts_as_ints) // 100\n",
        "texts_as_ints = texts_as_ints[: data_size * 100]\n",
        "\n",
        "# sequences: [None, 100]\n",
        "sequences = texts_as_ints.reshape(-1, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We examine the texts of the first 5 samples."
      ],
      "metadata": {
        "id": "yXxYBScuG1wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for item in sequences[:5]:\n",
        "  ids = [idx2char[i] for i in item]\n",
        "  print(''.join(ids))\n",
        "  print(\"---\")"
      ],
      "metadata": {
        "id": "uYLqUBS1GZ5X",
        "outputId": "58efa7e9-e628-497f-dde2-d82fa4975a87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Project Gutenberg eBook of Alice's Adventures in Wonderland This ebook is for the use of anyone \n",
            "---\n",
            "anywhere in the United States and most other parts of the world at no cost and with almost no restri\n",
            "---\n",
            "ctions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenbe\n",
            "---\n",
            "rg License included with this ebook or online at www.gutenberg.org. If you are not located in the Un\n",
            "---\n",
            "ited States, you will have to check the laws of the country where you are located before using this \n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vcKv8FEio5W"
      },
      "source": [
        "For the below function, you can imagine *sequence* is a batch of characters, for example \\['I', 'l', 'o', 'v', 'e', 'D', 'L'\\], this function will return \\['I', 'l', 'o', 'v', 'e', 'D'\\] and \\['l', 'o', 'v', 'e', 'D', 'L'\\].\n",
        "\n",
        "The idea later is that we feed \\['I', 'l', 'o', 'v', 'e', 'D'\\] to our RNN and try to predict \\['l', 'o', 'v', 'e', 'D', 'L'\\] which is the set of next characters. We also convert them to ``torch.LongTensor``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgOa7f-jio5W"
      },
      "outputs": [],
      "source": [
        "input_seq = torch.LongTensor(sequences[:, 0:-1])\n",
        "output_seq = torch.LongTensor(sequences[:, 1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfkPWqMEio5W"
      },
      "source": [
        "We encapsulate our generation model in the class *CharGenModel*. Our model has one embedding layer and one hidden layer with GRU cells."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CharGenModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "    super(CharGenModel, self).__init__()\n",
        "\n",
        "    self.embedding_layer = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "    self.rnn_layer = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
        "    self.dense_layer = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    e = self.embedding_layer(x)\n",
        "    h, _ = self.rnn_layer(e)\n",
        "    y = self.dense_layer(h)\n",
        "    return y"
      ],
      "metadata": {
        "id": "Sbb2upz_jDmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfeDvY4xio5W"
      },
      "source": [
        "We build the model and create a DataLoader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkH31mUpio5W"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 512\n",
        "hidden_dim = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1oZDm5Zio5W"
      },
      "outputs": [],
      "source": [
        "model = CharGenModel(vocab_size, embedding_dim, hidden_dim)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "indices = list(range(input_seq.size(0)))\n",
        "loader = DataLoader(indices, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "4KNyd1JM5f_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xjOVnOhio5W"
      },
      "source": [
        "We define the loss function which is the weighted mean of the loss at each time step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAAC9nyUio5W"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWAnoyT-io5X"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgq7yaWHio5X"
      },
      "source": [
        "To generate a text, we start from a prefix_string. We convert this string to a list of indices and declare a 2D tensor from this list with the first dimension to be $1$. We feed *inputs* to the model to work out the prediction probability *preds* and sample *pred_id* from this probability and so on."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, prefix_string, char2idx, idx2char, device, num_chars_to_generate=1000):\n",
        "  chars = [char2idx[s] for s in prefix_string]\n",
        "  inputs = torch.LongTensor(chars)\n",
        "  inputs = inputs.unsqueeze(dim=0).to(device)\n",
        "  text_generated = []\n",
        "  model.eval()\n",
        "  for i in range(num_chars_to_generate):\n",
        "    preds = model(inputs)\n",
        "    preds = preds[:, -1, :]\n",
        "    preds = preds.squeeze(dim=0)\n",
        "    pred_id = preds.argmax()\n",
        "    text_generated.append(idx2char[pred_id.item()])\n",
        "    inputs = torch.cat((inputs[:, 1:], pred_id.view(1,1)), dim=1)\n",
        "\n",
        "  return prefix_string + \"\".join(text_generated)"
      ],
      "metadata": {
        "id": "vuSpGTtC-yfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start the training procedure. First, we must load the model onto GPU."
      ],
      "metadata": {
        "id": "ocoWvyTH6xs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "vpcNIBEY7sKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d91cadf-0098-4116-9f27-bb16208d36f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharGenModel(\n",
              "  (embedding_layer): Embedding(93, 512, padding_idx=0)\n",
              "  (rnn_layer): GRU(512, 1024, num_layers=2, batch_first=True)\n",
              "  (dense_layer): Linear(in_features=1024, out_features=93, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, optimizer, input_seq, output_seq, loader, criterion, device):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    for idx in loader:\n",
        "        x = input_seq[idx, :].to(device)\n",
        "        target_seq = output_seq[idx, ].to(device)\n",
        "\n",
        "        predicted_seq = model(x)\n",
        "        predicted_seq = predicted_seq.permute(0,2,1)\n",
        "        loss = loss_fn(predicted_seq, target_seq)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses += loss.item()\n",
        "    return losses / len(loader)\n"
      ],
      "metadata": {
        "id": "Xha0A1-Qwqo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "curr_loss = 1e+5\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "  train_loss = train_epoch(model, optimizer, input_seq, output_seq, loader, loss_fn, device)\n",
        "  msg = f\"Epoch: {epoch}/{num_epochs} - Train loss: {train_loss:.3f}\"\n",
        "  print(msg)\n",
        "\n",
        "  # generate texts every time the loss decreases\n",
        "  if train_loss < curr_loss:\n",
        "    gen_text = generate_text(model, \"Alice opened the door\", char2idx, idx2char, device, num_chars_to_generate=100)\n",
        "    curr_loss = train_loss\n",
        "    print(gen_text)\n",
        "    print(\"---\")\n"
      ],
      "metadata": {
        "id": "hg5NtMthwjxT",
        "outputId": "e0476734-bf28-4981-ae76-48a98097d235",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/50 - loss = 2.487\n",
            "Alice opened the door the was she said the Queen the was she said the Queen the was she said the Queen the was she said t\n",
            "---\n",
            "Epoch: 2/50 - loss = 1.694\n",
            "Alice opened the door of the said the Queen she said the Queen she said the Queen she said the Queen she said the Queen s\n",
            "---\n",
            "Epoch: 3/50 - loss = 1.448\n",
            "Alice opened the door of the same of the same of the same of the same of the same of the same of the same of the same of \n",
            "---\n",
            "Epoch: 4/50 - loss = 1.303\n",
            "Alice opened the door with the same sharp and the table so much a little brook, and the Red Queen said to herself, and th\n",
            "---\n",
            "Epoch: 5/50 - loss = 1.202\n",
            "Alice opened the door was the copyright law in the words and she was a long way of the court, and the bottle of the court\n",
            "---\n",
            "Epoch: 6/50 - loss = 1.115\n",
            "Alice opened the door with the trademark license in the way the rest of the work and the procession or entity to see it w\n",
            "---\n",
            "Epoch: 7/50 - loss = 1.037\n",
            "Alice opened the door in the same thing as she could see it was a great deal of the country in the same thing as she coul\n",
            "---\n",
            "Epoch: 8/50 - loss = 0.967\n",
            "Alice opened the door with the terms of the Project Gutenberg™ works. • You can see the work in a tone of the ground was \n",
            "---\n",
            "Epoch: 9/50 - loss = 0.888\n",
            "Alice opened the door and said, “That would be a little beginning to the terms of this agreement for the fee of the world\n",
            "---\n",
            "Epoch: 10/50 - loss = 0.815\n",
            "Alice opened the door and finger at the moment the Gryphon and the moment she had not notice in her own invention of the \n",
            "---\n",
            "Epoch: 11/50 - loss = 0.739\n",
            "Alice opened the door, so she said this, but she was getting so much at the baby, the moral of that sounded like the Red \n",
            "---\n",
            "Epoch: 12/50 - loss = 0.667\n",
            "Alice opened the door and knocked and repeat something like a bone from the engine-driver-ending meant for its neck with \n",
            "---\n",
            "Epoch: 13/50 - loss = 0.595\n",
            "Alice opened the door again. \"I wonder what would become of it, and made a remark that particular stretched herself as sh\n",
            "---\n",
            "Epoch: 14/50 - loss = 0.528\n",
            "Alice opened the door and for a while, first on one side and the other way. I suppose so, of course, And shouting \"Off wi\n",
            "---\n",
            "Epoch: 15/50 - loss = 0.460\n",
            "Alice opened the door. \"Of course they all stopped, and she saw that it had eyes and said, ‘To play them such a _very_ st\n",
            "---\n",
            "Epoch: 16/50 - loss = 0.399\n",
            "Alice opened the door again in a moment like a conjuring-trick. It was so large a house, that she liked the window, and s\n",
            "---\n",
            "Epoch: 17/50 - loss = 0.347\n",
            "Alice opened the door and found an opportunity of adding, \"You're going on again, and handed them round and holder than s\n",
            "---\n",
            "Epoch: 18/50 - loss = 0.304\n",
            "Alice opened the door and found that it was the best plan not to walk _quite_ close to the Project Gutenberg Literary Arc\n",
            "---\n",
            "Epoch: 19/50 - loss = 0.264\n",
            "Alice opened the door and knocked. And when I go out here at all?” “I can’t say,” the Gnat remarked. “I’m afraid he’ll ca\n",
            "---\n",
            "Epoch: 20/50 - loss = 0.232\n",
            "Alice opened the door. \"Call the first witness was the Duchess. \"I make you a present of everything you like, but it isn’\n",
            "---\n",
            "Epoch: 21/50 - loss = 0.204\n",
            "Alice opened the door and went in. The door was shut, and was going on in the same tone, exactly as if nothing had happen\n",
            "---\n",
            "Epoch: 22/50 - loss = 0.185\n",
            "Alice opened the door and found that it led into a small passage, not much large mushroom again. But she didn’t like bein\n",
            "---\n",
            "Epoch: 23/50 - loss = 0.168\n",
            "Alice opened the door and found the door was fall and sleepy, and his eyes were half shut. “What’s the use of their heads\n",
            "---\n",
            "Epoch: 24/50 - loss = 0.152\n",
            "Alice opened the door and found that it led into a small passage, not much larger than the full Project Gutenberg™ electr\n",
            "---\n",
            "Epoch: 25/50 - loss = 0.139\n",
            "Alice opened the door and found that it led into a small passage, not much larger than she had lifted the Queen, there wa\n",
            "---\n",
            "Epoch: 26/50 - loss = 0.130\n",
            "Alice opened the door, and tried to open it; but, as the door opened inwards, and Alice's elbow was produced from images \n",
            "---\n",
            "Epoch: 27/50 - loss = 0.122\n",
            "Alice opened the door and found that it led into a small passage, not much like her keeping so close to her, one on each \n",
            "---\n",
            "Epoch: 28/50 - loss = 0.115\n",
            "Alice opened the door and found that it was the best plan.\" It sounded an excellent opportunity for repeating his remark,\n",
            "---\n",
            "Epoch: 29/50 - loss = 0.109\n",
            "Alice opened the door, and tried to open it; but, as the door opened inwards, and Alice's elbow was produced from images \n",
            "---\n",
            "Epoch: 30/50 - loss = 0.104\n",
            "Alice opened the door and found that it led into a large flower-pot that stood near. The three soldiers wandered about fo\n",
            "---\n",
            "Epoch: 31/50 - loss = 0.100\n",
            "Alice opened the door and found that it led into a small passage, not much larger than the last peg she felt that it woul\n",
            "---\n",
            "Epoch: 32/50 - loss = 0.096\n",
            "Alice opened the door and found that it led into a small passage, not much larger than she had lifted the Queen, that she\n",
            "---\n",
            "Epoch: 33/50 - loss = 0.093\n",
            "Alice opened the door and found that it led into a small passage, not much larger than the last peg, she was going to hap\n",
            "---\n",
            "Epoch: 34/50 - loss = 0.090\n",
            "Alice opened the door and found that it led into a small passage. \"It's no business there was a body to cut it off after \n",
            "---\n",
            "Epoch: 35/50 - loss = 0.087\n",
            "Alice opened the door and found that it led into a small passage. \"You make me laugh so that I can hardly hold you! And d\n",
            "---\n",
            "Epoch: 36/50 - loss = 0.084\n",
            "Alice opened the door and found that it led into a small passage, not much larger than the last of the right-hand bit aga\n",
            "---\n",
            "Epoch: 37/50 - loss = 0.083\n",
            "Alice opened the door and found that it was the best plan.\" It sounded an excellent plan, no doubt, and very neatly and s\n",
            "---\n",
            "Epoch: 38/50 - loss = 0.082\n",
            "Alice opened the door and found that it led into a small passage. \"Yes, I think you'd better leave off, you know you say \n",
            "---\n",
            "Epoch: 39/50 - loss = 0.081\n",
            "Alice opened the door and found that it led into a small passage. \"You are old,\" said the youth, \"and your Majesty must e\n",
            "---\n",
            "Epoch: 40/50 - loss = 0.080\n",
            "Alice opened the door and found that it led into a small passage, not much larger than she had lifted the Queen to disbel\n",
            "---\n",
            "Epoch: 41/50 - loss = 0.078\n",
            "Alice opened the door and found that it led into a small passage, not much larger than she had lifted the Queen, that she\n",
            "---\n",
            "Epoch: 42/50 - loss = 0.078\n",
            "Alice opened the door and found that it led into a small passage, not much larger than the fan she had tried to cut the p\n",
            "---\n",
            "Epoch: 43/50 - loss = 0.077\n",
            "Alice opened the door and found that it led into a small passage, not much larger than the last of the roofs taken off, a\n",
            "---\n",
            "Epoch: 44/50 - loss = 0.079\n",
            "Alice opened the door and found that it led into a small passage, not much larger than the full Project Gutenberg™ Licens\n",
            "---\n",
            "Epoch: 45/50 - loss = 0.081\n",
            "Alice opened the door and found that it led into a small passage, not much larger and larger, and rounder and larger, and\n",
            "---\n",
            "Epoch: 46/50 - loss = 0.088\n",
            "Alice opened the door and found that, as nearly as she could manage—the best plan now that I was! Let’s consider your age\n",
            "---\n",
            "Epoch: 47/50 - loss = 0.117\n",
            "Alice opened the door and found that, as nearly as she could, for the next tumble health. And now, if e’er by chance the \n",
            "---\n",
            "Epoch: 48/50 - loss = 0.279\n",
            "Alice opened the door, and after the door was locked, and the best of edge of the shelves: \"--and yet--it's rather curiou\n",
            "---\n",
            "Epoch: 49/50 - loss = 0.442\n",
            "Alice opened the door was hopes of one end of the wood. Alice couldn’t say this all her face, Nor wants cutting up the po\n",
            "---\n",
            "Epoch: 50/50 - loss = 0.331\n",
            "Alice opened the door again. And now, which was a very long closer to herself. “He came to things with the daisies, when \n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test generations\n",
        "gen_text = generate_text(model, \"The Queen said\", char2idx, idx2char, device, num_chars_to_generate=100)\n",
        "print(gen_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCQ63dlkSuzd",
        "outputId": "ecba42a4-4ba7-4572-eca5-e162f8d3dfa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Queen said to the White King went how fall upon Alice, and tried to stroke it; but it was _very_ dry; and then\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRNyfDoYio5X"
      },
      "source": [
        "---\n",
        "### <span style=\"color:#0b486b\"> <div  style=\"text-align:center\">**THE END**</div> </span>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}