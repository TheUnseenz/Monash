{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac6a5d0",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "CNNs are much more efficient because:\n",
    "- they preserve information that nearby pixels are related to each other\n",
    "    - instead of each pixel being connected to every other pixel (n^2 complexity per pixel), \n",
    "    each pixel only connects to the ones in a sliding window around it  \n",
    "- because they parallelize well across multi GPUs  \n",
    "\n",
    "If one layer has an error, it will propagate  \n",
    "\n",
    "Principles of computer vision:  \n",
    "- Translation invariance  \n",
    "- Locality  \n",
    "Adding channels other than red, green, blue is common to add extra dimensions to the data after stripping some by convolution.  \n",
    "\n",
    "Without zero padding, output image will shrink compared to input image  \n",
    "\n",
    "Batch normalization  \n",
    "1. Cope with internal covariate shift  \n",
    "2. Reduce vanishing/exploding gradient  \n",
    "3. Reduce overfitting  \n",
    "4. Make training more stable  \n",
    "5. Converge faster  \n",
    "\n",
    "Dropout: reduce overfitting  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3abff2",
   "metadata": {},
   "source": [
    "What is the relation between cross-entropy and convolution?  \n",
    "Cross-entropy has log  \n",
    "\n",
    "Covariate shift means the marginal distribution p(x) changes but p(y|x) stays the same. If p(y) changes, is it still covariate shift?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
