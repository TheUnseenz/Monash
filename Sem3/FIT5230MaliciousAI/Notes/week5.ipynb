{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ddf0930",
   "metadata": {},
   "source": [
    "# FIT5230 Week 5: Deepfakes II - Detection & Defense\n",
    "\n",
    "## 1. The Security Context: Anti-Deepfakes\n",
    "\n",
    "While Deepfakes use AI to attack the **Integrity (INT)** of media, Anti-Deepfake technology focuses on defense.\n",
    "\n",
    "### The Reality of Defense\n",
    "* **Prevention is impossible**: Just as cryptography cannot prevent someone from *trying* to guess a password, we cannot prevent the creation of deepfakes.\n",
    "* **Detection is key**: The goal is to distinguish legitimate media from forged media, similar to checking a cryptographic signature or verifying a watermark .\n",
    "\n",
    "### The Detection Process\n",
    "Detection is treated as a **Binary Classification Problem**:\n",
    "1.  **Input**: Media (Image, Video, Audio).\n",
    "2.  **Feature Extraction (FE)**: Isolating specific data points.\n",
    "3.  **Classifier (D)**: Determining if features belong to the \"Real\" class or \"Fake\" class.\n",
    "$$f_{test} \\rightarrow D \\rightarrow \\{Real, Fake\\}$$\n",
    "\n",
    "---\n",
    "<hr>\n",
    "\n",
    "## 2. Distinguishing Real vs. Fake: The Features\n",
    "\n",
    "To detect a fake, we must identify what makes it different from reality.\n",
    "\n",
    "### Real Media Characteristics\n",
    "* **Natural Origin**: Captured via camera sensors.\n",
    "* **Spectral Response**: Photo-sensors react to light wavelengths in specific, consistent ways.\n",
    "\n",
    "### Fake Media Characteristics (Artifacts)\n",
    "Generators (like GANs) create images from random noise, upsampling it to create pixels. This process leaves specific traces .\n",
    "\n",
    "1.  **Physical/Semantic Inconsistencies**: Visual errors where the AI fails to model physics correctly.\n",
    "    * *Examples*: Geometric inconsistencies, different eye colors (left vs. right), strange inter-reflections, or inconsistent illumination.\n",
    "2.  **Digital Artifacts**: Traces left by the generation process itself.\n",
    "    * **Upsampling Artifacts**: Real images are captured; fake images are *grown* via **Transpose Convolution** (upsampling). This leaves specific \"blocking\" artifacts and histogram patterns that differ from natural camera noise .\n",
    "\n",
    "---\n",
    "<hr>\n",
    "\n",
    "## 3. Neural Network Fundamentals (Recap)\n",
    "\n",
    "Understanding detection requires understanding the building blocks of the neural networks used for both generation and detection.\n",
    "\n",
    "### Convolution (Feature Extraction)\n",
    "* **Concept**: Sliding a kernel (filter) over an image to detect spatial patterns (edges, shapes).\n",
    "* **Stride**: The number of pixels the kernel moves per step. A stride $> 1$ reduces the output dimensions (downsampling) .\n",
    "* **Padding**: Adding border pixels (usually zeros) to the input to control the output size.\n",
    "\n",
    "### Pooling (Downsampling)\n",
    "* **Goal**: To summarize features and reduce the spatial size of the representation.\n",
    "* **Max Pooling**: Takes the maximum value in a window (captures the most prominent feature).\n",
    "* **Average Pooling**: Takes the average value (smooths the features) .\n",
    "\n",
    "### Transpose Convolution (Upsampling)\n",
    "* **Goal**: Used by Generators to increase low-resolution noise into high-resolution images.\n",
    "* **Mechanism**: It is essentially the reverse of convolution. It broadcasts input values to a larger output area. **Crucially, this is the primary source of digital artifacts in deepfakes** .\n",
    "\n",
    "### Activation Functions\n",
    "* **ReLU (Rectified Linear Unit)**: $f(x) = \\max(0, x)$. Passes positive values unchanged, zeroes out negative ones. Used in hidden layers.\n",
    "* **Sigmoid**: Squelches output between 0 and 1. Used in the final layer to output a probability (e.g., 0.9 = 90% chance it's fake) .\n",
    "\n",
    "---\n",
    "<hr>\n",
    "\n",
    "## 4. Detection Architectures\n",
    "\n",
    "Different models focus on different types of evidence to detect fakes.\n",
    "\n",
    "### A. MesoNet (The Lightweight Detective)\n",
    "* **Focus**: **Mesoscopic Properties**.\n",
    "    * *Microscopic*: Pixel-level noise (too variable).\n",
    "    * *Macroscopic*: High-level semantics (too complex).\n",
    "    * *Mesoscopic*: Mid-level features that carry traces of the manipulation process.\n",
    "* **Architecture**: A compact Convolutional Neural Network (CNN) with only a few layers (Meso-4).\n",
    "* **Use Case**: Fast, real-time detection .\n",
    "\n",
    "### B. EnsembleNet (The Robust Detective)\n",
    "* **Focus**: Combining multiple models to improve accuracy.\n",
    "* **Architecture**: An ensemble of EfficientNetB4 CNNs.\n",
    "* **Key Feature: Attention Layer**.\n",
    "    * Uses **Siamese training** (shared weights).\n",
    "    * Generates an **Attention Map** via convolution and sigmoid activation.\n",
    "    * *Benefit*: Helps the model focus on the specific regions where manipulation occurs (e.g., the face) rather than the background .\n",
    "\n",
    "### C. Vision Transformer - ViT (The Global Detective)\n",
    "* **The Problem with CNNs**: CNNs focus on local neighbors (pixels next to each other). Deepfake artifacts are often distributed globally (e.g., lighting mismatch between the face and the background).\n",
    "* **ViT Architecture**:\n",
    "    1.  **Patchify**: Splits the image into fixed-size squares (e.g., $16 \\times 16$).\n",
    "    2.  **Linear Projection**: Flattens patches into 1D vectors (tokens).\n",
    "    3.  **Positional Embedding**: Adds learnable location data to each token so the model knows the image structure.\n",
    "    4.  **Transformer Encoder**: Uses **Multi-Head Self-Attention** to analyze the relationship between *all* patches simultaneously, regardless of distance .\n",
    "* **Video Application**: ViT is excellent for **Temporal Consistency**. It can detect \"temporal glitches\" (e.g., unnatural blinking or head movement over time) by treating video frames as a sequence of tokens .\n",
    "\n",
    "---\n",
    "<hr>\n",
    "\n",
    "## 5. The Ideal Anti-Deepfake Strategy\n",
    "\n",
    "No single tool is sufficient. A robust defense requires a layered approach .\n",
    "\n",
    "1.  **Preventive Layer (Source)**:\n",
    "    * Embed cryptographic signatures or watermarks at the point of capture (cameras/official institutions) to verify authenticity.\n",
    "2.  **Layer 1: Real-Time Detection (Filter)**:\n",
    "    * Use lightweight models like **MesoNet** to scan all incoming uploads quickly.\n",
    "3.  **Layer 2: Advanced Analysis (Deep Dive)**:\n",
    "    * Flagged content is sent to heavy models.\n",
    "    * **EnsembleNet** for robust feature detection.\n",
    "    * **ViT** for global anomaly and temporal consistency checks.\n",
    "4.  **Layer 3: Human-in-the-Loop**:\n",
    "    * Low-confidence or high-stakes results (court evidence, medical records) are reviewed by human experts.\n",
    "5.  **Feedback Loop**:\n",
    "    * New deepfakes identified by humans are fed back into the training set to update the AI models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d1d825",
   "metadata": {},
   "source": [
    "# Deepfakes II\n",
    "## Anti-Deepfakes\n",
    "Deepfakes  \n",
    "- AI attacks Security property of INT  \n",
    "Anti-Deepfakes  \n",
    "- not always possible to prevent deepfakes, just like crypto  \n",
    "- detect deepfakes  \n",
    "    - Check metadata for media  \n",
    "    - Watermark  \n",
    "        - Can disrupt deepfake image to look different\n",
    "        - Attention mask maximizes differences in deepfake from minimal embedding  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dc2fdf",
   "metadata": {},
   "source": [
    "Vision Transformer (ViT)  \n",
    "Deepfake artefacts are often subtle and can span non-contiguous regions (e.g., inconsistent lighting across the entire face, unnatural reflections in eyes, irregularities in hair boundaries).  \n",
    "\n",
    "What’s wrong with CNN?  \n",
    "CNNs struggled to model global relationships between different parts of an image.  \n",
    "The self-attention mechanism of ViT inherently captures global dependencies across all image patches in a single layer.  \n",
    "This allows ViT to detect inconsistencies in the global coherence of an image that might be missed by models focusing on local features.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779869d8",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "1. What are the three core security properties discussed in the lecture, and how can AI compromise each of them?  \n",
    "- Confidentiality\n",
    "    - Inference attack\n",
    "- Integrity \n",
    "    - AI generates deepfakes\n",
    "- Authenticity\n",
    "    - AI mimic biometrics/deepfakes to impersonate  \n",
    "\n",
    "2. Explain the difference between encryption and inference attacks in the context of confidentiality.\n",
    "How does AI enhance the threat of inference attacks?  \n",
    "- ML models are great at identifying anonymous data - you need less data to break confidentiality  \n",
    "\n",
    "3. What is the role of keypoint detection in the First Order Motion Model for image animation? Why\n",
    "is it critical for generating realistic deepfakes?  \n",
    "- Keypoints help models map movements from person to person  \n",
    "\n",
    "4. Describe the brightness constancy assumption in optical flow. Why is this assumption important\n",
    "for motion estimation in deepfake generation?  \n",
    "- Brightness of point should not change as it moves around a frame.  \n",
    "  This helps motion to be tracked better without being confused by lighting.  \n",
    "\n",
    "5. In motion-supervised co-part segmentation, how is motion used to identify and segment object\n",
    "parts? What advantages does this self-supervised approach offer over traditional supervised methods?  \n",
    "-  Motion is an extra cue to identify keypoint segments  \n",
    "\n",
    "6. Compare affine and projective warping transformations. How do these affect the realism and\n",
    "accuracy of deepfake animations?  \n",
    "Projective adds depth and perspective (makes it look more 3D)  \n",
    "Affine stretches/rotates the image  \n",
    "\n",
    "7. A company uses facial recognition for employee authentication. A deepfake video mimics an\n",
    "employee’s facial gestures to gain unauthorized access. What type of biometric authentication is\n",
    "being attacked, and how could the system be improved to resist such deepfake threats?  \n",
    "Attacker targets soft biometrics, which are not unique enough\n",
    "Improvements - MFA:\n",
    "- Something you know: password  \n",
    "- Something you have: id card  \n",
    "- Something you are: fingerprint  \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
