{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a6ff1a2",
   "metadata": {},
   "source": [
    "What are your opponents doing? That's important for your defender/attacker strategy\n",
    "\n",
    "* Exam unit! MCQs and mock final assessments to prepare\n",
    "\n",
    "AI can be broadly classified to:\n",
    "1. Classification\n",
    "2. Regression\n",
    "3. Clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3475b25c",
   "metadata": {},
   "source": [
    "# Recap:\n",
    "Security is conventionally treated where the attacker is more powerful  \n",
    "Conventional AI does not consider threat of attacks on its security  \n",
    "- Security for AI considers that it's possible for samples used by AI to be corrupted i.e. attacks on the integrity of the samples  \n",
    "Conventional AI has random errors, attacks have biased errors.  \n",
    "Adversarial machine learning attacks the security property of *integrity* of AI  \n",
    "Generative adversarial networks resemble parties with opposing goals  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
