{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d1d825",
   "metadata": {},
   "source": [
    "# Deepfakes II\n",
    "## Anti-Deepfakes\n",
    "Deepfakes  \n",
    "- AI attacks Security property of INT  \n",
    "Anti-Deepfakes  \n",
    "- not always possible to prevent deepfakes, just like crypto  \n",
    "- detect deepfakes  \n",
    "    - Check metadata for media  \n",
    "    - Watermark  \n",
    "        - Can disrupt deepfake image to look different\n",
    "        - Attention mask maximizes differences in deepfake from minimal embedding  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dc2fdf",
   "metadata": {},
   "source": [
    "Vision Transformer (ViT)  \n",
    "Deepfake artefacts are often subtle and can span non-contiguous regions (e.g., inconsistent lighting across the entire face, unnatural reflections in eyes, irregularities in hair boundaries).  \n",
    "\n",
    "Whatâ€™s wrong with CNN?  \n",
    "CNNs struggled to model global relationships between different parts of an image.  \n",
    "The self-attention mechanism of ViT inherently captures global dependencies across all image patches in a single layer.  \n",
    "This allows ViT to detect inconsistencies in the global coherence of an image that might be missed by models focusing on local features.  \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
