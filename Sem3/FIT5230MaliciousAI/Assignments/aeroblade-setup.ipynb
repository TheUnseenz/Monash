{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82becae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "# !git clone https://github.com/jonasricker/aeroblade.git\n",
    "\n",
    "# Navigate into the cloned directory\n",
    "%cd aeroblade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b16e505",
   "metadata": {},
   "source": [
    "# Google colab version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b45ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\PersonalStuff\\Monash\\Sem3\\FIT5230MaliciousAI\\Assignments\\cloned_repos\\aeroblade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adria\\miniconda3\\envs\\aeroblade\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# Install a specific Python version using a more stable method for Colab\n",
    "# Note: This will restart the kernel.\n",
    "!pip install -q virtualenv\n",
    "!virtualenv -p python3.10 aeroblade_env\n",
    "!source aeroblade_env/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0044defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the core and pip-managed packages.\n",
    "# We are now pinning a compatible version of peft.\n",
    "!pip install -v --no-cache-dir --no-input \\\n",
    "    --extra-index-url https://download.pytorch.org/whl/cu128 \\\n",
    "    torch==2.8.0+cu128 torchvision==0.23.0+cu128 \\\n",
    "    peft==0.7.0 \\\n",
    "    scipy numpy \\\n",
    "    scikit-learn scikit-image \\\n",
    "    seaborn tqdm \\\n",
    "    networkx pyarrow \\\n",
    "    diffusers==0.25.1 huggingface-hub==0.25.2 \\\n",
    "    requests PyYAML filelock \\\n",
    "    pillow opencv-python \\\n",
    "    jupyter-client ipykernel ipython jupyter-core \\\n",
    "    clip-interrogator==0.6.0 joblib==1.5.2 lpips==0.1.4 pyiqa==0.1.14.1\n",
    "    \n",
    "# Install the project in editable mode\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55527868",
   "metadata": {},
   "source": [
    "# Locally run version. You may need to run this as administrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b966bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found conda at: C:\\Users\\adria\\miniconda3\\condabin\\conda.BAT\n",
      "Installing conda packages...\n",
      "Successfully installed conda packages.\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# import subprocess\n",
    "# import shutil\n",
    "\n",
    "# # Find the full path to the conda executable\n",
    "# conda_path = shutil.which(\"conda\")\n",
    "# if conda_path is None:\n",
    "#     print(\"Error: conda executable not found. Please ensure conda is installed and in your system PATH.\")\n",
    "#     # You might want to exit the script here.\n",
    "# else:\n",
    "#     print(f\"Found conda at: {conda_path}\")\n",
    "\n",
    "#     # List of conda-managed packages\n",
    "#     conda_packages = [\n",
    "#         'python=3.10',\n",
    "#         'numpy=1.26.3',\n",
    "#         'pandas=2.1.4',\n",
    "#         'scipy=1.12.0',\n",
    "#         'matplotlib=3.8.2',\n",
    "#         'scikit-learn=1.4.0',\n",
    "#         'scikit-image=0.22.0',\n",
    "#         'seaborn=0.13.2',\n",
    "#         'tqdm=4.66.1',\n",
    "#         'networkx=3.2.1',\n",
    "#         'pyarrow=15.0.0',\n",
    "#         'pip'\n",
    "#     ]\n",
    "\n",
    "#     # Install conda packages\n",
    "#     print(\"Installing conda packages...\")\n",
    "#     try:\n",
    "#         subprocess.run([conda_path, 'install', '-y', '-c', 'conda-forge'] + conda_packages, check=True)\n",
    "#         print(\"Successfully installed conda packages.\")\n",
    "#     except subprocess.CalledProcessError as e:\n",
    "#         print(f\"Failed to install conda packages: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b28b61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing pip packages...\n",
      "Successfully installed pip packages.\n",
      "Installing in editable mode...\n",
      "Successfully installed in editable mode.\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# import subprocess\n",
    "\n",
    "# # List of pip-managed packages\n",
    "# pip_packages = [\n",
    "#     '--extra-index-url', 'https://download.pytorch.org/whl/cu128',\n",
    "#     'torch==2.8.0+cu128',\n",
    "#     'torchvision==0.23.0+cu128',\n",
    "#     'diffusers==0.25.1',\n",
    "#     'huggingface-hub==0.25.2',\n",
    "#     'transformers==4.37.2',\n",
    "#     'requests==2.31.0',\n",
    "#     'PyYAML==6.0.1',\n",
    "#     'filelock==3.13.1',\n",
    "#     'pillow==10.2.0',\n",
    "#     'opencv-python==4.9.0.80',\n",
    "#     'jupyter-client==8.6.0',\n",
    "#     'ipykernel==6.28.0',\n",
    "#     'ipython==8.20.0',\n",
    "#     'jupyter-core==5.7.1',\n",
    "#     'clip-interrogator==0.6.0',\n",
    "#     'joblib==1.5.2',\n",
    "#     'lpips==0.1.4',\n",
    "#     'pyiqa==0.1.14.1'\n",
    "# ]\n",
    "\n",
    "# # Install pip packages\n",
    "# print(\"Installing pip packages...\")\n",
    "# try:\n",
    "#     subprocess.run([sys.executable, '-m', 'pip', 'install', '--no-cache-dir', '--no-input'] + pip_packages, check=True)\n",
    "#     print(\"Successfully installed pip packages.\")\n",
    "# except subprocess.CalledProcessError as e:\n",
    "#     print(f\"Failed to install pip packages: {e}\")\n",
    "\n",
    "# # Replicates !pip install -e . Might need administrator access.\n",
    "# print(\"Installing in editable mode...\")\n",
    "# try:\n",
    "#     subprocess.run([sys.executable, '-m', 'pip', 'install', '-e', '.'], check=True)\n",
    "#     print(\"Successfully installed in editable mode.\")\n",
    "# except subprocess.CalledProcessError as e:\n",
    "#     print(f\"Failed to install in editable mode: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60999fe8",
   "metadata": {},
   "source": [
    "# Run the scripts. \n",
    "This is the same whether on colab or locally run.\n",
    "Input your adversarial images as png images into example_images, or specify the folder directory manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f0247",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET IMAGE DIRECTORY HERE\n",
    "IMG_DIR = \"generated/fake_images_sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43febd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adria\\miniconda3\\envs\\aeroblade\\lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded VAE.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_21924\\3783955311.py:39: FutureWarning: Accessing config attribute `scaling_factor` directly via 'AutoencoderKL' object attribute is deprecated. Please access 'scaling_factor' over 'AutoencoderKL's config object instead, e.g. 'unet.config.scaling_factor'.\n",
      "  latent = vae.encode(x).latent_dist.sample() * vae.scaling_factor\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_21924\\3783955311.py:40: FutureWarning: Accessing config attribute `scaling_factor` directly via 'AutoencoderKL' object attribute is deprecated. Please access 'scaling_factor' over 'AutoencoderKL's config object instead, e.g. 'unet.config.scaling_factor'.\n",
      "  decoded = vae.decode(latent / vae.scaling_factor).sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Preprocessed folders in: real_img/real_nonsqface_sample\n"
     ]
    }
   ],
   "source": [
    "# Preprocess images with vaeround - increases robustness to generated images\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "VAEROUND_DIR = f\"{IMG_DIR}/vaeround\"\n",
    "\n",
    "def list_images(input_dir):\n",
    "    exts = ('.jpg', '.jpeg', '.png', '.webp', '.bmp', '.tiff')\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(exts):\n",
    "                yield os.path.join(root, f)\n",
    "\n",
    "def save_img(img: Image.Image, src_path, out_root, transform_name, input_root):\n",
    "    rel = os.path.relpath(src_path, start=input_root)   # key fix\n",
    "    dest_dir = os.path.join(out_root, transform_name, os.path.dirname(rel))\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    dest_path = os.path.join(dest_dir, os.path.basename(rel))\n",
    "    img.save(dest_path, quality=95)\n",
    "    return dest_path\n",
    "\n",
    "\n",
    "def vae_roundtrip_pil(img: Image.Image, vae=None, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Convert PIL image -> latent via SD VAE encoder -> decode back.\n",
    "    vae should be an AutoencoderKL or compatible model from diffusers.\n",
    "    Works at 1024 resolution expected; will resize image to 1024x1024.\n",
    "    \"\"\"\n",
    "    if vae is None:\n",
    "        raise RuntimeError(\"VAE model not provided\")\n",
    "    import torch\n",
    "    from torchvision import transforms\n",
    "    img = img.convert(\"RGB\")\n",
    "    img_resized = img.resize((1024, 1024), resample=Image.BICUBIC)\n",
    "    to_tensor = transforms.ToTensor()\n",
    "    x = to_tensor(img_resized).unsqueeze(0).to(device) * 2.0 - 1.0  # [-1,1]\n",
    "    with torch.no_grad():\n",
    "        latent = vae.encode(x).latent_dist.sample() * vae.scaling_factor\n",
    "        decoded = vae.decode(latent / vae.scaling_factor).sample\n",
    "    decoded = (decoded / 2 + 0.5).clamp(0, 1)\n",
    "    decoded = (decoded[0].cpu().permute(1, 2, 0).numpy() * 255).astype('uint8')\n",
    "    return Image.fromarray(decoded)\n",
    "\n",
    "inp = IMG_DIR\n",
    "out = IMG_DIR\n",
    "\n",
    "vae = None\n",
    "try:\n",
    "    from diffusers import AutoencoderKL\n",
    "    # choose a VAE checkpoint compatible with SD. Adjust repo/model as needed.\n",
    "    vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\").to(\"cuda\")\n",
    "    vae.eval()\n",
    "    print(\"Loaded VAE.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load VAE (skipping). Exception:\", e)\n",
    "    vae = None\n",
    "\n",
    "for path in list_images(inp):\n",
    "    try:\n",
    "        img = Image.open(path).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(\"skip\", path, e)\n",
    "        continue\n",
    "    \n",
    "    # VAE roundtrip    \n",
    "    try:\n",
    "        vr = vae_roundtrip_pil(img, vae=vae, device=\"cuda\")\n",
    "        save_img(vr, path, out, \"vaeround\", inp)\n",
    "    except Exception as e:\n",
    "        print(\"vae roundtrip failed for\", path, e)\n",
    "\n",
    "print(\"Done. Preprocessed folders in:\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36bf8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reconstructing with CompVis/stable-diffusion-v1-1.:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "PROGRESS (compute_distances):   0%|          | 0/3 [07:25<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module '__main__' has no attribute '__spec__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mC:\\PersonalStuff\\Monash\\Sem3\\FIT5230MaliciousAI\\Assignments\\cloned_repos\\aeroblade\\scripts\\run_aeroblade.py:87\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mparse_args()\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\PersonalStuff\\Monash\\Sem3\\FIT5230MaliciousAI\\Assignments\\cloned_repos\\aeroblade\\scripts\\run_aeroblade.py:15\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     12\u001b[0m safe_mkdir(args\u001b[38;5;241m.\u001b[39moutput_dir)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# compute distances\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m distances \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_distances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles_or_dirs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoencoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance_metric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreconstruction_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreconstructions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# save and display results\u001b[39;00m\n\u001b[0;32m     28\u001b[0m distances\u001b[38;5;241m.\u001b[39mto_csv(args\u001b[38;5;241m.\u001b[39moutput_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistances.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\PersonalStuff\\Monash\\Sem3\\FIT5230MaliciousAI\\Assignments\\cloned_repos\\aeroblade\\src\\aeroblade\\high_level_funcs.py:61\u001b[0m, in \u001b[0;36mcompute_distances\u001b[1;34m(dirs, transforms, repo_ids, distance_metrics, amount, reconstruction_root, seed, batch_size, num_workers, compute_max, **distance_kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# iterate over autoencoder repo_ids\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m repo_id \u001b[38;5;129;01min\u001b[39;00m repo_ids:\n\u001b[1;32m---> 61\u001b[0m     rec_paths \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_reconstructions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreconstruction_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     ds_rec \u001b[38;5;241m=\u001b[39m ImageFolder(rec_paths)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# iterate over distance metrics\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adria\\miniconda3\\envs\\aeroblade\\lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\PersonalStuff\\Monash\\Sem3\\FIT5230MaliciousAI\\Assignments\\cloned_repos\\aeroblade\\src\\aeroblade\\image.py:91\u001b[0m, in \u001b[0;36mcompute_reconstructions\u001b[1;34m(ds, repo_id, output_root, output_dir, iterations, seed, batch_size, num_workers)\u001b[0m\n\u001b[0;32m     89\u001b[0m generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mGenerator()\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m     90\u001b[0m reconstruction_paths \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, paths \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[0;32m     92\u001b[0m     DataLoader(ds, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, num_workers\u001b[38;5;241m=\u001b[39mnum_workers),\n\u001b[0;32m     93\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReconstructing with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     94\u001b[0m ):\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# normalize\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device(), dtype\u001b[38;5;241m=\u001b[39mae\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# encode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adria\\miniconda3\\envs\\aeroblade\\lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adria\\miniconda3\\envs\\aeroblade\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:494\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adria\\miniconda3\\envs\\aeroblade\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:427\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adria\\miniconda3\\envs\\aeroblade\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1172\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1165\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1172\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\adria\\miniconda3\\envs\\aeroblade\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adria\\miniconda3\\envs\\aeroblade\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adria\\miniconda3\\envs\\aeroblade\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adria\\miniconda3\\envs\\aeroblade\\lib\\multiprocessing\\popen_spawn_win32.py:45\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m---> 45\u001b[0m     prep_data \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_preparation_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# read end of pipe will be duplicated by the child process\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# -- see spawn_main() in spawn.py.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# bpo-33929: Previously, the read end of pipe was \"stolen\" by the child\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# process, but it leaked a handle if the child process had been\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# terminated before it could steal the handle from the parent process.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     rhandle, whandle \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreatePipe(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\adria\\miniconda3\\envs\\aeroblade\\lib\\multiprocessing\\spawn.py:183\u001b[0m, in \u001b[0;36mget_preparation_data\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Figure out whether to initialise main in the subprocess as a module\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# or through direct execution (or to leave it alone entirely)\u001b[39;00m\n\u001b[0;32m    182\u001b[0m main_module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 183\u001b[0m main_mod_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43mmain_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__spec__\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m main_mod_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit_main_from_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m main_mod_name\n",
      "\u001b[1;31mAttributeError\u001b[0m: module '__main__' has no attribute '__spec__'"
     ]
    }
   ],
   "source": [
    "# Image directory specified above\n",
    "%run scripts/run_aeroblade.py --files-or-dirs {VAEROUND_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43aa438f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing distances_fake_image_sample.csv ===\n",
      "\n",
      "Prediction counts:\n",
      "prediction\n",
      "fake    455\n",
      "true     35\n",
      "\n",
      "Accuracy (on 490 images with ground truth): 0.9286\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted  fake  true\n",
      "Actual               \n",
      "fake        455    35\n",
      "\n",
      "=== Processing distances_fakegen_vaeround.csv ===\n",
      "\n",
      "Prediction counts:\n",
      "prediction\n",
      "fake    15\n",
      "\n",
      "Accuracy (on 15 images with ground truth): 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted  fake\n",
      "Actual         \n",
      "fake         15\n",
      "\n",
      "=== Processing distances_real_vae_1024.csv ===\n",
      "\n",
      "Prediction counts:\n",
      "prediction\n",
      "true    428\n",
      "fake     72\n",
      "\n",
      "Accuracy (on 500 images with ground truth): 0.8560\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted  fake  true\n",
      "Actual               \n",
      "true         72   428\n",
      "\n",
      "==============================\n",
      "=== Overall Summary Across All Files ===\n",
      "\n",
      "Total prediction counts (all images):\n",
      "prediction\n",
      "fake    542\n",
      "true    463\n",
      "\n",
      "Overall Accuracy (on 1005 labeled images): 0.8935\n",
      "\n",
      "Overall Confusion Matrix:\n",
      "Predicted  fake  true\n",
      "Actual               \n",
      "fake        470    35\n",
      "true         72   428\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# ==== CONFIG ====\n",
    "decision_boundary = -0.008  # <-- Adjust here\n",
    "\n",
    "input_dir = \"aeroblade_output\"\n",
    "\n",
    "# =================\n",
    "\n",
    "def classify(distance):\n",
    "    if 0 >= distance >= decision_boundary:\n",
    "        return \"fake\"\n",
    "    elif distance < decision_boundary:\n",
    "        return \"true\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "def extract_label(path, filename):\n",
    "    path_str = f\"{path} {filename}\".lower()\n",
    "    if \"real\" in path_str:\n",
    "        return \"true\"\n",
    "    elif \"fake\" in path_str:\n",
    "        return \"fake\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Find all CSV files starting with \"distances\"\n",
    "csv_files = sorted(glob(os.path.join(input_dir, \"distances*.csv\")))\n",
    "if not csv_files:\n",
    "    print(f\"No files found starting with 'distances' in {input_dir}\")\n",
    "    exit()\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    print(f\"\\n=== Processing {os.path.basename(csv_file)} ===\")\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df_max = df[df[\"repo_id\"] == \"max\"].copy()\n",
    "\n",
    "    if df_max.empty:\n",
    "        print(\"No 'max' rows found, skipping.\")\n",
    "        continue\n",
    "\n",
    "    df_max[\"prediction\"] = df_max[\"distance\"].apply(classify)\n",
    "    df_max[\"ground_truth\"] = df_max.apply(\n",
    "        lambda row: extract_label(row[\"dir\"], row[\"file\"]), axis=1\n",
    "    )\n",
    "\n",
    "    # Prediction counts (all images)\n",
    "    counts = df_max[\"prediction\"].value_counts(dropna=False)\n",
    "    print(\"\\nPrediction counts:\")\n",
    "    print(counts.to_string())\n",
    "\n",
    "    # Evaluate where ground truth is known\n",
    "    valid = df_max[df_max[\"ground_truth\"] != \"unknown\"]\n",
    "    if not valid.empty:\n",
    "        accuracy = (valid[\"prediction\"] == valid[\"ground_truth\"]).mean()\n",
    "        print(f\"\\nAccuracy (on {len(valid)} images with ground truth): {accuracy:.4f}\")\n",
    "\n",
    "        confusion = pd.crosstab(valid[\"ground_truth\"], valid[\"prediction\"],\n",
    "                                rownames=[\"Actual\"], colnames=[\"Predicted\"], dropna=False)\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(confusion)\n",
    "    else:\n",
    "        accuracy = None\n",
    "        confusion = None\n",
    "        print(\"⚠️ No ground-truth labels found in this file.\")\n",
    "\n",
    "    # Keep for overall tally\n",
    "    df_max[\"source_file\"] = os.path.basename(csv_file)\n",
    "    all_results.append(df_max)\n",
    "\n",
    "# ==== Aggregate overall stats ====\n",
    "if all_results:\n",
    "    df_all = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"=== Overall Summary Across All Files ===\")\n",
    "\n",
    "    # Prediction counts\n",
    "    total_counts = df_all[\"prediction\"].value_counts(dropna=False)\n",
    "    print(\"\\nTotal prediction counts (all images):\")\n",
    "    print(total_counts.to_string())\n",
    "\n",
    "    # Accuracy + confusion for known labels\n",
    "    valid_all = df_all[df_all[\"ground_truth\"] != \"unknown\"]\n",
    "    if not valid_all.empty:\n",
    "        overall_accuracy = (valid_all[\"prediction\"] == valid_all[\"ground_truth\"]).mean()\n",
    "        print(f\"\\nOverall Accuracy (on {len(valid_all)} labeled images): {overall_accuracy:.4f}\")\n",
    "\n",
    "        overall_confusion = pd.crosstab(valid_all[\"ground_truth\"], valid_all[\"prediction\"],\n",
    "                                        rownames=[\"Actual\"], colnames=[\"Predicted\"], dropna=False)\n",
    "        print(\"\\nOverall Confusion Matrix:\")\n",
    "        print(overall_confusion)\n",
    "    else:\n",
    "        print(\"\\n⚠️ No ground-truth labels found across any files.\")\n",
    "else:\n",
    "    print(\"\\nNo valid 'max' data found in any distances CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd8c6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeroblade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
