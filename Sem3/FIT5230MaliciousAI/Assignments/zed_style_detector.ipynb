{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ZED-style Zero-Shot Detector (Entropy-based)\n",
        "\n",
        "**What this notebook does**\n",
        "\n",
        "- Implements a *ZED-style* detector for AI-generated images without using the original authors' code.\n",
        "- Uses a pretrained neural **entropy model** from **CompressAI** to compute an entropy score (bits-per-pixel, bpp).\n",
        "- **No fake data needed for training**: calibrate a threshold using *real images only*.\n",
        "- Evaluate on your own real/fake sets; visualize histograms & ROC; export CSV scores.\n",
        "\n",
        "**Folder layout expected**\n",
        "\n",
        "```\n",
        "data/\n",
        "  real/   # put real images here (jpg/png)\n",
        "  fake/   # put synthetic images here (optional, for evaluation)\n",
        "```\n",
        "\n",
        "**How to run**\n",
        "1. Upload this notebook to **Google Colab** (recommended) or run locally with Python 3.10+.\n",
        "2. Create `data/real` and (optionally) `data/fake` and add images.\n",
        "3. Run all cells.\n",
        "4. For deployment, use the *Single Image Inference* cell.\n",
        "\n",
        "> ⚠️ This is a faithful *reproduction of the idea* behind ZED using open components. Results depend on your chosen entropy model and preprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "If packages are missing, run: pip install compressai torch torchvision scikit-learn pillow matplotlib\n"
          ]
        }
      ],
      "source": [
        "#@title 0) Setup (installs) — run once per environment\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "    !pip -q install compressai==1.2.6 torch torchvision scikit-learn pillow matplotlib\n",
        "else:\n",
        "    print(\"If packages are missing, run: pip install compressai torch torchvision scikit-learn pillow matplotlib\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dae12e51",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting compressai==1.2.6\n",
            "  Downloading compressai-1.2.6.tar.gz (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.9/163.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting einops (from compressai==1.2.6)\n",
            "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from compressai==1.2.6) (1.26.4)\n",
            "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from compressai==1.2.6) (2.2.3)\n",
            "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from compressai==1.2.6) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from compressai==1.2.6) (3.10.0)\n",
            "Requirement already satisfied: torch>=1.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from compressai==1.2.6) (2.7.0)\n",
            "Collecting torch-geometric>=2.3.0 (from compressai==1.2.6)\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from compressai==1.2.6) (4.12.2)\n",
            "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (from compressai==1.2.6) (0.20.1)\n",
            "Collecting pytorch-msssim (from compressai==1.2.6)\n",
            "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from compressai==1.2.6) (4.67.1)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.7.1->compressai==1.2.6) (3.13.1)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.7.1->compressai==1.2.6) (69.5.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.7.1->compressai==1.2.6) (1.14.0)\n",
            "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.7.1->compressai==1.2.6) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.7.1->compressai==1.2.6) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.7.1->compressai==1.2.6) (2024.3.1)\n",
            "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from torch-geometric>=2.3.0->compressai==1.2.6) (3.9.5)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch-geometric>=2.3.0->compressai==1.2.6) (5.9.0)\n",
            "Requirement already satisfied: pyparsing in /opt/anaconda3/lib/python3.12/site-packages (from torch-geometric>=2.3.0->compressai==1.2.6) (3.0.9)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from torch-geometric>=2.3.0->compressai==1.2.6) (2.32.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->compressai==1.2.6) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->compressai==1.2.6) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->compressai==1.2.6) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->compressai==1.2.6) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->compressai==1.2.6) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->compressai==1.2.6) (10.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->compressai==1.2.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->compressai==1.2.6) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->compressai==1.2.6) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->compressai==1.2.6) (1.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.7.1->compressai==1.2.6) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch-geometric>=2.3.0->compressai==1.2.6) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch-geometric>=2.3.0->compressai==1.2.6) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch-geometric>=2.3.0->compressai==1.2.6) (1.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch-geometric>=2.3.0->compressai==1.2.6) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch-geometric>=2.3.0->compressai==1.2.6) (1.9.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.7.1->compressai==1.2.6) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torch-geometric>=2.3.0->compressai==1.2.6) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torch-geometric>=2.3.0->compressai==1.2.6) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torch-geometric>=2.3.0->compressai==1.2.6) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torch-geometric>=2.3.0->compressai==1.2.6) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
            "Building wheels for collected packages: compressai\n",
            "  Building wheel for compressai (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for compressai: filename=compressai-1.2.6-cp312-cp312-macosx_11_0_arm64.whl size=401429 sha256=16ab0477e4e41853c473fd1a27639d940db5dd68909c32353d6dd255cd0aec9a\n",
            "  Stored in directory: /Users/kuan_/Library/Caches/pip/wheels/6e/29/1f/b2b9f9e8b1523d10eb7a222e85f7ebf365e57bcf457d465dc7\n",
            "Successfully built compressai\n",
            "Installing collected packages: einops, torch-geometric, pytorch-msssim, compressai\n",
            "Successfully installed compressai-1.2.6 einops-0.8.1 pytorch-msssim-1.0.0 torch-geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install compressai==1.2.6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @amp.autocast(enabled=False)\n"
          ]
        }
      ],
      "source": [
        "#@title 1) Imports & utilities\n",
        "import os, glob, math, json, random\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, f1_score\n",
        "\n",
        "from compressai.zoo import bmshj2018_hyperprior, cheng2020_attn\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using device:', DEVICE)\n",
        "\n",
        "IMG_EXTS = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}\n",
        "\n",
        "def list_images(folder: str) -> List[str]:\n",
        "    p = Path(folder)\n",
        "    if not p.exists():\n",
        "        return []\n",
        "    return sorted([str(x) for x in p.rglob('*') if x.suffix.lower() in IMG_EXTS])\n",
        "\n",
        "def load_image(path: str, max_side: int = 512) -> torch.Tensor:\n",
        "    \"\"\"Load image -> torch.Tensor [1,3,H,W] in [0,1]. Resizes so the longer side <= max_side.\"\"\"\n",
        "    img = Image.open(path).convert('RGB')\n",
        "    w, h = img.size\n",
        "    scale = min(1.0, max_side / max(w, h))\n",
        "    if scale < 1.0:\n",
        "        new_w, new_h = int(w*scale), int(h*scale)\n",
        "        img = img.resize((max(1,new_w), max(1,new_h)), Image.LANCZOS)\n",
        "    arr = np.asarray(img).astype(np.float32) / 255.0\n",
        "    x = torch.from_numpy(arr).permute(2,0,1).unsqueeze(0)\n",
        "    return x\n",
        "\n",
        "def choose_entropy_model(model_name: str = 'bmshj2018_hyperprior', quality: int = 8):\n",
        "    \"\"\"Load a pretrained CompressAI model. quality in [1..8] (higher = better rate-distortion, more compute).\"\"\"\n",
        "    if model_name == 'bmshj2018_hyperprior':\n",
        "        m = bmshj2018_hyperprior(quality=quality, pretrained=True)\n",
        "    elif model_name == 'cheng2020_attn':\n",
        "        m = cheng2020_attn(pretrained=True)\n",
        "    else:\n",
        "        raise ValueError('Unknown model_name')\n",
        "    m.eval().to(DEVICE)\n",
        "    try:\n",
        "        m.update()  # updates entropy parameters if needed\n",
        "    except Exception as e:\n",
        "        print('Warning: model.update() failed:', e)\n",
        "    return m\n",
        "\n",
        "def bpp_from_likelihoods(x: torch.Tensor, out: dict) -> torch.Tensor:\n",
        "    \"\"\"Estimate bits-per-pixel using model likelihoods (faster than full arithmetic coding).\"\"\"\n",
        "    N, C, H, W = x.shape\n",
        "    total_bits = 0.0\n",
        "    for k, lik in out['likelihoods'].items():\n",
        "        # Ensure numerical stability\n",
        "        lik = torch.clamp(lik, min=1e-9)\n",
        "        total_bits += torch.sum(-torch.log2(lik))\n",
        "    bpp = total_bits / (N * H * W)\n",
        "    return bpp\n",
        "\n",
        "def zed_score(image_path: str, model, multiscale=(1.0, 0.75, 0.5)) -> float:\n",
        "    \"\"\"Compute a ZED-style surprisal score: average bpp across a few downscale factors.\"\"\"\n",
        "    scores = []\n",
        "    base = Image.open(image_path).convert('RGB')\n",
        "    for s in multiscale:\n",
        "        w, h = base.size\n",
        "        img = base if s == 1.0 else base.resize((max(1,int(w*s)), max(1,int(h*s))), Image.LANCZOS)\n",
        "        x = torch.from_numpy(np.asarray(img).astype(np.float32)/255.0).permute(2,0,1).unsqueeze(0).to(DEVICE)\n",
        "        with torch.inference_mode():\n",
        "            out = model(x)\n",
        "            bpp = bpp_from_likelihoods(x, out)\n",
        "        scores.append(float(bpp.detach().cpu()))\n",
        "    return float(np.mean(scores))\n",
        "\n",
        "def batch_scores(paths: List[str], model, desc: str = '') -> List[float]:\n",
        "    scores = []\n",
        "    for i, p in enumerate(paths):\n",
        "        sc = zed_score(p, model)\n",
        "        scores.append(sc)\n",
        "        if (i+1) % 10 == 0:\n",
        "            print(f\"{desc} {i+1}/{len(paths)}: current={sc:.4f}\")\n",
        "    return scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://compressai.s3.amazonaws.com/models/v1/bmshj2018-hyperprior-8-a583f0cf.pth.tar\" to /Users/kuan_/.cache/torch/hub/checkpoints/bmshj2018-hyperprior-8-a583f0cf.pth.tar\n",
            "100%|██████████| 46.0M/46.0M [03:02<00:00, 265kB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded: bmshj2018_hyperprior quality 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#@title 2) Load model\n",
        "model_name = 'bmshj2018_hyperprior'  #@param ['bmshj2018_hyperprior', 'cheng2020_attn']\n",
        "quality = 8  #@param {type:'slider', min:1, max:8, step:1}\n",
        "model = choose_entropy_model(model_name, quality)\n",
        "print('Model loaded:', model_name, 'quality', quality)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b93205bb",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m zip_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mROOT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/tiny-imagenet-200.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(zip_path):\n\u001b[0;32m---> 16\u001b[0m     urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlretrieve(\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://cs231n.stanford.edu/tiny-imagenet-200.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m, zip_path\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(zip_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zf:\n\u001b[1;32m     21\u001b[0m     zf\u001b[38;5;241m.\u001b[39mextractall(ROOT)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/urllib/request.py:268\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reporthook:\n\u001b[1;32m    266\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[0;32m--> 268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m block \u001b[38;5;241m:=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(bs):\n\u001b[1;32m    269\u001b[0m     read \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(block)\n\u001b[1;32m    270\u001b[0m     tfp\u001b[38;5;241m.\u001b[39mwrite(block)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/socket.py:708\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# --- Setup: download Tiny ImageNet and export N real images for ZED ---\n",
        "import os, zipfile, urllib.request, random, shutil\n",
        "from PIL import Image\n",
        "\n",
        "ROOT = \"data/tiny-imagenet\"\n",
        "OUT  = \"data/zed\"\n",
        "N_TRAIN, N_VAL = 2000, 500   # change counts as you like\n",
        "SIZE = 256                   # resize target (ZED usually uses 224/256)\n",
        "\n",
        "os.makedirs(ROOT, exist_ok=True)\n",
        "os.makedirs(f\"{OUT}/train/real\", exist_ok=True)\n",
        "os.makedirs(f\"{OUT}/val/real\", exist_ok=True)\n",
        "\n",
        "zip_path = f\"{ROOT}/tiny-imagenet-200.zip\"\n",
        "if not os.path.exists(zip_path):\n",
        "    urllib.request.urlretrieve(\n",
        "        \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\", zip_path\n",
        "    )\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "    zf.extractall(ROOT)\n",
        "\n",
        "# Collect all train/val image paths\n",
        "def collect(img_dir):\n",
        "    paths = []\n",
        "    for cls in os.listdir(img_dir):\n",
        "        p = os.path.join(img_dir, cls, \"images\")\n",
        "        if os.path.isdir(p):\n",
        "            for f in os.listdir(p):\n",
        "                if f.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                    paths.append(os.path.join(p, f))\n",
        "    return paths\n",
        "\n",
        "train_imgs = collect(os.path.join(ROOT, \"tiny-imagenet-200\", \"train\"))\n",
        "val_dir    = os.path.join(ROOT, \"tiny-imagenet-200\", \"val\", \"images\")\n",
        "val_imgs   = [os.path.join(val_dir, f) for f in os.listdir(val_dir)\n",
        "              if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(train_imgs)\n",
        "random.shuffle(val_imgs)\n",
        "train_imgs = train_imgs[:N_TRAIN]\n",
        "val_imgs   = val_imgs[:N_VAL]\n",
        "\n",
        "def export(paths, outdir):\n",
        "    for i, src in enumerate(paths):\n",
        "        try:\n",
        "            im = Image.open(src).convert(\"RGB\")\n",
        "            im = im.resize((SIZE, SIZE), Image.BICUBIC)\n",
        "            im.save(os.path.join(outdir, f\"real_{i:06d}.jpg\"), quality=95)\n",
        "        except Exception as e:\n",
        "            print(\"skip\", src, e)\n",
        "\n",
        "export(train_imgs, f\"{OUT}/train/real\")\n",
        "export(val_imgs,   f\"{OUT}/val/real\")\n",
        "\n",
        "print(\"Done. Sample:\",\n",
        "      len(os.listdir(f'{OUT}/train/real')), \"train,\",\n",
        "      len(os.listdir(f'{OUT}/val/real')),   \"val\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6f63c54c",
      "metadata": {},
      "outputs": [
        {
          "ename": "HTTPError",
          "evalue": "HTTP Error 404: Not Found",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m fake_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/jeffheaton/WhichFaceIsReal-dataset/raw/master/fake.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m fake_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfake.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 23\u001b[0m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlretrieve(fake_url, fake_zip)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(fake_zip, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zf:\n\u001b[1;32m     25\u001b[0m     zf\u001b[38;5;241m.\u001b[39mextractall(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/fake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/urllib/request.py:240\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(urlopen(url, data)) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    241\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/urllib/request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/urllib/request.py:521\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    520\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 521\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/urllib/request.py:630\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 630\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/urllib/request.py:559\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    558\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/urllib/request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/urllib/request.py:639\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 639\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ],
      "source": [
        "import os, urllib.request, zipfile, random, shutil\n",
        "\n",
        "os.makedirs(\"data/real\", exist_ok=True)\n",
        "os.makedirs(\"data/fake\", exist_ok=True)\n",
        "\n",
        "# --- Download a tiny set of real images ---\n",
        "url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
        "zip_path = \"tiny-imagenet.zip\"\n",
        "if not os.path.exists(zip_path):\n",
        "    urllib.request.urlretrieve(url, zip_path)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "    zf.extractall(\".\")\n",
        "\n",
        "# Copy 50 real images into data/real\n",
        "src_dir = \"tiny-imagenet-200/train/n01443537/images\"\n",
        "for i, f in enumerate(os.listdir(src_dir)[:50]):\n",
        "    shutil.copy(os.path.join(src_dir, f), f\"data/real/real_{i:03d}.jpg\")\n",
        "\n",
        "# --- Download some fake faces (StyleGAN on Kaggle mirror) ---\n",
        "fake_url = \"https://github.com/jeffheaton/WhichFaceIsReal-dataset/raw/master/fake.zip\"\n",
        "fake_zip = \"fake.zip\"\n",
        "urllib.request.urlretrieve(fake_url, fake_zip)\n",
        "with zipfile.ZipFile(fake_zip, 'r') as zf:\n",
        "    zf.extractall(\"data/fake\")\n",
        "\n",
        "print(\"Real images:\", len(os.listdir(\"data/real\")))\n",
        "print(\"Fake images:\", len(os.listdir(\"data/fake\")))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 0 real images, 0 fake images\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "Please add some images into data/real first.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m fake_paths \u001b[38;5;241m=\u001b[39m list_images(FAKE_DIR)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(real_paths)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m real images, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(fake_paths)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fake images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(real_paths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease add some images into data/real first.\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Please add some images into data/real first."
          ]
        }
      ],
      "source": [
        "#@title 3) Point to your data folders\n",
        "REAL_DIR = 'data/real'  #@param {type:'string'}\n",
        "FAKE_DIR = 'data/fake'  #@param {type:'string'}\n",
        "\n",
        "real_paths = list_images(REAL_DIR)\n",
        "fake_paths = list_images(FAKE_DIR)\n",
        "print(f\"Found {len(real_paths)} real images, {len(fake_paths)} fake images\")\n",
        "assert len(real_paths) > 0, 'Please add some images into data/real first.'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 4) Calibrate threshold on REAL images only\n",
        "target_fpr = 0.05  #@param {type:'number'}\n",
        "np.random.seed(0)\n",
        "calib_subset = real_paths  # you can subsample if you have many\n",
        "real_scores = batch_scores(calib_subset, model, desc='Real')\n",
        "thr = float(np.quantile(real_scores, 1.0 - target_fpr))\n",
        "print(f\"Calibrated threshold @FPR~{target_fpr:.2f}: {thr:.4f} bpp\")\n",
        "\n",
        "# Save for later use\n",
        "os.makedirs('artifacts', exist_ok=True)\n",
        "json.dump({'threshold_bpp': thr, 'model_name': model_name, 'quality': quality}, open('artifacts/zed_threshold.json','w'))\n",
        "np.savetxt('artifacts/real_scores.csv', np.array(real_scores), delimiter=',')\n",
        "print('Saved artifacts to artifacts/ directory')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 5) Evaluate on REAL and FAKE (if available)\n",
        "def predict_label(score, thr):\n",
        "    return 1 if score > thr else 0  # 1=fake, 0=real\n",
        "\n",
        "all_y, all_s = [], []\n",
        "print('Scoring real set...')\n",
        "real_scores_eval = batch_scores(real_paths, model, desc='RealEval')\n",
        "all_y += [0]*len(real_scores_eval)\n",
        "all_s += real_scores_eval\n",
        "\n",
        "fake_scores_eval = []\n",
        "if len(fake_paths) > 0:\n",
        "    print('Scoring fake set...')\n",
        "    fake_scores_eval = batch_scores(fake_paths, model, desc='FakeEval')\n",
        "    all_y += [1]*len(fake_scores_eval)\n",
        "    all_s += fake_scores_eval\n",
        "\n",
        "metrics = {}\n",
        "if len(set(all_y)) == 2:\n",
        "    auroc = roc_auc_score(all_y, all_s)\n",
        "    fpr, tpr, _ = roc_curve(all_y, all_s)\n",
        "    preds = [predict_label(s, thr) for s in all_s]\n",
        "    acc = accuracy_score(all_y, preds)\n",
        "    f1 = f1_score(all_y, preds)\n",
        "    metrics = {'AUROC': auroc, 'ACC@thr': acc, 'F1@thr': f1}\n",
        "    print('Metrics:', metrics)\n",
        "else:\n",
        "    print('Only real images found; evaluated calibration only.')\n",
        "\n",
        "# Save detailed CSV\n",
        "import csv\n",
        "with open('artifacts/scores_detailed.csv','w', newline='') as f:\n",
        "    w = csv.writer(f)\n",
        "    w.writerow(['path','label(0=real,1=fake)','score_bpp','pred(0=real,1=fake)'])\n",
        "    for p, s in zip(real_paths, real_scores_eval):\n",
        "        w.writerow([p, 0, s, predict_label(s, thr)])\n",
        "    for p, s in zip(fake_paths, fake_scores_eval):\n",
        "        w.writerow([p, 1, s, predict_label(s, thr)])\n",
        "print('Saved artifacts/scores_detailed.csv')\n",
        "\n",
        "# Plots\n",
        "plt.figure(figsize=(6,4))\n",
        "if len(real_scores_eval):\n",
        "    plt.hist(real_scores_eval, bins=40, alpha=0.6, label='real')\n",
        "if len(fake_scores_eval):\n",
        "    plt.hist(fake_scores_eval, bins=40, alpha=0.6, label='fake')\n",
        "plt.axvline(thr, linestyle='--', label=f'Threshold={thr:.3f}')\n",
        "plt.xlabel('Entropy score (bpp)')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Score distribution')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "if len(metrics):\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('FPR')\n",
        "    plt.ylabel('TPR')\n",
        "    plt.title(f'ROC (AUROC={metrics[\"AUROC\"]:.3f})')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 6) Single Image Inference (deploy-style)\n",
        "import json\n",
        "cfg = json.load(open('artifacts/zed_threshold.json')) if os.path.exists('artifacts/zed_threshold.json') else None\n",
        "if cfg:\n",
        "    print('Loaded threshold config:', cfg)\n",
        "else:\n",
        "    print('No saved threshold found; using current settings.')\n",
        "    cfg = {'threshold_bpp': thr, 'model_name': model_name, 'quality': quality}\n",
        "\n",
        "TEST_IMAGE = ''  #@param {type:'string'}\n",
        "if TEST_IMAGE:\n",
        "    score = zed_score(TEST_IMAGE, model)\n",
        "    decision = 'FAKE' if score > cfg['threshold_bpp'] else 'REAL'\n",
        "    print(f\"Image: {TEST_IMAGE}\\nScore (bpp): {score:.4f}\\nDecision: {decision}\")\n",
        "else:\n",
        "    print('Set TEST_IMAGE to a file path to run inference.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 7) (Optional) Ensemble over multiple models\n",
        "def zed_score_ensemble(image_path: str, models: list) -> float:\n",
        "    return float(np.mean([zed_score(image_path, m) for m in models]))\n",
        "\n",
        "## Example usage:\n",
        "# models = [choose_entropy_model('bmshj2018_hyperprior', q) for q in (6,8)]\n",
        "# sc = zed_score_ensemble('data/real/example.jpg', models)\n",
        "# print('Ensemble score:', sc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes & Tips\n",
        "- **Calibration**: The 95th percentile threshold on real scores targets ~5% FPR. Adjust `target_fpr` to your needs.\n",
        "- **Speed**: Using `bpp_from_likelihoods` avoids full arithmetic coding and is faster, while remaining faithful to the idea.\n",
        "- **Robustness**: You can improve robustness by averaging scores over multiple scales and mild JPEG compressions.\n",
        "- **Security**: Like all detectors, this can be attacked. Consider ensembling, input randomization, and frequency-domain checks for production.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
