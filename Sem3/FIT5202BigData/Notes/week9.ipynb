{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4566d02",
   "metadata": {},
   "source": [
    "# Big Data Lecture Notes: Stream Data Processing\n",
    "\n",
    "## Part 1: Fundamentals of Data Streams\n",
    "\n",
    "### What is a Data Stream? üèûÔ∏è\n",
    "\n",
    "A **data stream** is a real-time, continuous, and ordered sequence of data items that is potentially unbounded (infinite). Unlike a traditional database where data is stored before being queried, stream data is processed as it arrives.\n",
    "\n",
    "Think of it like a river: the water (data) is always flowing, and you can't store the entire river. You can only analyze the water that is passing by you right now.\n",
    "\n",
    "#### Key Characteristics of Streaming Data\n",
    "* **Unbounded Data**: The data arrives continuously and has no defined end.\n",
    "* **Real-time Processing**: Queries are run continuously over the data as it arrives, and quick responses are needed.\n",
    "* **Continuous Arrival**: Data can arrive at a uniform rate (e.g., a sensor reading every second) or in sudden bursts (e.g., a surge in social media posts).\n",
    "* **Focus on Events/Trends**: We are often interested in detecting events or tracking trends over time.\n",
    "\n",
    "\n",
    "#### Database vs. Stream Processing\n",
    "\n",
    "| Feature | Database (Batch Processing) | Stream Processing |\n",
    "| :--- | :--- | :--- |\n",
    "| **Data Scope** | Bounded (entire dataset) | Unbounded (infinite stream) |\n",
    "| **Data State** | Relatively static | Dynamic and constantly changing |\n",
    "| **Queries** | Complex, ad-hoc queries | Simple, continuous queries |\n",
    "| **Answers** | Exact and precise | Often approximate |\n",
    "| **Data Access** | Can access data multiple times | Single-pass operation (no backtracking) |\n",
    "\n",
    "### Querying Data Streams\n",
    "\n",
    "Since we can't store an entire infinite stream, we must process data on the fly, often using a **synopsis** or **accumulator** to maintain a summary.\n",
    "\n",
    "* **Question**: *How to find the total number of attendees up to now?*\n",
    "    * **Answer**: Use a single accumulator variable. When a new data point arrives, add its value to the accumulator. There's no need to store the individual data points.\n",
    "* **Question**: *How to find the average number of attendees so far?*\n",
    "    * **Answer**: Use two accumulators: one for the sum and another for the count. The average can be calculated at any time by dividing the sum by the count.\n",
    "* **Question**: *How to predict if the next number will be higher or lower?*\n",
    "    * **Answer**: This is a predictive query. It requires learning from past data. Since we have limited memory, we can't store the whole stream. Instead, we use a model that gets updated as new data arrives.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: Windowing\n",
    "\n",
    "Windowing is the most common technique for handling unbounded streams. It allows us to run computations over a finite chunk, or \"window,\" of the stream.\n",
    "\n",
    "### Types of Windows\n",
    "\n",
    "1.  **Time-Based Windows**: The window is defined by a fixed time duration.\n",
    "    * **Example**: \"Calculate the average traffic volume over the last 5 minutes.\"\n",
    "    * The number of data points in each window can vary, especially if the data arrives in bursts.\n",
    "2.  **Tuple-Based (Count-Based) Windows**: The window is defined by a fixed number of data points.\n",
    "    * **Example**: \"Calculate the average price over the last 100 stock trades.\"\n",
    "    * The time duration covered by each window can vary.\n",
    "\n",
    "### Window Movement\n",
    "\n",
    "Windows can move over the stream in two primary ways:\n",
    "\n",
    "1.  **Tumbling Windows (Non-Overlapping)**: The window \"tumbles\" forward in increments equal to its size. Each data point belongs to exactly one window.\n",
    "2.  **Sliding Windows (Overlapping)**: The window \"slides\" forward in increments smaller than its size. This means the windows overlap, and a single data point can belong to multiple windows. This is useful for getting more frequent updates.\n",
    "\n",
    "* **Practice Question**: A stream has tuples in the format `(eventTime, value, processingTime)`. We use a **time-based window** with a **size of 3 seconds** and a **slide of 2 seconds**, starting at processing time 1. What is in the third window?\n",
    "    * **Data**: `{1,a,1}, {2,b,4}, {3,c,4}, {5,e,6}, {6,f,8}, {7,g,8}, ...`\n",
    "    * **Answer**: We trace the windows based on *processing time*.\n",
    "        1.  **Window 1**: Covers the time interval `[1, 4)`. It contains tuples with processing times of 1, 2, and 3. The tuples are: `{1,a,1}`. *Wait, re-reading the example data, the tuples are {1,a,1}, then {2,b,4}, {3,c,4}. So Window 1 contains all three.*\n",
    "        2.  **Window 2**: The window slides by 2 seconds, so it starts at time `1+2=3`. It covers the interval `[3, 6)`, containing tuples with processing times of 3, 4, and 5. The tuples are: `{2,b,4}, {3,c,4}, {5,e,6}`.\n",
    "        3.  **Window 3**: The window slides by another 2 seconds, starting at time `3+2=5`. It covers the interval `[5, 8)`, containing tuples with processing times of 5, 6, and 7. The tuples are: `{5,e,6}, {6,f,8}, {7,g,8}`.\n",
    "    * The correct answer is **C**.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 3: Stream Processing Technologies\n",
    "\n",
    "### Real-Time Streaming Architecture\n",
    "\n",
    "Modern streaming architectures typically involve a few key components working together. A common pattern is integrating **Apache Kafka** with **Apache Spark Streaming**.\n",
    "\n",
    "\n",
    "* **Producers**: Applications that generate and send the data streams (e.g., IoT devices, web servers).\n",
    "* **Kafka**: A messaging system that ingests and stores these streams in a fault-tolerant way.\n",
    "* **Spark Streaming**: A processing engine that consumes the streams from Kafka in small batches, processes them, and sends the results to a destination.\n",
    "* **Consumers/Destinations**: Applications or systems that use the processed data, such as a database, a dashboard, or another consumer application.\n",
    "\n",
    "### Apache Kafka üì¨\n",
    "\n",
    "Kafka is a distributed, publish-subscribe messaging system that acts as the central nervous system for real-time data. It's designed to be scalable, durable, and fault-tolerant.\n",
    "\n",
    "#### Key Kafka Concepts\n",
    "* **Producer**: Publishes streams of records to Kafka topics.\n",
    "* **Consumer**: Subscribes to topics to read and process the streams of records.\n",
    "* **Topic**: A category or feed name to which records are published. Think of it as a table in a database, but for a stream. A topic is stored as a **commit log**.\n",
    "* **Broker**: A Kafka server. Kafka is run as a cluster of one or more brokers that manage the data.\n",
    "* **Partition**: A topic is split into multiple partitions. Each partition is an ordered, append-only log. Splitting a topic into partitions allows for parallelism, as multiple consumers can read from different partitions at the same time. Partitions are also replicated across brokers for fault tolerance.\n",
    "* **Offset**: A unique sequence ID given to each record as it arrives in a partition. Consumers are responsible for tracking the offset they have read up to, which gives them full control over how they consume messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d1d825",
   "metadata": {},
   "source": [
    "### Stream Data Processing\n",
    "Data stream is a real-time, continuous, time-ordered sequence of items\n",
    "\n",
    "We store accumulated statistics of data and not every data item due to memory constraints\n",
    "Stream window size determines processing needed\n",
    "\n",
    "Database\n",
    "- Bounded data\n",
    "- Relatively static data\n",
    "- Complex, adhoc query\n",
    "- Can backtrack during processing\n",
    "- Exact answer to a query\n",
    "- Tuples arrival rate is low\n",
    "\n",
    "Stream processing\n",
    "- Unbounded data\n",
    "- Dynamic data\n",
    "- Simple, continuous query\n",
    "- No backtracking, single pass operation\n",
    "- Approximate answer to a query\n",
    "- Tuples arrival rate is high\n",
    "\n",
    "### Run week 9 Lab. New docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01694501",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
