{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b8adf91",
   "metadata": {},
   "source": [
    "# Week 2 Notes: Parallel Databases and Search\n",
    "\n",
    "## Part 1: Introduction to Parallel Databases (Volume I)\n",
    "\n",
    "This section covers the foundational concepts of parallel database processing, including the obstacles to performance and the high-level architectures.\n",
    "\n",
    "### üéØ Parallelism Objectives & Obstacles\n",
    "\n",
    "The main objectives of parallel query processing are to improve performance through **Speed Up** (running a task faster with more resources) and **Scale Up** (handling more data in the same time with more resources).\n",
    "\n",
    "However, achieving perfect linear performance is hindered by several obstacles:\n",
    "\n",
    "* **Start-up and Consolidation**: Every parallel task has \"serial parts\".\n",
    "    * **Start-up** is the initial cost of initiating all the parallel processes.\n",
    "    * **Consolidation** is the final cost of collecting and combining the results from all processors.\n",
    "* **Interference and Communication**:\n",
    "    * **Interference** occurs when parallel processes compete for shared resources (like a bus or disk).\n",
    "    * **Communication** introduces overhead, as processes may need to wait for data or signals from other processes.\n",
    "* **Skew**: This refers to the unevenness or imbalance of the workload among processors. A skewed workload is undesirable because the total job time is limited by the most overloaded processor.\n",
    "\n",
    "### üå™Ô∏è Modeling Skew\n",
    "\n",
    "Skew is often modeled using the **Zipf distribution**. This model helps estimate the data distribution's unevenness.\n",
    "\n",
    "* The formula is: $|R_{i}|=\\frac{|R|}{i^{0}\\times\\sum_{j=1}^{N}\\frac{1}{j^{0}}}$ \n",
    "* The parameter **$\\theta$ (theta)** denotes the degree of skewness.\n",
    "    * **$\\theta = 0$**: Indicates no skew (a uniform distribution).\n",
    "    * **$\\theta = 1$**: Indicates a highly skewed distribution.\n",
    "\n",
    "\n",
    "### üèõÔ∏è Parallel Database Architectures\n",
    "\n",
    "There are four main architectures for parallel databases:\n",
    "\n",
    "1.  **Shared-Memory**: All processors share a common main memory and all disks.\n",
    "    * **Pro**: Load balancing is relatively easy.\n",
    "    * **Con**: Suffers from memory and bus contention as more processors are added.\n",
    "2.  **Shared-Disk**: Each processor has its own private main memory, but all processors share all disks.\n",
    "3.  **Shared-Nothing**: This is the most scalable architecture. Each processor has its own private main memory *and* its own private disks. Processors communicate over an interconnected network.\n",
    "    * **Con**: Load balancing is more difficult.\n",
    "4.  **Shared-Something (Cluster)**: A hybrid model that is common in practice. It consists of multiple \"nodes\" connected in a shared-nothing network. Each individual node is a shared-memory (SMP) machine.\n",
    "\n",
    "### ‚ö° Forms of Parallelism\n",
    "\n",
    "Parallelism can be applied at different levels to speed up database processing:\n",
    "\n",
    "* **Interquery Parallelism**: Different queries are executed in parallel. This is the primary way to scale up online transaction processing (OLTP) systems.\n",
    "* **Intraquery Parallelism**: A single, complex query is broken down and its parts are executed in parallel. This is used to speed up long-running queries , and it can be done in two ways:\n",
    "    * **Intraoperation Parallelism**: A single operation (like a sort or a join) is parallelized by partitioning the data.\n",
    "    * **Interoperation Parallelism**: *Different* operations within the same query are executed concurrently. This includes:\n",
    "        * **Pipeline Parallelism**: The output of one operation is immediately fed as input to the next, like an assembly line.\n",
    "        * **Independent Parallelism**: Operations that do not depend on each other are executed at the same time.\n",
    "\n",
    "In practice, a query will use a **Mixed Parallelism** approach, combining all these forms.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: Parallel Search (Volume II)\n",
    "\n",
    "This section applies parallel processing concepts specifically to search (selection) operations.\n",
    "\n",
    "### ‚ùì Types of Search Queries\n",
    "\n",
    "A search query is a \"selection\" operation that retrieves a horizontal subset (records) from a table.\n",
    "\n",
    "* **Exact-Match Search**: Uses an exact value, like `WHERE Sid = 23`.\n",
    "* **Range Search**: Covers a range of values.\n",
    "    * **Continuous**: `WHERE Sgpa > 3.50`.\n",
    "    * **Discrete**: `WHERE Sdegree IN ('BCS', 'BInfSys')`.\n",
    "* **Multiattribute Search**: Involves more than one attribute, using `AND` or `OR`.\n",
    "\n",
    "### üóÇÔ∏è Data Partitioning Strategies\n",
    "\n",
    "Data partitioning is the act of distributing data across multiple processing elements to enable parallelism.\n",
    "\n",
    "#### Basic Partitioning Methods\n",
    "First, data can be partitioned **vertically** (splitting by columns/attributes) or **horizontally** (splitting by rows/records). Horizontal partitioning is more common for parallel databases.\n",
    "\n",
    "Key horizontal partitioning methods include:\n",
    "\n",
    "* **Round-Robin**: Each record is allocated to the next processor in turn.\n",
    "    * **Pros**: Guarantees even data distribution and perfect load balance.\n",
    "    * **Cons**: Data is not grouped semantically. An exact-match query must run on *all* processors, as there's no way to know where the data is.\n",
    "* **Hash Partitioning**: A hash function is applied to an attribute to determine which processor stores the record.\n",
    "    * **Pros**: Data is grouped semantically. Very efficient for exact-match searches, as the query can be sent to exactly *one* processor.\n",
    "    * **Cons**: Can cause data skew. Inefficient for range searches, as the hash values are not ordered, requiring *all* processors to be activated.\n",
    "* **Range Partitioning**: Records are distributed based on a range of values for an attribute (e.g., A-C to P1, D-G to P2).\n",
    "    * **Pros**: Excellent for range searches, as the query can be localized to only the \"selected\" processors that hold that range.\n",
    "    * **Cons**: Can easily result in data skew if data is not uniformly distributed.\n",
    "* **Random-Unequal Partitioning**: The partitioning method is unknown or based on a non-retrieval attribute. This is common for temporary data that results from a previous operation.\n",
    "\n",
    "#### Complex Partitioning Methods\n",
    "These methods are based on multiple attributes or combine basic methods.\n",
    "\n",
    "* **HRPS (Hybrid-Range Partitioning Strategy)**: Combines range and round-robin. It first divides the data into many small *range* fragments, then distributes those fragments in a *round-robin* fashion. This strategy provides the range localization benefits of range partitioning while also achieving the load-balancing properties of round-robin.\n",
    "* **MAGIC (Multiattribute Grid Declustering)**: Partitions data based on multiple attributes. It creates a grid where each attribute is an axis, and each cell in the grid is assigned to a processor. This allows queries on *any* of the partitioning attributes to be localized to a subset of processors.\n",
    "* **BERD (Bubba's Extended Range Declustering)**: A two-level multiattribute method. It first applies range partitioning on a *primary* attribute. It then creates an \"auxiliary\" table based on a *secondary* attribute, which is also range partitioned.\n",
    "\n",
    "### üèÉ Parallel Search Algorithms\n",
    "\n",
    "A parallel search algorithm has three main components:\n",
    "\n",
    "1.  **Processor Activation (or Involvement)**\n",
    "    This determines how many processors need to be activated for a query. It depends entirely on the **partitioning method** and the **query type**.\n",
    "    * **Example**: An *exact-match* query on *hash-partitioned* data only needs **1** processor. The same query on *round-robin* data needs **All** processors.\n",
    "    * **Example**: A *continuous range* query on *range-partitioned* data only needs **Selected** processors. The same query on *hash-partitioned* data needs **All** processors.\n",
    "\n",
    "2.  **Local Searching Method**\n",
    "    This is the search algorithm used *within* each activated processor.\n",
    "    * If the local data is **Ordered**, use **Binary Search**.\n",
    "    * If the local data is **Unordered**, use **Linear Search**.\n",
    "\n",
    "3.  **Key Comparison**\n",
    "    This determines whether to stop searching after finding a match.\n",
    "    * You can **Stop** after the first match *only if* the query is an **Exact Match** and the attribute's values are **Unique**.\n",
    "    * In all other cases (range queries, or if duplicates are possible), you must **Continue** searching to find all possible matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4d48f2",
   "metadata": {},
   "source": [
    "# Parallel Computing\n",
    "Obstacles causing sub-linear speedups:  \n",
    "- Startup and consolidation costs\n",
    "    - Startup: Initiation of multiple processes\n",
    "    - Consolidation: Cost of collecting results obtained by each processor by host processor\n",
    "- Interference and communication\n",
    "    - Interference: Competing to access shared resources\n",
    "    - Communication: One process communicating with other processes, and often one has to \n",
    "    wait for others to be ready for communication (i.e. waiting time) (**bottleneck**)\n",
    "- Skew\n",
    "    - Unevenness of workload: requires load balancing\n",
    "    - Measure of skew: \n",
    "$$\n",
    "|R_i| = \\frac{|R|}{i^{\\theta} \\times \\sum_{j=1}^{N} \\frac{1}{j^{\\theta}}}\n",
    "\\quad \\text{where } 0 \\leq \\theta \\leq 1\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2567f5ad",
   "metadata": {},
   "source": [
    "# Forms of Parallelism\n",
    "Forms of parallelism for database processing:  \n",
    "- Interquery parallelism  \n",
    "- Intraquery parallelism  \n",
    "- Interoperation parallelism  \n",
    "- Intraoperation parallelism  \n",
    "- Mixed parallelism  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff22cc",
   "metadata": {},
   "source": [
    "# Parallel Database Architectures\n",
    "Parallel computers are no longer a monopoly of supercomputers  \n",
    "Parallel computers are available in many forms:  \n",
    "- Shared-memory architecture\n",
    "- Shared-disk architecture\n",
    "- Shared-nothing architecture\n",
    "- Shared-something architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ce9161",
   "metadata": {},
   "source": [
    "# Parallel Search\n",
    "## Search Queries\n",
    "3 kinds of search queries:  \n",
    "- Exact-match search  \n",
    "- Range search  \n",
    "- Multi attribute search  \n",
    "\n",
    "## Data Partitioning\n",
    "- Distributes data over a number of processing elements\n",
    "- Each processing element executed in parallel\n",
    "- Can be physical or logical data partitioning\n",
    "\n",
    "### Basic Data Partitioning\n",
    "- Vertical vs horizontal data partitioning  \n",
    "    - Vertical: partitions data across all processors  \n",
    "        - Used in distributed database systems  \n",
    "    - Horizontal: each processor holds a partial number of complete records  \n",
    "        - Used in parallel relational database systems  \n",
    "- Round robin data partitioning  \n",
    "    - Sequential equal partitioning  \n",
    "    - Even distribution of items, but data is not grouped semantically  \n",
    "- Hash data partitioning  \n",
    "    - A hash function (math formula) partitions the data  \n",
    "    - Data grouped semantically, easy for exact match search but not range search  \n",
    "    - Initial data skewed   \n",
    "- Range data partitioning   \n",
    "    - Spread the records based on given range of partitioning attribute e.g. based on gpa  \n",
    "    - Initial data allocation skewed  \n",
    "- Random unequal data partitioning   \n",
    "    - Random everything  \n",
    "\n",
    "### Complex Data Partitioning\n",
    "- Partitioning done based on multiple attributes or single attribute but multiple partitioning methods  \n",
    "- Single attribute with multiple partitioning methods:  \n",
    "    - Hybrid-Range Partitioning Strategy (HRPS)  \n",
    "        - Partition to fragments using range, then distribute fragments by round robin  \n",
    "        - Cannot localize a range query search  \n",
    "\n",
    "        ‚Äì Support for Small Tables  \n",
    "        If the number of fragments of a table is less than the number of processors, \n",
    "        then the table will automatically be partitioned across a subset of the processors  \n",
    "        ‚Äì Support for Tables with Nonuniform Distributions of the Partitioning Attribute Values  \n",
    "        Because the cardinality of each fragment is not based on the value of the \n",
    "        partitioning attribute value, once the HRPS determines the cardinality of each \n",
    "        fragment, it will partition a table based on that value.  \n",
    "\n",
    "- Multiple attributes:  \n",
    "    - Multiattribute Grid Declustering (MAGIC)  \n",
    "    - Bubba‚Äôs Extended Range Declustering (BERB)  \n",
    "\n",
    "\n",
    "## Search Algorithms\n",
    "Serial search algorithms:  \n",
    "- Linear search  \n",
    "- Binary search  \n",
    " \n",
    "Parallel earch algorithms:  \n",
    "- Processor activation or involvement  \n",
    "- Local searching method (linear or binary)  \n",
    "- Key comparison  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597791a0",
   "metadata": {},
   "source": [
    "Spark session is a higher level of spark context\n",
    "Spark SQL - module for structured data processing"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
