{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d1d825",
   "metadata": {},
   "source": [
    "# Big Data Lecture Notes\n",
    "\n",
    "## Part 1: Introduction to Machine Learning\n",
    "\n",
    "### What is Machine Learning (ML)? ü§î\n",
    "\n",
    "Machine learning gives computers the ability to learn without being explicitly programmed. It's used in many applications you see daily. For example, a McKinsey study found that ML-driven recommendations are responsible for **35% of Amazon purchases** and **75% of what people watch on Netflix**.\n",
    "\n",
    "A formal definition by Tom Mitchell (1997) is: \"A computer program is said to learn from **experience E** with respect to some class of **tasks T** and **performance measure P**, if its performance at tasks in T, as measured by P, improves with experience E\".\n",
    "\n",
    "Let's break that down with an example like **face recognition**:\n",
    "* **Task (T)**: Given a new photo, recognize the name of the person.\n",
    "* **Experience (E)**: A database of thousands of known faces.\n",
    "* **Performance (P)**: How accurately the recognition is.\n",
    "\n",
    "***\n",
    "\n",
    "### Core Elements of Machine Learning\n",
    "\n",
    "ML systems are built on three key elements: Data, Model, and Assessment.\n",
    "\n",
    "#### 1. Data üìä\n",
    "Data is the foundation of ML.\n",
    "* It consists of **features** (input variables, denoted as $x \\in \\mathbb{R}^{d}$) and sometimes **labels** (output variables, denoted as $y \\in Y$).\n",
    "* A collection of these data points forms a **dataset**: $\\mathcal{D}=\\{x_{i},y_{i}\\}_{i=1}^{n}$.\n",
    "* Before feeding data to a model, it must be processed through steps like feature extraction, selection, transformation, and normalization.\n",
    "\n",
    "#### 2. Model üß†\n",
    "The model is the algorithm that learns patterns from the data.\n",
    "* In supervised learning, the goal is to find a function $f_{\\theta}:X\\rightarrow Y$ that maps data from the data space (X) to the label space (Y).\n",
    "* The **predictive model** is represented as $Y=f_{\\theta}(X)$.\n",
    "* **Model Learning (Training)** is the process of finding the optimal model parameters ($\\theta$) by minimizing the error between the model's predictions and the true labels in the training data, based on a loss function.\n",
    "\n",
    "#### 3. Assessment üìà\n",
    "This step evaluates how well the model performs.\n",
    "* **Model Testing** involves using the learned model to make predictions on new, unseen test data: $\\hat{y}=f_{\\theta}(x_{test})$.\n",
    "* **Performance metrics** (like accuracy) are used to assess the model's predictions against the actual values.\n",
    "\n",
    "***\n",
    "\n",
    "### Machine Learning Workflow Overview\n",
    "\n",
    "The ML process is split into two main stages:\n",
    "\n",
    "1.  **Training Stage**: A learning algorithm uses the **training data** ($D_{train}$) to find a suitable predictive model ($Y=f_{\\theta}(X)$).\n",
    "2.  **Prediction Stage**: The trained model is given new **test data** ($x_{test}$) to generate a **predicted label** ($\\hat{y}$), which is then evaluated for performance.\n",
    "\n",
    "\n",
    "\n",
    "[Image of a machine learning workflow diagram]\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "### Types of Machine Learning\n",
    "\n",
    "There are two primary types of machine learning, distinguished by the kind of data they use.\n",
    "\n",
    "#### Supervised Learning üßë‚Äçüè´\n",
    "\n",
    "In supervised learning, the goal is to learn a function from **labeled training data** to predict an output for new, unlabeled input. The training data includes both input features and the correct output labels.\n",
    "\n",
    "There are two main sub-types:\n",
    "\n",
    "1.  **Classification**: The output is a discrete label or category.\n",
    "    * **Binary Classification**: Separates inputs into one of two classes (e.g., \"dog\" or \"not dog\").\n",
    "    * **Multinomial (Multi-class) Classification**: Separates inputs into one of multiple classes (e.g., \"Australian shepherd,\" \"golden retriever,\" or \"poodle\").\n",
    "2.  **Regression**: The output is a continuous, real-world value (e.g., predicting ice cream sales in dollars based on temperature).\n",
    "\n",
    "Common supervised learning algorithms in Apache Spark include Linear Regression, Logistic Regression, Decision Trees, and Support Vector Machines (SVMs).\n",
    "\n",
    "#### Unsupervised Learning üïµÔ∏è\n",
    "\n",
    "In unsupervised learning, the goal is to discover underlying structures and patterns in **unlabeled data**.\n",
    "\n",
    "The two main sub-types are:\n",
    "\n",
    "1.  **Clustering**: Divides data into groups (clusters) where items in the same cluster are more similar to each other than to those in other clusters (e.g., grouping customers by purchasing habits).\n",
    "2.  **Association**: Discovers rules that describe relationships between items in a large dataset (e.g., \"people who buy X also tend to buy Y\").\n",
    "\n",
    "Common unsupervised learning algorithms in Apache Spark include k-means, Latent Dirichlet Allocation (LDA), and Gaussian Mixture Models.\n",
    "\n",
    "***\n",
    "\n",
    "### Model Assessment and Performance\n",
    "\n",
    "To assess a model, we need to prepare the data and measure its performance.\n",
    "\n",
    "* **Data Preparation**:\n",
    "    * **Train-Test Split**: The dataset is split into a training set (e.g., 80%) to build the model and a test set (e.g., 20%) to evaluate it on unseen data.\n",
    "    * **K-fold Cross-Validation**: A technique to improve model robustness by splitting the data into 'k' folds, training on k-1 folds, and testing on the remaining one, repeating for all folds.\n",
    "* **Performance Metrics** (for classification):\n",
    "    * These are calculated using values from a **confusion matrix**: True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN).\n",
    "    * **Accuracy**: $Accuracy = \\frac{tp + tn}{tp + tn + fp + fn}$\n",
    "        * **Note**: This formula calculates the proportion of total predictions that were correct. It adds the number of correct positive predictions (tp) and correct negative predictions (tn) and divides by the total number of predictions.\n",
    "    * **Precision**: $Precision = \\frac{tp}{tp + fp}$\n",
    "        * **Note**: This formula measures the accuracy of positive predictions. It divides the number of true positives (tp) by the total number of items predicted as positive (tp + fp).\n",
    "    * **Recall (Sensitivity)**: $Recall = \\frac{tp}{tp + fn}$\n",
    "        * **Note**: This formula measures how many of the actual positives were correctly identified. It divides the number of true positives (tp) by the total number of actual positive items (tp + fn).\n",
    "    * **F1-Score**: $F = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall}$\n",
    "        * **Note**: This is the harmonic mean of Precision and Recall, providing a single score that balances both metrics.\n",
    "\n",
    "***\n",
    "\n",
    "### Bias vs. Variance Trade-off\n",
    "\n",
    "Two key concepts in model performance are bias and variance.\n",
    "\n",
    "* **Bias**: The gap between the model's average prediction and the actual value. **High bias** can cause an algorithm to miss relevant relations between features and target outputs (**underfitting**).\n",
    "* **Variance**: Measures the distance of the predicted values in relation to each other. **High variance** can cause an algorithm to model the random noise in the training data (**overfitting**).\n",
    "\n",
    "The ideal model has **low bias** and **low variance**.\n",
    "\n",
    "* **Underfitting (High Bias, Low Variance)**: The model is too simple and does not perform well even on the training data.\n",
    "* **Overfitting (Low Bias, High Variance)**: The model performs well on training data but generalizes poorly to new data.\n",
    "\n",
    "#### How to Prevent Overfitting\n",
    "\n",
    "1.  **Train with more data**: More data can help the model learn the true underlying patterns instead of noise.\n",
    "2.  **Remove features**: A simpler model with fewer features can be less prone to overfitting.\n",
    "3.  **Early stopping**: Stop the training process before the model starts to overfit, typically when performance on a validation set starts to decrease.\n",
    "4.  **Cross-validation**: Use methods like k-fold cross-validation to ensure the model generalizes well to different subsets of data.\n",
    "\n",
    "## Part 2: Featurization\n",
    "\n",
    "### The ML Pipeline and Featurization\n",
    "\n",
    "A typical ML pipeline involves:\n",
    "1.  **Featurization**: Converting raw training data (e.g., text) into numerical **feature vectors** that algorithms can understand.\n",
    "2.  **Training**: Feeding these vectors into a model to learn patterns.\n",
    "3.  **Model Evaluation**: Testing different models to find the best one.\n",
    "\n",
    "\n",
    "\n",
    "**Featurization** is the process of extracting, transforming, and selecting features. Defining the right features is often the most critical part of the ML process.\n",
    "\n",
    "***\n",
    "\n",
    "### Feature Extraction\n",
    "\n",
    "This involves extracting features from \"raw\" data. For text data, common techniques include:\n",
    "\n",
    "#### 1. Count Vectorizer\n",
    "Converts a collection of text documents into vectors of token (word) counts. It selects the top words by frequency to create a vocabulary.\n",
    "\n",
    "#### 2. TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "A statistic that shows how important a word is to a document in a collection (corpus). It's calculated in two parts:\n",
    "\n",
    "* **Term Frequency (TF)**: Measures how frequently a term appears in a document.\n",
    "    * $TF(t,d)$\n",
    "        * **Note**: This represents the frequency of term 't' in document 'd'.\n",
    "* **Inverse Document Frequency (IDF)**: Measures how much information a word provides by looking at how common or rare it is across all documents.\n",
    "    * $IDF(t,D) = log \\frac{|D|+1}{DF(t,D)+1}$\n",
    "        * **Note**: This formula calculates the importance of a term.\n",
    "        * $t$: The term (word).\n",
    "        * $D$: The corpus (the entire collection of documents).\n",
    "        * $|D|$: The total number of documents in the corpus.\n",
    "        * $DF(t,D)$: The number of documents that contain the term 't'.\n",
    "        * The log scale helps to dampen the effect of very high IDF values.\n",
    "* **TF-IDF Score**: The product of the two values.\n",
    "    * $TFIDF(t,d,D) = TF(t,d) \\cdot IDF(t,D)$\n",
    "        * **Note**: This final score combines the term frequency within a document with its inverse document frequency across the entire corpus. A high score means the term is frequent in a specific document but rare overall, making it a significant feature.\n",
    "\n",
    "* **Practice Question**: Calculate the TF-IDF for the term ‚Äúexample‚Äù.\n",
    "    * **Answer**: Using the formulas from the slides, if Document 1 is \"this is a sample\" (5 words) and Document 2 is \"this is another example example example\" (7 words):\n",
    "        * **TF(\"example\", d2)** = 3 / 7 ‚âà 0.43.\n",
    "        * **TF(\"example\", d1)** = 0.\n",
    "        * **DF(\"example\", D)** = 1 (appears in one document).\n",
    "        * **IDF(\"example\", D)** = log((2+1)/(1+1)) = log(1.5) ‚âà 0.176.\n",
    "        * **TF-IDF(\"example\", d2, D)** = 0.43 * 0.176 ‚âà 0.075.\n",
    "        * **TF-IDF(\"example\", d1, D)** = 0 * 0.176 = 0.\n",
    "\n",
    "#### 3. Word2Vec\n",
    "Maps each word to a unique fixed-size numerical vector. This allows the model to understand semantic relationships between words.\n",
    "\n",
    "***\n",
    "\n",
    "### Feature Transformation\n",
    "\n",
    "This involves scaling, converting, or modifying features.\n",
    "\n",
    "* **Tokenization**: Breaking text (like a sentence) into individual terms (tokens).\n",
    "* **Stop Words Remover**: Removing common words (like \"the\", \"a\", \"is\") that appear frequently but don't carry much meaning.\n",
    "* **String Indexing**: Converting a column of string labels into a column of numerical indices.\n",
    "* **One-Hot Encoding (OHE)**: Maps a categorical feature index to a binary vector where a single '1' indicates the presence of a specific feature value.\n",
    "\n",
    "* **Question**: Why can't we stop at String Indexing?\n",
    "    * **Answer**: String Indexing assigns numerical values (e.g., Javascript=0, Python=1, Scala=2). Machine learning algorithms might misinterpret these numbers as having an **ordinal relationship** (e.g., that 2 is \"greater\" than 1), which is incorrect for categorical data without a natural order. One-Hot Encoding removes this problem by creating a binary vector for each category, so there is no implied order.\n",
    "\n",
    "***\n",
    "\n",
    "### Feature Selection\n",
    "\n",
    "This involves selecting a subset of the most important features to improve model performance and reduce complexity.\n",
    "\n",
    "* **Vector Slicer**: A tool used to extract a sub-array of features from a larger feature vector."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
