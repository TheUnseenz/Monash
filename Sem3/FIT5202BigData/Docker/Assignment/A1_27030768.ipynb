{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5202 2025 S2 Assignment 1 : Analysing Australian Property Market Data\n",
    "\n",
    "## Table of Contents\n",
    "* [Part 1 : Working with RDD](#part-1)  \n",
    "    - [1.1 Data Preparation and Loading](#1.1)  \n",
    "    - [1.2 Data Partitioning in RDD](#1.2)  \n",
    "    - [1.3 Query/Analysis](#1.3)  \n",
    "* [Part 2 : Working with DataFrames](#2-dataframes)  \n",
    "    - [2.1 Data Preparation and Loading](#2-dataframes)  \n",
    "    - [2.2 Query/Analysis](#2.2)  \n",
    "* [Part 3 :  RDDs vs DataFrame vs Spark SQL](#part-3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Feel free to add Code/Markdown cells as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 : Working with RDDs (30%) <a class=\"anchor\" name=\"part-1\"></a>\n",
    "## 1.1 Working with RDD\n",
    "In this section, you will need to create RDDs from the given datasets, perform partitioning in these RDDs and use various RDD operations to answer the queries. \n",
    "\n",
    "1.1.1 Data Preparation and Loading <a class=\"anchor\" name=\"1.1\"></a>\n",
    "1.\tWrite the code to create a SparkContext object using SparkSession. To create a SparkSession, you first need to build a SparkConf object that contains information about your application. Use Melbourne time as the session timezone. Give your application an appropriate name and run Spark locally with 4 cores on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkConf class into program\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# local[*]: run Spark in local mode with as many working processors as logical cores on your machine\n",
    "# If we want Spark to run locally with 'k' worker threads, we can specify as \"local[k]\".\n",
    "master = \"local[4]\"\n",
    "# The `appName` field is a name to be shown on the Spark cluster UI page\n",
    "app_name = \"Assignment1\"\n",
    "# Setup configuration parameters for Spark\n",
    "spark_conf = SparkConf().setMaster(master).setAppName(app_name)\n",
    "\n",
    "# Import SparkContext and SparkSession classes\n",
    "from pyspark import SparkContext # Spark\n",
    "from pyspark.sql import SparkSession # Spark SQL\n",
    "\n",
    "# Method 1: Using SparkSession\n",
    "spark = SparkSession.builder.config(conf=spark_conf).config(\"spark.sql.session.timeZone\", \"GMT+10\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.2 Load the CSV and JSON files into multiple RDDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = [\"data/council.json\", \"data/nsw_property_price.csv\", \"data/property_purpose.json\", \"data/zoning.json\"]\n",
    "rdds = []  \n",
    "headers = {}\n",
    "for file in files:\n",
    "    # get file extension\n",
    "    ext = os.path.splitext(file)[1].lower()  \n",
    "    # filter out whitespace\n",
    "    rdd = (\n",
    "        sc.textFile(file)\n",
    "          .map(lambda x: x.strip().rstrip(\",\").replace(\"{\", \"\").replace(\"}\", \"\"))\n",
    "          .filter(lambda x: x != \"\")\n",
    "    )\n",
    "\n",
    "    if ext == \".json\":\n",
    "        rdds.append((rdd, \"json\", file))\n",
    "    elif ext == \".csv\":\n",
    "        rdds.append((rdd, \"csv\", file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.3 For each RDD, remove the header rows and display the total count and the first 8 records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/council.json: grouped=220\n",
      "data/nsw_property_price.csv: grouped=4854814\n",
      "data/property_purpose.json: grouped=865\n",
      "data/zoning.json: grouped=71\n",
      "Header for data/council.json = \"council_id,council_name\"\n",
      "Header for data/nsw_property_price.csv = \"property_id\",\"purchase_price\",\"address\",\"post_code\",\"property_type\",\"strata_lot_number\",\"property_name\",\"area\",\"area_type\",\"iso_contract_date\",\"iso_settlement_date\",\"nature_of_property\",\"legal_description\",\"id\",\"council_id\",\"purpose_id\",\"zone_id\"\n",
      "Header for data/property_purpose.json = \"purpose_id, primary_purpose\"\n",
      "Header for data/zoning.json = \"zoning_id, zoning\"\n",
      "[{'council_id': '1', 'council_name': '003'}, {'council_id': '3', 'council_name': '013'}]\n",
      "[{'property_id': '4270509', 'purchase_price': '1400000.00', 'address': '8 C NYARI RD', 'post_code': 'KENTHURST', 'property_type': '2156', 'strata_lot_number': 'house', 'property_name': '', 'area': '', 'area_type': '2.044', 'iso_contract_date': 'H', 'iso_settlement_date': '2023-12-14', 'nature_of_property': '2024-02-14', 'legal_description': 'V', 'id': '2/1229857', 'council_id': '142', 'purpose_id': '200', 'zone_id': '9922'}, {'property_id': '4329326', 'purchase_price': '1105000.00', 'address': '82 CAMARERO ST', 'post_code': 'BOX HILL', 'property_type': '2765', 'strata_lot_number': 'house', 'property_name': '', 'area': '', 'area_type': '300.2', 'iso_contract_date': 'M', 'iso_settlement_date': '2024-01-12', 'nature_of_property': '2024-02-09', 'legal_description': 'R', 'id': '1119/1256791', 'council_id': '143', 'purpose_id': '200', 'zone_id': '7071'}]\n",
      "[{'purpose_id': '1', 'primary_purpose': ''}, {'purpose_id': '29', 'primary_purpose': '10 FLATS'}]\n",
      "[{'zoning_id': '1', 'zoning': ''}, {'zoning_id': '3', 'zoning': 'AGB'}]\n"
     ]
    }
   ],
   "source": [
    "# used GPT to assemble the messy logic together cleanly\n",
    "def safe_dict(it):\n",
    "    \"\"\"Safely turn iterable of kv pairs into dict, skipping malformed entries.\"\"\"\n",
    "    d = {}\n",
    "    for kv in it:\n",
    "        if isinstance(kv, tuple) and len(kv) == 2:\n",
    "            k, v = kv\n",
    "            d[k] = v\n",
    "    return d\n",
    "\n",
    "def process_rdd(rdd, ext, filename):\n",
    "    # remove header\n",
    "    header = rdd.first()\n",
    "    clean_header = header.split(\"\\\\n\", 1)[0]\n",
    "    if clean_header.startswith('\"') and not clean_header.endswith('\"'):\n",
    "        clean_header += '\"'  # restore the closing quote\n",
    "    headers[filename] = clean_header\n",
    "    lines = rdd.filter(lambda s: s != header)\n",
    "\n",
    "    \n",
    "    if ext == \"json\":        \n",
    "        # robust key:value parsing (handles both \"key : value\" and \"key\": \"value\")\n",
    "        kv = (\n",
    "            lines\n",
    "            .map(lambda s: s.strip())\n",
    "            .filter(lambda s: \":\" in s)              # accept any colon, with or without spaces\n",
    "            .map(lambda s: s.split(\":\", 1))          # split once, keep right side intact\n",
    "            .filter(lambda kv: len(kv) == 2)         # keep only well-formed pairs\n",
    "            .map(lambda kv: (kv[0].strip(' \"\\',{}'), kv[1].strip(' \"\\',{}')))\n",
    "        )\n",
    "\n",
    "        # group into records (assumes each record spans 2 lines)\n",
    "        grouped = (\n",
    "            kv.zipWithIndex()\n",
    "              .map(lambda x: (x[1] // 2, x[0]))\n",
    "              .groupByKey()\n",
    "              .mapValues(safe_dict)\n",
    "              .values()\n",
    "        )\n",
    "\n",
    "        print(f\"{filename}: grouped={grouped.count()}\")\n",
    "        return grouped\n",
    "    \n",
    "    if ext == \"csv\":\n",
    "        \n",
    "        fieldnames = [h.strip().strip('\"') for h in headers[filename].split(\",\")]\n",
    "        lines = (\n",
    "            lines.map(lambda row: dict(\n",
    "                zip(\n",
    "                    fieldnames,\n",
    "                    [val.strip().strip('\"') for val in row.split(\",\")]\n",
    "                )\n",
    "            ))\n",
    "        )\n",
    "        print(f\"{filename}: grouped={lines.count()}\")\n",
    "        return lines\n",
    "\n",
    "# Replace items in rdds\n",
    "rdds = [\n",
    "    (process_rdd(rdd, ext, filename), ext, filename)\n",
    "    for (rdd, ext, filename) in rdds\n",
    "]\n",
    "\n",
    "for fname, header in headers.items():\n",
    "    print(\"Header for\", fname, \"=\", header)\n",
    "    \n",
    "for (rdd, ext, filename) in rdds:\n",
    "    print(rdd.take(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.4 Drop records with invalid information: purpose_id or council_id is null, empty, or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/council.json: type:<class 'pyspark.rdd.PipelinedRDD'>\n",
      "data/nsw_property_price.csv: type:<class 'pyspark.rdd.PipelinedRDD'>\n",
      "data/property_purpose.json: type:<class 'pyspark.rdd.PipelinedRDD'>\n",
      "data/zoning.json: type:<class 'pyspark.rdd.PipelinedRDD'>\n"
     ]
    }
   ],
   "source": [
    "for (rdd, ext, filename) in rdds:\n",
    "    print(f\"{filename}: type:{type(rdd)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/council.json: raw=220, filtered=220\n",
      "data/nsw_property_price.csv: raw=4854814, filtered=4729218\n",
      "data/property_purpose.json: raw=865, filtered=865\n",
      "data/zoning.json: raw=71, filtered=71\n"
     ]
    }
   ],
   "source": [
    "def valid_record(rec):\n",
    "    for k, v in rec.items():\n",
    "        if k.endswith(\"_id\"):\n",
    "            try:\n",
    "                if int(v) < 1:  # must be integer-parsable and > 0\n",
    "                    return False\n",
    "            except (ValueError, TypeError):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def filter_rdd(rdd, ext, filename):\n",
    "    filtered = rdd.filter(valid_record)\n",
    "\n",
    "    print(f\"{filename}: raw={rdd.count()}, filtered={filtered.count()}\")\n",
    "    return filtered\n",
    "\n",
    "# Apply filtering\n",
    "rdds = [\n",
    "    (filter_rdd(rdd, ext, filename), ext, filename)\n",
    "    for (rdd, ext, filename) in rdds\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Partitioning in RDD <a class=\"anchor\" name=\"1.2\"></a>\n",
    "1.2.1 For each RDD, using Spark’s default partitioning, print out the total number of partitions and the number of records in each partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default partitions:  2\n",
      "Default partitions:  19\n",
      "Default partitions:  2\n",
      "Default partitions:  2\n"
     ]
    }
   ],
   "source": [
    "for rdd, ext, filename in rdds:\n",
    "    print('Default partitions: ',rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.2 Answer the following questions:   \n",
    "a) How many partitions do the above RDDs have?  \n",
    "b) How is the data in these RDDs partitioned by default, when we do not explicitly specify any partitioning strategy? Can you explain why it is partitioned in this number?   \n",
    "c) Assuming we are querying the dataset based on <strong> Property Price</strong>, can you think of a better strategy for partitioning the data based on your available hardware resources?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer for a)  \n",
    "The csv file has 19 partitions, while all of the json files have 2 partitions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer for b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer for c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.3 Create a user-defined function (UDF) to transform the date strings from ISO format (YYYY-MM-DD) (e.g. 2025-01-01) to Australian format (DD/Mon/YYYY) (e.g. 01/Jan/2025), then call the UDF to transform two date columns (iso_contract_date and iso_settlement_date) to contract_date and settlement_date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated header for data/nsw_property_price.csv = ['property_id', 'purchase_price', 'address', 'post_code', 'property_type', 'strata_lot_number', 'property_name', 'area', 'area_type', 'contract_date', 'settlement_date', 'nature_of_property', 'legal_description', 'id', 'council_id', 'purpose_id', 'zone_id']\n",
      "Example row as dict: {'property_id': '4270509', 'purchase_price': '1400000.00', 'address': '8 C NYARI RD, KENTHURST', 'post_code': '2156', 'property_type': 'house', 'strata_lot_number': '', 'property_name': '', 'area': '2.044', 'area_type': 'H', 'contract_date': '14/Dec/2023', 'settlement_date': '14/Feb/2024', 'nature_of_property': 'V', 'legal_description': '2/1229857', 'id': '142', 'council_id': '200', 'purpose_id': '9922', 'zone_id': '53'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to parse a CSV line safely, respecting quotes\n",
    "def parse_csv_line(line: str):\n",
    "    reader = csv.reader(StringIO(line), quotechar='\"', delimiter=',')\n",
    "    return next(reader)\n",
    "\n",
    "# ISO -> AUS conversion\n",
    "def iso_to_aus(iso_date: str) -> str:\n",
    "    try:\n",
    "        dt = datetime.strptime(iso_date, \"%Y-%m-%d\")\n",
    "        return dt.strftime(\"%d/%b/%Y\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "for fname, header in headers.items():\n",
    "    if fname != \"data/nsw_property_price.csv\":\n",
    "        continue\n",
    "    # Parse header using the same csv.reader\n",
    "    columns = parse_csv_line(header)\n",
    "\n",
    "    # Build column index lookup\n",
    "    col_index = {col: idx for idx, col in enumerate(columns)}\n",
    "\n",
    "    # Replace header names\n",
    "    columns[col_index[\"iso_contract_date\"]] = \"contract_date\"\n",
    "    columns[col_index[\"iso_settlement_date\"]] = \"settlement_date\"\n",
    "\n",
    "    # Load CSV RDD\n",
    "    rdd = sc.textFile(fname)\n",
    "\n",
    "    # Remove header row\n",
    "    data_rdd = rdd.filter(lambda line: line != header)\n",
    "\n",
    "    # Parse rows safely with csv.reader\n",
    "    parsed_rdd = data_rdd.map(parse_csv_line)\n",
    "\n",
    "    # Replace ISO dates with AUS format\n",
    "    transformed_rdd = parsed_rdd.map(\n",
    "        lambda row: [\n",
    "            iso_to_aus(row[col_index[\"iso_contract_date\"]]) if i == col_index[\"iso_contract_date\"]\n",
    "            else iso_to_aus(row[col_index[\"iso_settlement_date\"]]) if i == col_index[\"iso_settlement_date\"]\n",
    "            else val\n",
    "            for i, val in enumerate(row)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Zip headers with row -> dict\n",
    "    dict_rdd = transformed_rdd.map(lambda row: dict(zip(columns, row)))\n",
    "\n",
    "    # Example output\n",
    "    print(\"Updated header for\", fname, \"=\", columns)\n",
    "    print(\"Example row as dict:\", dict_rdd.first())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Query/Analysis <a class=\"anchor\" name=\"1.3\"></a>\n",
    "For this part, write relevant RDD operations to answer the following queries.\n",
    "\n",
    "1.3.1 Extract the Month (Jan-Dec) information and print the total number of sales by contract date for each Month. (5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[73] at RDD at PythonRDD.scala:53\n"
     ]
    }
   ],
   "source": [
    "print(dict_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nov-1000 = 0.0\n",
      "Jan-1012 = 1900000.0\n",
      "Jul-1016 = 333500.0\n",
      "Oct-1016 = 225000.0\n",
      "Apr-1017 = 526400.0\n",
      "Feb-1018 = 405000.0\n",
      "Oct-1018 = 1820000.0\n",
      "Dec-1018 = 270000.0\n",
      "Feb-1019 = 630000.0\n",
      "Jun-1019 = 2250000.0\n",
      "Jul-1019 = 989000.0\n",
      "Aug-1020 = 1225000.0\n",
      "Oct-1020 = 702000.0\n",
      "Feb-1021 = 359000.0\n",
      "May-1021 = 3340000.0\n",
      "Oct-1021 = 682000.0\n",
      "Nov-1021 = 1598000.0\n",
      "Feb-1022 = 4000000.0\n",
      "May-1022 = 6440000.0\n",
      "Jun-1022 = 650000.0\n",
      "Oct-1022 = 1240000.0\n",
      "Nov-1022 = 280000.0\n",
      "Dec-1022 = 520000.0\n",
      "Apr-1023 = 1225000.0\n",
      "May-1023 = 1135000.0\n",
      "Aug-1023 = 2804000.0\n",
      "Sep-1023 = 1030000.0\n",
      "Nov-1023 = 1233000.0\n",
      "Jan-1024 = 1316000.0\n",
      "Mar-1028 = 230000.0\n",
      "Oct-1029 = 450000.0\n",
      "Feb-1877 = 23000.0\n",
      "Jan-1900 = 350000.0\n",
      "Jan-1901 = 350000.0\n",
      "Oct-1903 = 202.0\n",
      "Dec-1903 = 137000.0\n",
      "Jan-1908 = 305000.0\n",
      "Nov-1909 = 292000.0\n",
      "Jan-1910 = 514000.0\n",
      "Mar-1910 = 860000.0\n",
      "May-1910 = 215000.0\n",
      "Jul-1910 = 390000.0\n",
      "Sep-1910 = 2226000.0\n",
      "Jan-1911 = 6000.0\n",
      "Feb-1911 = 710500.0\n",
      "Apr-1911 = 1552500.0\n",
      "Jun-1911 = 449000.0\n",
      "Jul-1911 = 875000.0\n",
      "Aug-1911 = 700000.0\n",
      "Sep-1911 = 1504000.0\n",
      "Oct-1911 = 520000.0\n",
      "Nov-1911 = 1100000.0\n",
      "Feb-1912 = 3172500.0\n",
      "Apr-1912 = 1476500.0\n",
      "Jul-1912 = 1800000.0\n",
      "Aug-1912 = 1340000.0\n",
      "Nov-1912 = 520000.0\n",
      "Dec-1912 = 1175000.0\n",
      "Feb-1913 = 892500.0\n",
      "Mar-1913 = 1248000.0\n",
      "Apr-1913 = 818000.0\n",
      "May-1913 = 2284250.0\n",
      "Jun-1913 = 1110000.0\n",
      "Jul-1913 = 760000.0\n",
      "Aug-1913 = 980000.0\n",
      "Sep-1913 = 1680000.0\n",
      "Nov-1913 = 1427000.0\n",
      "Dec-1913 = 1500000.0\n",
      "Jan-1914 = 797500.0\n",
      "Feb-1914 = 1364000.0\n",
      "Mar-1914 = 545950.0\n",
      "Apr-1914 = 775000.0\n",
      "May-1914 = 1775000.0\n",
      "Jun-1914 = 2365000.0\n",
      "Jul-1914 = 2427500.0\n",
      "Aug-1914 = 359000.0\n",
      "Sep-1914 = 861250.0\n",
      "Nov-1914 = 230000.0\n",
      "Dec-1914 = 2440000.0\n",
      "Jan-1915 = 680000.0\n",
      "Feb-1915 = 260000.0\n",
      "Mar-1915 = 1120000.0\n",
      "Apr-1915 = 1592500.0\n",
      "May-1915 = 325000.0\n",
      "Jun-1915 = 959900.0\n",
      "Jul-1915 = 550000.0\n",
      "Oct-1915 = 1032500.0\n",
      "Nov-1915 = 3090000.0\n",
      "Dec-1915 = 1709500.0\n",
      "Jan-1916 = 1175000.0\n",
      "Feb-1916 = 2392000.0\n",
      "Mar-1916 = 445000.0\n",
      "Apr-1916 = 2300000.0\n",
      "Aug-1916 = 650000.0\n",
      "Mar-1917 = 839700.0\n",
      "Jun-1917 = 3159500.0\n",
      "Sep-1917 = 525900.0\n",
      "Feb-1918 = 1075000.0\n",
      "May-1918 = 600000.0\n",
      "Jun-1918 = 717750.0\n",
      "Aug-1918 = 670000.0\n",
      "Nov-1919 = 2485000.0\n",
      "Jan-1920 = 400000.0\n",
      "Mar-1920 = 149000.0\n",
      "May-1920 = 1300790.0\n",
      "Jun-1920 = 540000.0\n",
      "Aug-1920 = 660000.0\n",
      "Dec-1920 = 872000.0\n",
      "Jan-1921 = 1420000.0\n",
      "Feb-1921 = 1250000.0\n",
      "Mar-1921 = 2794500.0\n",
      "Apr-1921 = 420000.0\n",
      "May-1921 = 835000.0\n",
      "Jun-1921 = 3240000.0\n",
      "Jul-1921 = 1494500.0\n",
      "Aug-1921 = 1209000.0\n",
      "Sep-1921 = 665500.0\n",
      "Nov-1921 = 849000.0\n",
      "Dec-1921 = 1631000.0\n",
      "Feb-1922 = 2903000.0\n",
      "Mar-1922 = 1575000.0\n",
      "May-1922 = 1200000.0\n",
      "Jul-1922 = 635000.0\n",
      "Oct-1922 = 2245000.0\n",
      "Jan-1923 = 70000.0\n",
      "Apr-1923 = 870000.0\n",
      "Jun-1923 = 910000.0\n",
      "Sep-1923 = 2730000.0\n",
      "Mar-1928 = 2500.0\n",
      "Jun-1929 = 260600.0\n",
      "Sep-1929 = 3500000.0\n",
      "Apr-1944 = 350000.0\n",
      "Jan-1949 = 400.0\n",
      "May-1949 = 1520000.0\n",
      "Dec-1949 = 800.0\n",
      "Apr-1950 = 340000.0\n",
      "Jun-1950 = 292500.0\n",
      "Jul-1950 = 330000.0\n",
      "Aug-1950 = 2454000.0\n",
      "Sep-1950 = 550000.0\n",
      "Jan-1951 = 60000.0\n",
      "Mar-1951 = 654500.0\n",
      "May-1951 = 1051500.0\n",
      "Jul-1951 = 418000.0\n",
      "Aug-1951 = 525000.0\n",
      "Sep-1951 = 714000.0\n",
      "Nov-1951 = 250000.0\n",
      "Mar-1952 = 655000.0\n",
      "Apr-1952 = 235000.0\n",
      "May-1952 = 2160000.0\n",
      "Nov-1952 = 235000.0\n",
      "Jan-1953 = 6130.0\n",
      "Mar-1953 = 4050.0\n",
      "Apr-1953 = 60000.0\n",
      "Jun-1953 = 275000.0\n",
      "Nov-1953 = 5838.0\n",
      "Feb-1954 = 925000.0\n",
      "May-1954 = 239000.0\n",
      "Jun-1954 = 51000.0\n",
      "Aug-1954 = 257000.0\n",
      "Oct-1954 = 3200.0\n",
      "Nov-1954 = 0.0\n",
      "Jan-1955 = 45000.0\n",
      "Feb-1955 = 520000.0\n",
      "Apr-1955 = 190000.0\n",
      "May-1955 = 1211760.0\n",
      "Jun-1955 = 6054.0\n",
      "Jul-1955 = 566356.0\n",
      "Sep-1955 = 835510.0\n",
      "Dec-1955 = 1212500.0\n",
      "Jan-1956 = 6600.0\n",
      "Feb-1956 = 400000.0\n",
      "May-1956 = 230000.0\n",
      "Jun-1956 = 365000.0\n",
      "Jul-1956 = 15182.0\n",
      "Aug-1956 = 432500.0\n",
      "Sep-1956 = 3080.0\n",
      "Oct-1956 = 13010.0\n",
      "Dec-1956 = 19242.0\n",
      "Jan-1957 = 685360.0\n",
      "Feb-1957 = 242530.0\n",
      "Mar-1957 = 77800.0\n",
      "Apr-1957 = 11640.0\n",
      "May-1957 = 40010.0\n",
      "Jun-1957 = 20840.0\n",
      "Jul-1957 = 22593.0\n",
      "Aug-1957 = 14885.0\n",
      "Sep-1957 = 24140.0\n",
      "Oct-1957 = 46480.0\n",
      "Nov-1957 = 28930.0\n",
      "Dec-1957 = 38984.0\n",
      "Jan-1958 = 25330.0\n",
      "Feb-1958 = 727580.0\n",
      "Mar-1958 = 1075800.0\n",
      "Apr-1958 = 1482426.0\n",
      "May-1958 = 1057428.0\n",
      "Jun-1958 = 23950.0\n",
      "Jul-1958 = 7010.0\n",
      "Aug-1958 = 500574.0\n",
      "Sep-1958 = 11750.0\n",
      "Oct-1958 = 28584.0\n",
      "Nov-1958 = 25026.0\n",
      "Dec-1958 = 2642882.0\n",
      "Jan-1959 = 5130.0\n",
      "Feb-1959 = 11302.0\n",
      "Mar-1959 = 10480.0\n",
      "Apr-1959 = 16730.0\n",
      "May-1959 = 43254.0\n",
      "Jun-1959 = 704552.0\n",
      "Jul-1959 = 47922.0\n",
      "Aug-1959 = 59990.0\n",
      "Sep-1959 = 22098.0\n",
      "Oct-1959 = 12250.0\n",
      "Nov-1959 = 49922.0\n",
      "Dec-1959 = 25770.0\n",
      "Jan-1960 = 47846.0\n",
      "Feb-1960 = 289316.0\n",
      "Mar-1960 = 78440.0\n",
      "Apr-1960 = 13242.0\n",
      "May-1960 = 25400.0\n",
      "Jun-1960 = 66515.0\n",
      "Jul-1960 = 638580.0\n",
      "Aug-1960 = 14430.0\n",
      "Sep-1960 = 50878.0\n",
      "Oct-1960 = 5950.0\n",
      "Nov-1960 = 49360.0\n",
      "Dec-1960 = 15791.0\n",
      "Jan-1961 = 7470.0\n",
      "Feb-1961 = 7220.0\n",
      "Mar-1961 = 2620828.0\n",
      "Apr-1961 = 56334.0\n",
      "May-1961 = 952474.0\n",
      "Jun-1961 = 1131600.0\n",
      "Jul-1961 = 19920.0\n",
      "Aug-1961 = 21420.0\n",
      "Sep-1961 = 25882.0\n",
      "Oct-1961 = 94950.0\n",
      "Nov-1961 = 358580.0\n",
      "Dec-1961 = 69564.0\n",
      "Jan-1962 = 751330.0\n",
      "Feb-1962 = 297420.0\n",
      "Mar-1962 = 962630.0\n",
      "Apr-1962 = 45005.0\n",
      "May-1962 = 35280.0\n",
      "Jun-1962 = 1409270.0\n",
      "Jul-1962 = 46210.0\n",
      "Aug-1962 = 666910.0\n",
      "Sep-1962 = 49090.0\n",
      "Oct-1962 = 2088400.0\n",
      "Nov-1962 = 807674.0\n",
      "Dec-1962 = 280188.0\n",
      "Jan-1963 = 302890.0\n",
      "Feb-1963 = 571737.0\n",
      "Mar-1963 = 51360.0\n",
      "Apr-1963 = 31510.0\n",
      "May-1963 = 56522.0\n",
      "Jun-1963 = 694930.0\n",
      "Jul-1963 = 65740.0\n",
      "Aug-1963 = 3558378.0\n",
      "Sep-1963 = 4057660.0\n",
      "Oct-1963 = 42710.0\n",
      "Nov-1963 = 69830.0\n",
      "Dec-1963 = 742876.0\n",
      "Jan-1964 = 26360.0\n",
      "Feb-1964 = 55575.0\n",
      "Mar-1964 = 573448.0\n",
      "Apr-1964 = 899150.0\n",
      "May-1964 = 268640.0\n",
      "Jun-1964 = 45470.0\n",
      "Jul-1964 = 123100.0\n",
      "Aug-1964 = 52890.0\n",
      "Sep-1964 = 67950.0\n",
      "Oct-1964 = 69540.0\n",
      "Nov-1964 = 56456.0\n",
      "Dec-1964 = 1609310.0\n",
      "Jan-1965 = 31330.0\n",
      "Feb-1965 = 98560.0\n",
      "Mar-1965 = 70689.0\n",
      "Apr-1965 = 388690.0\n",
      "May-1965 = 636252.0\n",
      "Jun-1965 = 1640918.0\n",
      "Jul-1965 = 290780.0\n",
      "Aug-1965 = 47060.0\n",
      "Sep-1965 = 2265408.0\n",
      "Oct-1965 = 43700.0\n",
      "Nov-1965 = 882360.0\n",
      "Dec-1965 = 1095890.0\n",
      "Jan-1966 = 61680.0\n",
      "Feb-1966 = 763388.0\n",
      "Mar-1966 = 604496.0\n",
      "Apr-1966 = 3273438.0\n",
      "May-1966 = 67370.0\n",
      "Jun-1966 = 41790.0\n",
      "Jul-1966 = 1232310.0\n",
      "Aug-1966 = 415435.0\n",
      "Sep-1966 = 24350.0\n",
      "Oct-1966 = 55385.0\n",
      "Nov-1966 = 44870.0\n",
      "Dec-1966 = 143300.0\n",
      "Jan-1967 = 16400.0\n",
      "Feb-1967 = 38670.0\n",
      "Mar-1967 = 49850.0\n",
      "Apr-1967 = 1453790.0\n",
      "May-1967 = 3582020.0\n",
      "Jun-1967 = 1301450.0\n",
      "Jul-1967 = 199060.0\n",
      "Aug-1967 = 59232.0\n",
      "Sep-1967 = 113800.0\n",
      "Oct-1967 = 80930.0\n",
      "Nov-1967 = 211560.0\n",
      "Dec-1967 = 35530.0\n",
      "Jan-1968 = 36260.0\n",
      "Feb-1968 = 80915.0\n",
      "Mar-1968 = 51820.0\n",
      "Apr-1968 = 180270.0\n",
      "May-1968 = 45420.0\n",
      "Jun-1968 = 20505.0\n",
      "Jul-1968 = 1672315.0\n",
      "Aug-1968 = 52475.0\n",
      "Sep-1968 = 137344.0\n",
      "Oct-1968 = 38780.0\n",
      "Nov-1968 = 339130.0\n",
      "Dec-1968 = 54070.0\n",
      "Jan-1969 = 34710.0\n",
      "Feb-1969 = 76940.0\n",
      "Mar-1969 = 81690.0\n",
      "Apr-1969 = 29000.0\n",
      "May-1969 = 68155.0\n",
      "Jun-1969 = 805360.0\n",
      "Jul-1969 = 97230.0\n",
      "Aug-1969 = 74910.0\n",
      "Sep-1969 = 400170.0\n",
      "Oct-1969 = 114090.0\n",
      "Nov-1969 = 105820.0\n",
      "Dec-1969 = 166090.0\n",
      "Jan-1970 = 97180.0\n",
      "Feb-1970 = 32440.0\n",
      "Mar-1970 = 129400.0\n",
      "Apr-1970 = 52610.0\n",
      "May-1970 = 728830.0\n",
      "Jun-1970 = 424130.0\n",
      "Jul-1970 = 116370.0\n",
      "Aug-1970 = 720365.0\n",
      "Sep-1970 = 42470.0\n",
      "Oct-1970 = 4044870.0\n",
      "Nov-1970 = 1132830.0\n",
      "Dec-1970 = 117455.0\n",
      "Jan-1971 = 77910.0\n",
      "Feb-1971 = 86335.0\n",
      "Mar-1971 = 100805.0\n",
      "Apr-1971 = 131347.0\n",
      "May-1971 = 2919420.0\n",
      "Jun-1971 = 120845.0\n",
      "Jul-1971 = 223345.0\n",
      "Aug-1971 = 1061700.0\n",
      "Sep-1971 = 133320.0\n",
      "Oct-1971 = 1258730.0\n",
      "Nov-1971 = 97220.0\n",
      "Dec-1971 = 125485.0\n",
      "Jan-1972 = 152315.0\n",
      "Feb-1972 = 365402.0\n",
      "Mar-1972 = 39190.0\n",
      "Apr-1972 = 125580.0\n",
      "May-1972 = 241090.0\n",
      "Jun-1972 = 716920.0\n",
      "Jul-1972 = 189956.0\n",
      "Aug-1972 = 677050.0\n",
      "Sep-1972 = 112740.0\n",
      "Oct-1972 = 818660.0\n",
      "Nov-1972 = 905990.0\n",
      "Dec-1972 = 260090.0\n",
      "Jan-1973 = 56544.0\n",
      "Feb-1973 = 14375.0\n",
      "Mar-1973 = 599550.0\n",
      "Apr-1973 = 286230.0\n",
      "May-1973 = 115900.0\n",
      "Jun-1973 = 56955.0\n",
      "Jul-1973 = 132070.0\n",
      "Aug-1973 = 1311300.0\n",
      "Sep-1973 = 887878.0\n",
      "Oct-1973 = 58700.0\n",
      "Nov-1973 = 36375.0\n",
      "Dec-1973 = 78050.0\n",
      "Jan-1974 = 11280.0\n",
      "Feb-1974 = 3434150.0\n",
      "Mar-1974 = 97690.0\n",
      "Apr-1974 = 54250.0\n",
      "May-1974 = 73550.0\n",
      "Jun-1974 = 121985.0\n",
      "Jul-1974 = 48206.0\n",
      "Aug-1974 = 928960.0\n",
      "Sep-1974 = 110050.0\n",
      "Oct-1974 = 83825.0\n",
      "Nov-1974 = 299125.0\n",
      "Dec-1974 = 228540.0\n",
      "Jan-1975 = 191775.0\n",
      "Feb-1975 = 252940.0\n",
      "Mar-1975 = 51700.0\n",
      "Apr-1975 = 341100.0\n",
      "May-1975 = 547550.0\n",
      "Jun-1975 = 351580.0\n",
      "Jul-1975 = 266545.0\n",
      "Aug-1975 = 237675.0\n",
      "Sep-1975 = 260170.0\n",
      "Oct-1975 = 749843.0\n",
      "Nov-1975 = 203900.0\n",
      "Dec-1975 = 95801.0\n",
      "Jan-1976 = 138960.0\n",
      "Feb-1976 = 152945.0\n",
      "Mar-1976 = 3115085.0\n",
      "Apr-1976 = 344720.0\n",
      "May-1976 = 728150.0\n",
      "Jun-1976 = 364410.0\n",
      "Jul-1976 = 438210.0\n",
      "Aug-1976 = 198750.0\n",
      "Sep-1976 = 251564.0\n",
      "Oct-1976 = 297900.0\n",
      "Nov-1976 = 470600.0\n",
      "Dec-1976 = 2004150.0\n",
      "Jan-1977 = 45000.0\n",
      "Feb-1977 = 274550.0\n",
      "Mar-1977 = 2714850.0\n",
      "Apr-1977 = 37000.0\n",
      "May-1977 = 30572.0\n",
      "Jun-1977 = 29250.0\n",
      "Jul-1977 = 479285.0\n",
      "Sep-1977 = 92480.0\n",
      "Nov-1977 = 48700.0\n",
      "Dec-1977 = 58000.0\n",
      "Jan-1978 = 815000.0\n",
      "Mar-1978 = 3810.0\n",
      "May-1978 = 455500.0\n",
      "Jun-1978 = 917500.0\n",
      "Jul-1978 = 100500.0\n",
      "Sep-1978 = 15000.0\n",
      "Oct-1978 = 10005.0\n",
      "Nov-1978 = 38250.0\n",
      "Dec-1978 = 7200.0\n",
      "Jan-1979 = 663050.0\n",
      "Feb-1979 = 475000.0\n",
      "Mar-1979 = 9000.0\n",
      "Apr-1979 = 371406.0\n",
      "May-1979 = 592500.0\n",
      "Jul-1979 = 15400.0\n",
      "Sep-1979 = 18500.0\n",
      "Oct-1979 = 521250.0\n",
      "Nov-1979 = 468800.0\n",
      "Dec-1979 = 130000.0\n",
      "Feb-1980 = 424000.0\n",
      "Mar-1980 = 913000.0\n",
      "Apr-1980 = 230.0\n",
      "May-1980 = 864008.0\n",
      "Jun-1980 = 4180000.0\n",
      "Jul-1980 = 10000.0\n",
      "Aug-1980 = 31000.0\n",
      "Sep-1980 = 215000.0\n",
      "Oct-1980 = 70600.0\n",
      "Nov-1980 = 720000.0\n",
      "Dec-1980 = 397500.0\n",
      "Feb-1981 = 0.0\n",
      "Mar-1981 = 81500.0\n",
      "May-1981 = 0.0\n",
      "Jun-1981 = 145500.0\n",
      "Jul-1981 = 42000.0\n",
      "Aug-1981 = 40000.0\n",
      "Sep-1981 = 85200.0\n",
      "Oct-1981 = 1365000.0\n",
      "Nov-1981 = 71910.0\n",
      "Jan-1982 = 164000.0\n",
      "Feb-1982 = 135.0\n",
      "Mar-1982 = 597000.0\n",
      "May-1982 = 6310.0\n",
      "Jun-1982 = 119700.0\n",
      "Jul-1982 = 914620.0\n",
      "Aug-1982 = 127933.0\n",
      "Sep-1982 = 246500.0\n",
      "Oct-1982 = 1235460.0\n",
      "Nov-1982 = 20000.0\n",
      "Dec-1982 = 842150.0\n",
      "Feb-1983 = 181000.0\n",
      "Mar-1983 = 16950.0\n",
      "Apr-1983 = 0.0\n",
      "May-1983 = 40000.0\n",
      "Jun-1983 = 149600.0\n",
      "Jul-1983 = 960000.0\n",
      "Sep-1983 = 108526.0\n",
      "Oct-1983 = 73000.0\n",
      "Nov-1983 = 1532750.0\n",
      "Dec-1983 = 91000.0\n",
      "Jan-1984 = 330000.0\n",
      "Feb-1984 = 151040.0\n",
      "Mar-1984 = 153730.0\n",
      "Apr-1984 = 146000.0\n",
      "Jun-1984 = 188990.0\n",
      "Jul-1984 = 75754.0\n",
      "Aug-1984 = 64934.0\n",
      "Sep-1984 = 123950.0\n",
      "Oct-1984 = 48000.0\n",
      "Nov-1984 = 634000.0\n",
      "Dec-1984 = 1158900.0\n",
      "Jan-1985 = 142500.0\n",
      "Feb-1985 = 1035980.0\n",
      "Mar-1985 = 111250.0\n",
      "Apr-1985 = 611710.0\n",
      "May-1985 = 260000.0\n",
      "Jun-1985 = 664170.0\n",
      "Jul-1985 = 168000.0\n",
      "Aug-1985 = 457850.0\n",
      "Sep-1985 = 6213025.0\n",
      "Oct-1985 = 12410.0\n",
      "Nov-1985 = 405425.0\n",
      "Dec-1985 = 569600.0\n",
      "Jan-1986 = 325000.0\n",
      "Feb-1986 = 494400.0\n",
      "Mar-1986 = 4400.0\n",
      "Apr-1986 = 297410.0\n",
      "May-1986 = 116770.0\n",
      "Jun-1986 = 196935.0\n",
      "Aug-1986 = 718000.0\n",
      "Sep-1986 = 448856.0\n",
      "Oct-1986 = 61750.0\n",
      "Nov-1986 = 587334.0\n",
      "Jan-1987 = 112000.0\n",
      "Feb-1987 = 881460.0\n",
      "Mar-1987 = 147000.0\n",
      "Apr-1987 = 239000.0\n",
      "May-1987 = 1041475.0\n",
      "Jun-1987 = 289349.0\n",
      "Jul-1987 = 429732.0\n",
      "Aug-1987 = 454312.0\n",
      "Sep-1987 = 156940.0\n",
      "Oct-1987 = 373000.0\n",
      "Nov-1987 = 419610.0\n",
      "Dec-1987 = 148830.0\n",
      "Jan-1988 = 163000.0\n",
      "Feb-1988 = 329550.0\n",
      "Mar-1988 = 25660.0\n",
      "Apr-1988 = 68500.0\n",
      "May-1988 = 2293310.0\n",
      "Jun-1988 = 1013000.0\n",
      "Jul-1988 = 224154.0\n",
      "Aug-1988 = 169000.0\n",
      "Sep-1988 = 1958178.0\n",
      "Oct-1988 = 273100.0\n",
      "Nov-1988 = 1753000.0\n",
      "Dec-1988 = 505530.0\n",
      "Jan-1989 = 388000.0\n",
      "Feb-1989 = 100800.0\n",
      "Mar-1989 = 560528.0\n",
      "Apr-1989 = 869440.0\n",
      "May-1989 = 342800.0\n",
      "Jun-1989 = 992450.0\n",
      "Jul-1989 = 1301994.0\n",
      "Aug-1989 = 233940.0\n",
      "Sep-1989 = 269950.0\n",
      "Oct-1989 = 706000.0\n",
      "Dec-1989 = 317280.0\n",
      "Jan-1990 = 7241430.0\n",
      "Feb-1990 = 804512.0\n",
      "Mar-1990 = 611950.0\n",
      "Apr-1990 = 750350.0\n",
      "May-1990 = 1341300.0\n",
      "Jun-1990 = 3370666.0\n",
      "Jul-1990 = 362458.0\n",
      "Aug-1990 = 1590000.0\n",
      "Sep-1990 = 2749500.0\n",
      "Oct-1990 = 1090000.0\n",
      "Nov-1990 = 775590.0\n",
      "Dec-1990 = 942150.0\n",
      "Jan-1991 = 320000.0\n",
      "Feb-1991 = 1109567.0\n",
      "Mar-1991 = 5206427.0\n",
      "Apr-1991 = 1053078.0\n",
      "May-1991 = 1400912.0\n",
      "Jun-1991 = 157600.0\n",
      "Jul-1991 = 755100.0\n",
      "Aug-1991 = 2292400.0\n",
      "Sep-1991 = 1478700.0\n",
      "Oct-1991 = 662900.0\n",
      "Nov-1991 = 921556.0\n",
      "Dec-1991 = 861253.0\n",
      "Jan-1992 = 1206914.0\n",
      "Feb-1992 = 1381000.0\n",
      "Mar-1992 = 441500.0\n",
      "Apr-1992 = 1273600.0\n",
      "May-1992 = 5007293.0\n",
      "Jun-1992 = 2472336.0\n",
      "Jul-1992 = 384000.0\n",
      "Aug-1992 = 1771920.0\n",
      "Sep-1992 = 5242517.0\n",
      "Oct-1992 = 4204849.0\n",
      "Nov-1992 = 2782639.0\n",
      "Dec-1992 = 1796000.0\n",
      "Jan-1993 = 132000.0\n",
      "Feb-1993 = 1735026.0\n",
      "Mar-1993 = 4787500.0\n",
      "Apr-1993 = 2713635.0\n",
      "May-1993 = 6017620.0\n",
      "Jun-1993 = 2141269.0\n",
      "Jul-1993 = 3385643.0\n",
      "Aug-1993 = 3830309.0\n",
      "Sep-1993 = 3604668.0\n",
      "Oct-1993 = 1602800.0\n",
      "Nov-1993 = 58905811.0\n",
      "Dec-1993 = 1737500.0\n",
      "Jan-1994 = 1317900.0\n",
      "Feb-1994 = 2272600.0\n",
      "Mar-1994 = 4895100.0\n",
      "Apr-1994 = 3903500.0\n",
      "May-1994 = 9292500.0\n",
      "Jun-1994 = 6721340.0\n",
      "Jul-1994 = 5612370.0\n",
      "Aug-1994 = 1719365.0\n",
      "Sep-1994 = 5241800.0\n",
      "Oct-1994 = 2335784.0\n",
      "Nov-1994 = 6977550.0\n",
      "Dec-1994 = 11963950.0\n",
      "Jan-1995 = 1024315.0\n",
      "Feb-1995 = 3544550.0\n",
      "Mar-1995 = 9374497.0\n",
      "Apr-1995 = 6141500.0\n",
      "May-1995 = 4100454.0\n",
      "Jun-1995 = 6913850.0\n",
      "Jul-1995 = 6153100.0\n",
      "Aug-1995 = 12221731.0\n",
      "Sep-1995 = 8203605.0\n",
      "Oct-1995 = 6246849.0\n",
      "Nov-1995 = 29000842.0\n",
      "Dec-1995 = 51286738.0\n",
      "Jan-1996 = 6230500.0\n",
      "Feb-1996 = 17695900.0\n",
      "Mar-1996 = 6329983.0\n",
      "Apr-1996 = 73221500.0\n",
      "May-1996 = 5285300.0\n",
      "Jun-1996 = 8603105.0\n",
      "Jul-1996 = 7758965.0\n",
      "Aug-1996 = 5587450.0\n",
      "Sep-1996 = 12701521.0\n",
      "Oct-1996 = 6997730.0\n",
      "Nov-1996 = 6666373.0\n",
      "Dec-1996 = 10648632.0\n",
      "Jan-1997 = 9616400.0\n",
      "Feb-1997 = 16413617.0\n",
      "Mar-1997 = 15162346.0\n",
      "Apr-1997 = 13395614.0\n",
      "May-1997 = 30620266.0\n",
      "Jun-1997 = 29197234.0\n",
      "Jul-1997 = 15479612.0\n",
      "Aug-1997 = 21367067.0\n",
      "Sep-1997 = 20288634.0\n",
      "Oct-1997 = 92176322.0\n",
      "Nov-1997 = 25936058.0\n",
      "Dec-1997 = 38941296.0\n",
      "Jan-1998 = 9924860.0\n",
      "Feb-1998 = 15725986.0\n",
      "Mar-1998 = 47521454.0\n",
      "Apr-1998 = 52817700.0\n",
      "May-1998 = 27042087.0\n",
      "Jun-1998 = 99974850.0\n",
      "Jul-1998 = 59906709.0\n",
      "Aug-1998 = 25451021.0\n",
      "Sep-1998 = 439075022.0\n",
      "Oct-1998 = 468431416.0\n",
      "Nov-1998 = 65049373.0\n",
      "Dec-1998 = 94061267.0\n",
      "Jan-1999 = 34860973.0\n",
      "Feb-1999 = 69960898.0\n",
      "Mar-1999 = 102775480.0\n",
      "Apr-1999 = 74089580.0\n",
      "May-1999 = 285670647.0\n",
      "Jun-1999 = 325256435.0\n",
      "Jul-1999 = 249742622.0\n",
      "Aug-1999 = 278142996.0\n",
      "Sep-1999 = 218559400.0\n",
      "Oct-1999 = 750045692.0\n",
      "Nov-1999 = 305728632.0\n",
      "Dec-1999 = 278952364.0\n",
      "Jan-2000 = 141111094.0\n",
      "Feb-2000 = 323952115.0\n",
      "Mar-2000 = 930477816.0\n",
      "Apr-2000 = 415885091.0\n",
      "May-2000 = 518318996.0\n",
      "Jun-2000 = 12652951262.0\n",
      "Jul-2000 = 519958473.0\n",
      "Aug-2000 = 548527016.0\n",
      "Sep-2000 = 564177512.0\n",
      "Oct-2000 = 784202708.0\n",
      "Nov-2000 = 1213922450.0\n",
      "Dec-2000 = 2176814889.0\n",
      "Jan-2001 = 2020424726.0\n",
      "Feb-2001 = 5739457024.0\n",
      "Mar-2001 = 7717122403.0\n",
      "Apr-2001 = 6294394516.0\n",
      "May-2001 = 8319658982.0\n",
      "Jun-2001 = 8625818231.0\n",
      "Jul-2001 = 8130159560.0\n",
      "Aug-2001 = 9333697535.0\n",
      "Sep-2001 = 9181059079.0\n",
      "Oct-2001 = 9796063517.0\n",
      "Nov-2001 = 10666707099.0\n",
      "Dec-2001 = 9309782079.0\n",
      "Jan-2002 = 5810185636.0\n",
      "Feb-2002 = 8155161080.0\n",
      "Mar-2002 = 15882701130.0\n",
      "Apr-2002 = 9118702013.0\n",
      "May-2002 = 21920876771.0\n",
      "Jun-2002 = 9554278050.0\n",
      "Jul-2002 = 9460806258.0\n",
      "Aug-2002 = 9344711743.0\n",
      "Sep-2002 = 15374752734.0\n",
      "Oct-2002 = 10333941872.0\n",
      "Nov-2002 = 9974438092.0\n",
      "Dec-2002 = 8563932075.0\n",
      "Jan-2003 = 5364256863.0\n",
      "Feb-2003 = 9163655626.0\n",
      "Mar-2003 = 9929448620.0\n",
      "Apr-2003 = 10467360856.0\n",
      "May-2003 = 11598305033.0\n",
      "Jun-2003 = 11300719625.0\n",
      "Jul-2003 = 11716290173.0\n",
      "Aug-2003 = 11123084105.0\n",
      "Sep-2003 = 11412241396.0\n",
      "Oct-2003 = 12214444863.0\n",
      "Nov-2003 = 9658840457.0\n",
      "Dec-2003 = 10637598182.0\n",
      "Jan-2004 = 4538723396.0\n",
      "Feb-2004 = 7787764748.0\n",
      "Mar-2004 = 11245891319.0\n",
      "Apr-2004 = 8873287257.0\n",
      "May-2004 = 16506410279.0\n",
      "Jun-2004 = 7149926863.0\n",
      "Jul-2004 = 7811256899.0\n",
      "Aug-2004 = 8741607874.0\n",
      "Sep-2004 = 8466536938.0\n",
      "Oct-2004 = 8100228100.0\n",
      "Nov-2004 = 9401756498.0\n",
      "Dec-2004 = 9885487786.0\n",
      "Jan-2005 = 4191390722.0\n",
      "Feb-2005 = 7196417637.0\n",
      "Mar-2005 = 8828065717.0\n",
      "Apr-2005 = 6765792799.0\n",
      "May-2005 = 8873961215.0\n",
      "Jun-2005 = 13748007334.0\n",
      "Jul-2005 = 8485102363.0\n",
      "Aug-2005 = 9137140485.0\n",
      "Sep-2005 = 8768315327.0\n",
      "Oct-2005 = 7909867976.0\n",
      "Nov-2005 = 8816774412.0\n",
      "Dec-2005 = 11955949478.0\n",
      "Jan-2006 = 4121954706.0\n",
      "Feb-2006 = 7976231618.0\n",
      "Mar-2006 = 10977205923.0\n",
      "Apr-2006 = 8066958628.0\n",
      "May-2006 = 11021615739.0\n",
      "Jun-2006 = 11527345510.0\n",
      "Jul-2006 = 8113891914.0\n",
      "Aug-2006 = 11019413229.0\n",
      "Sep-2006 = 9142309358.0\n",
      "Oct-2006 = 8182810750.0\n",
      "Nov-2006 = 13221378761.0\n",
      "Dec-2006 = 13770286422.0\n",
      "Jan-2007 = 5547689971.0\n",
      "Feb-2007 = 10021027919.0\n",
      "Mar-2007 = 13321371264.0\n",
      "Apr-2007 = 9786263601.0\n",
      "May-2007 = 14283186633.0\n",
      "Jun-2007 = 19666744434.0\n",
      "Jul-2007 = 12566342724.0\n",
      "Aug-2007 = 11951897417.0\n",
      "Sep-2007 = 10672275113.0\n",
      "Oct-2007 = 12802953038.0\n",
      "Nov-2007 = 13925348397.0\n",
      "Dec-2007 = 13536366476.0\n",
      "Jan-2008 = 6664656556.0\n",
      "Feb-2008 = 12321760518.0\n",
      "Mar-2008 = 10648548975.0\n",
      "Apr-2008 = 12424539123.0\n",
      "May-2008 = 10188494527.0\n",
      "Jun-2008 = 9215953753.0\n",
      "Jul-2008 = 7777330006.0\n",
      "Aug-2008 = 7057402043.0\n",
      "Sep-2008 = 7386371264.0\n",
      "Oct-2008 = 9275750894.0\n",
      "Nov-2008 = 6754925273.0\n",
      "Dec-2008 = 7592029615.0\n",
      "Jan-2009 = 4113130517.0\n",
      "Feb-2009 = 7456323126.0\n",
      "Mar-2009 = 9278450520.0\n",
      "Apr-2009 = 8705448355.0\n",
      "May-2009 = 9856325756.0\n",
      "Jun-2009 = 10651639172.0\n",
      "Jul-2009 = 20035767611.0\n",
      "Aug-2009 = 9924289562.0\n",
      "Sep-2009 = 12214317166.0\n",
      "Oct-2009 = 9519355670.0\n",
      "Nov-2009 = 10486860322.0\n",
      "Dec-2009 = 11199451813.0\n",
      "Jan-2010 = 4171455726.0\n",
      "Feb-2010 = 8727565067.0\n",
      "Mar-2010 = 11520931592.0\n",
      "Apr-2010 = 9351035015.0\n",
      "May-2010 = 17374104183.0\n",
      "Jun-2010 = 10570155357.0\n",
      "Jul-2010 = 10925922016.0\n",
      "Aug-2010 = 8703086528.0\n",
      "Sep-2010 = 9638586750.0\n",
      "Oct-2010 = 10643639472.0\n",
      "Nov-2010 = 16255276389.0\n",
      "Dec-2010 = 14735135669.0\n",
      "Jan-2011 = 4681492167.0\n",
      "Feb-2011 = 9288950190.0\n",
      "Mar-2011 = 17253553278.0\n",
      "Apr-2011 = 9410831860.0\n",
      "May-2011 = 9571368694.0\n",
      "Jun-2011 = 9654809961.0\n",
      "Jul-2011 = 11756114064.0\n",
      "Aug-2011 = 9210280805.0\n",
      "Sep-2011 = 9153913589.0\n",
      "Oct-2011 = 9085813685.0\n",
      "Nov-2011 = 11630949427.0\n",
      "Dec-2011 = 18458831631.0\n",
      "Jan-2012 = 4458925880.0\n",
      "Feb-2012 = 9776688704.0\n",
      "Mar-2012 = 10043640606.0\n",
      "Apr-2012 = 8027921857.0\n",
      "May-2012 = 11951074419.0\n",
      "Jun-2012 = 13047501285.0\n",
      "Jul-2012 = 9205755831.0\n",
      "Aug-2012 = 8993919844.0\n",
      "Sep-2012 = 9337912369.0\n",
      "Oct-2012 = 10737490568.0\n",
      "Nov-2012 = 11637729500.0\n",
      "Dec-2012 = 10769804969.0\n",
      "Jan-2013 = 5186574462.0\n",
      "Feb-2013 = 9339072453.0\n",
      "Mar-2013 = 12141650051.0\n",
      "Apr-2013 = 10488107224.0\n",
      "May-2013 = 14217318970.0\n",
      "Jun-2013 = 13784902071.0\n",
      "Jul-2013 = 11342594094.0\n",
      "Aug-2013 = 13514580097.0\n",
      "Sep-2013 = 13706013808.0\n",
      "Oct-2013 = 23290653443.0\n",
      "Nov-2013 = 22484147776.0\n",
      "Dec-2013 = 23190489463.0\n",
      "Jan-2014 = 8824614050.0\n",
      "Feb-2014 = 15420546478.0\n",
      "Mar-2014 = 17760790530.0\n",
      "Apr-2014 = 13955914277.0\n",
      "May-2014 = 16168429162.0\n",
      "Jun-2014 = 17217019813.0\n",
      "Jul-2014 = 17290846138.0\n",
      "Aug-2014 = 21808406502.0\n",
      "Sep-2014 = 20648248363.0\n",
      "Oct-2014 = 24385104651.0\n",
      "Nov-2014 = 21344809414.0\n",
      "Dec-2014 = 20009375371.0\n",
      "Jan-2015 = 10360882420.0\n",
      "Feb-2015 = 16480615788.0\n",
      "Mar-2015 = 23431538667.0\n",
      "Apr-2015 = 17547167653.0\n",
      "May-2015 = 24174087893.0\n",
      "Jun-2015 = 21609424728.0\n",
      "Jul-2015 = 25046746120.0\n",
      "Aug-2015 = 21386102073.0\n",
      "Sep-2015 = 20496722103.0\n",
      "Oct-2015 = 17686892107.0\n",
      "Nov-2015 = 18553872742.0\n",
      "Dec-2015 = 22631126111.0\n",
      "Jan-2016 = 9047246040.0\n",
      "Feb-2016 = 16343578759.0\n",
      "Mar-2016 = 18497339286.0\n",
      "Apr-2016 = 17213586511.0\n",
      "May-2016 = 18408779193.0\n",
      "Jun-2016 = 18310091468.0\n",
      "Jul-2016 = 28848541753.0\n",
      "Aug-2016 = 22361859182.0\n",
      "Sep-2016 = 24537924247.0\n",
      "Oct-2016 = 19638223427.0\n",
      "Nov-2016 = 25259678472.0\n",
      "Dec-2016 = 43183417332.0\n",
      "Jan-2017 = 7695225497.0\n",
      "Feb-2017 = 16621469558.0\n",
      "Mar-2017 = 22825771485.0\n",
      "Apr-2017 = 16228909133.0\n",
      "May-2017 = 21444477789.0\n",
      "Jun-2017 = 36157857417.0\n",
      "Jul-2017 = 23292077090.0\n",
      "Aug-2017 = 17714535551.0\n",
      "Sep-2017 = 19527222580.0\n",
      "Oct-2017 = 17009909746.0\n",
      "Nov-2017 = 19622746585.0\n",
      "Dec-2017 = 21234653073.0\n",
      "Jan-2018 = 7295946165.0\n",
      "Feb-2018 = 18931173834.0\n",
      "Mar-2018 = 20077637151.0\n",
      "Apr-2018 = 15166420739.0\n",
      "May-2018 = 17096545838.0\n",
      "Jun-2018 = 16749332802.0\n",
      "Jul-2018 = 16491092577.0\n",
      "Aug-2018 = 19551349765.0\n",
      "Sep-2018 = 16967684092.0\n",
      "Oct-2018 = 15611843894.0\n",
      "Nov-2018 = 26047099676.0\n",
      "Dec-2018 = 13176961532.0\n",
      "Jan-2019 = 5983979597.0\n",
      "Feb-2019 = 11102100991.0\n",
      "Mar-2019 = 18981700003.0\n",
      "Apr-2019 = 13916321536.0\n",
      "May-2019 = 26133422872.0\n",
      "Jun-2019 = 13488214126.0\n",
      "Jul-2019 = 15346932559.0\n",
      "Aug-2019 = 44915775337.0\n",
      "Sep-2019 = 18277878575.0\n",
      "Oct-2019 = 17967680347.0\n",
      "Nov-2019 = 21656345890.0\n",
      "Dec-2019 = 64598550714.0\n",
      "Jan-2020 = 7788809287.0\n",
      "Feb-2020 = 14729927371.0\n",
      "Mar-2020 = 15170989027.0\n",
      "Apr-2020 = 10359137782.0\n",
      "May-2020 = 12459922651.0\n",
      "Jun-2020 = 15410653442.0\n",
      "Jul-2020 = 19052785249.0\n",
      "Aug-2020 = 16936353893.0\n",
      "Sep-2020 = 22036818967.0\n",
      "Oct-2020 = 20331505674.0\n",
      "Nov-2020 = 50110434036.0\n",
      "Dec-2020 = 26431787543.0\n",
      "Jan-2021 = 9779700688.0\n",
      "Feb-2021 = 22666459643.0\n",
      "Mar-2021 = 29948198254.0\n",
      "Apr-2021 = 26590715785.0\n",
      "May-2021 = 29876574783.0\n",
      "Jun-2021 = 28686231495.0\n",
      "Jul-2021 = 29770865809.0\n",
      "Aug-2021 = 22973611474.0\n",
      "Sep-2021 = 30889678241.0\n",
      "Oct-2021 = 32640116600.0\n",
      "Nov-2021 = 39575603384.0\n",
      "Dec-2021 = 28962063835.0\n",
      "Jan-2022 = 10447449006.0\n",
      "Feb-2022 = 23711066610.0\n",
      "Mar-2022 = 27528493709.0\n",
      "Apr-2022 = 23170678037.0\n",
      "May-2022 = 26497983118.0\n",
      "Jun-2022 = 23948067986.0\n",
      "Jul-2022 = 25588665074.0\n",
      "Aug-2022 = 17353679963.0\n",
      "Sep-2022 = 19143003669.0\n",
      "Oct-2022 = 18186683265.0\n",
      "Nov-2022 = 20432618904.0\n",
      "Dec-2022 = 17689076204.0\n",
      "Jan-2023 = 7116227906.0\n",
      "Feb-2023 = 15508048822.0\n",
      "Mar-2023 = 21145720016.0\n",
      "Apr-2023 = 17905205853.0\n",
      "May-2023 = 22541330986.0\n",
      "Jun-2023 = 21170314176.0\n",
      "Jul-2023 = 20973529165.0\n",
      "Aug-2023 = 24098245074.0\n",
      "Sep-2023 = 21156246426.0\n",
      "Oct-2023 = 23424876543.0\n",
      "Nov-2023 = 19465990395.0\n",
      "Dec-2023 = 12829077343.0\n",
      "Jan-2024 = 4910669682.0\n",
      "Feb-2024 = 366574260.0\n",
      "Mar-2029 = 0.0\n",
      "Sep-2031 = 528000.0\n",
      "Oct-2031 = 690000.0\n",
      "Nov-2031 = 280000.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def extract_month(date_str: str) -> str:\n",
    "    try:\n",
    "        dt = datetime.strptime(date_str, \"%d/%b/%Y\")  # AUS format\n",
    "        return dt.strftime(\"%b-%Y\")  # \"Jan-2025\"\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def parse_month(month_str: str) -> datetime:\n",
    "    return datetime.strptime(month_str, \"%b-%Y\")\n",
    "\n",
    "def safe_float(x: str) -> float:\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "# Filter out header-like rows and bad values\n",
    "clean_rdd = dict_rdd.filter(\n",
    "    lambda row: row[\"contract_date\"] not in (None, \"\", \"contract_date\") \n",
    "                and row[\"purchase_price\"] not in (None, \"\", \"purchase_price\")\n",
    ")\n",
    "\n",
    "# Extract (month, purchase_price)\n",
    "month_price_rdd = clean_rdd.map(\n",
    "    lambda row: (\n",
    "        extract_month(row[\"contract_date\"]),\n",
    "        safe_float(row[\"purchase_price\"])\n",
    "    )\n",
    ").filter(lambda x: x[0] is not None)\n",
    "\n",
    "# Reduce by key (sum per month)\n",
    "monthly_totals = month_price_rdd.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Collect and sort chronologically\n",
    "monthly_totals_sorted = sorted(\n",
    "    monthly_totals.collect(),\n",
    "    key=lambda x: parse_month(x[0])\n",
    ")\n",
    "\n",
    "for month, total in monthly_totals_sorted:\n",
    "    print(month, \"=\", total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jan: Sales=232506, Total Purchase Price=150349905292.0\n",
      "Feb: Sales=387321, Total Purchase Price=285319462750.0\n",
      "Mar: Sales=463130, Total Purchase Price=365311248208.0\n",
      "Apr: Sales=384295, Total Purchase Price=290504534216.0\n",
      "May: Sales=451956, Total Purchase Price=381422491121.0\n",
      "Jun: Sales=410513, Total Purchase Price=374419320769.0\n",
      "Jul: Sales=406578, Total Purchase Price=359921097048.0\n",
      "Aug: Sales=415692, Total Purchase Price=358084768214.0\n",
      "Sep: Sales=425426, Total Purchase Price=349453709090.0\n",
      "Oct: Sales=434540, Total Purchase Price=350918253916.0\n",
      "Nov: Sales=449023, Total Purchase Price=418727748950.0\n",
      "Dec: Sales=393246, Total Purchase Price=437044783603.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def extract_month_name(date_str: str) -> str:\n",
    "    try:\n",
    "        dt = datetime.strptime(date_str, \"%d/%b/%Y\")  # AUS format\n",
    "        return dt.strftime(\"%b\")   # \"Jan\"\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def safe_float(x: str) -> float:\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "# Filter out header remnants / blanks\n",
    "clean_rdd = dict_rdd.filter(\n",
    "    lambda row: row[\"contract_date\"] not in (None, \"\", \"contract_date\")\n",
    ")\n",
    "\n",
    "# Map to (month, (count, total_purchase_price))\n",
    "month_metrics_rdd = clean_rdd.map(\n",
    "    lambda row: (\n",
    "        extract_month_name(row[\"contract_date\"]),\n",
    "        (1, safe_float(row[\"purchase_price\"]))\n",
    "    )\n",
    ").filter(lambda x: x[0] is not None)\n",
    "\n",
    "# Reduce: sum counts and purchase prices\n",
    "monthly_metrics = month_metrics_rdd.reduceByKey(\n",
    "    lambda a, b: (a[0] + b[0], a[1] + b[1])\n",
    ")\n",
    "\n",
    "# Collect and sort by calendar order\n",
    "month_order = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "monthly_metrics_sorted = sorted(\n",
    "    monthly_metrics.collect(),\n",
    "    key=lambda x: month_order.index(x[0])\n",
    ")\n",
    "\n",
    "# Print results\n",
    "for month, (count, total) in monthly_metrics_sorted:\n",
    "    print(f\"{month}: Sales={count}, Total Purchase Price={total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.2 Which 5 councils have the largest number of houses? Show their name and the total number of houses. (Note: Each house may appear multiple times if there are more than one sales, you should only count them once.) (5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Working with DataFrames (45%) <a class=\"anchor\" name=\"2-dataframes\"></a>\n",
    "In this section, you need to load the given datasets into PySpark DataFrames and use DataFrame functions to answer the queries.\n",
    "### 2.1 Data Preparation and Loading\n",
    "\n",
    "2.1.1. Load the CSV/JSON files into separate dataframes. When you create your dataframes, please refer to the metadata file and think about the appropriate data type for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = [\"data/council.json\", \"data/nsw_property_price.csv\", \"data/property_purpose.json\", \"data/zoning.json\"]\n",
    "dfs = []  \n",
    "for file in files:\n",
    "    ext = os.path.splitext(file)[1].lower()  # get file extension\n",
    "    \n",
    "    if ext == \".json\":\n",
    "        df = spark.read.json(file)\n",
    "        dfs.append((df, \"json\", file))\n",
    "    elif ext == \".csv\":\n",
    "        # rdd = spark.read.csv(file, header=True, inferSchema=True)\n",
    "        df = spark.read.csv(file)\n",
    "        dfs.append((df, \"csv\", file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.2 Display the schema of the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[_corrupt_record: string]\n",
      "root\n",
      " |-- _corrupt_record: string (nullable = true)\n",
      "\n",
      "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string, _c6: string, _c7: string, _c8: string, _c9: string, _c10: string, _c11: string, _c12: string, _c13: string, _c14: string, _c15: string, _c16: string]\n",
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      "\n",
      "DataFrame[_corrupt_record: string]\n",
      "root\n",
      " |-- _corrupt_record: string (nullable = true)\n",
      "\n",
      "DataFrame[_corrupt_record: string]\n",
      "root\n",
      " |-- _corrupt_record: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df, ext, filename in dfs:\n",
    "    print(df)\n",
    "    df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the dataset is large, do you need all columns? How to optimize memory usage? Do you need a customized data partitioning strategy? (Note: Think about those questions but you don’t need to answer these questions.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 QueryAnalysis  <a class=\"anchor\" name=\"2.2\"></a>\n",
    "Implement the following queries using dataframes. You need to be able to perform operations like transforming, filtering, sorting, joining and group by using the functions provided by the DataFrame API. For each task, display the first 5 results where no output is specified.\n",
    "\n",
    "2.2.1. The area column has two types: (H, A and M): 1 H is one hectare = 10000 sqm, 1A is one acre = 4000 sqm, 1 M is one sqm. Unify the unit to sqm and create a new column called area_sqm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking IDs in data/council.json\n",
      "Checking IDs in data/property_purpose.json\n",
      "Checking IDs in data/zoning.json\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "for df, filetype, filename in dfs:\n",
    "    if filetype == \"json\":\n",
    "        print(f\"Checking IDs in {filename}\")\n",
    "        \n",
    "        # find all columns ending with \"_id\"\n",
    "        id_cols = [c for c in df.columns if c.endswith(\"_id\")]\n",
    "        \n",
    "        for id_col in id_cols:\n",
    "            print(f\"  Validating column: {id_col}\")\n",
    "            \n",
    "            # filter invalid rows based on regex\n",
    "            invalid_rows = df.filter(~col(id_col).rlike(\"^[A-Za-z0-9]+$\"))\n",
    "            \n",
    "            if invalid_rows.count() > 0:\n",
    "                print(f\"    Found {invalid_rows.count()} invalid {id_col} values\")\n",
    "                invalid_rows.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.2. <pre>The top five property types are: Residence, Vacant Land, Commercial, Farm and Industrial.\n",
    "However, for historical reason, they may have different strings in the database. Please update the primary_purpose with the following rules:\n",
    "a)\tAny purpose that has “HOME”, “HOUSE”, “UNIT” is classified as “Residence”;\n",
    "b)\t“Warehouse”, “Factory”,  “INDUST” should be changed to “Industrial”;\n",
    "c)\tAnything that contains “FARM”(i.e. FARMING), should be changed to “FARM”;\n",
    "d)\t“Vacant”, “Land” should be “Vacant Land”;\n",
    "e)\tAnything that has “COMM”, “Retail”, “Shop” or “Office” are “Cmmercial”.\n",
    "f)\tAll remaining properties, including null and empty purposes, are classified as “Others”.\n",
    "Show the count of each type in a table.\n",
    "(note: Some properties are multi-purpose, e.g. “House & Farm”, it’s fine to count them multiple times.)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.3 Find the top 20 properties that make the largest value gain, show their address, suburb, and value increased. To calculate the value gain, the property must have been sold multiple times, “value increase” can be calculated with the last sold price – first sold price, regardless the transactions in between. Print all 20 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.4 For each season, plot the median house price trend over the years. Seasons in Australia are defined as: (Spring: Sep-Nov, Summer: Dec-Feb, Autumn: Mar-May, Winter: Jun-Aug). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.5 (Open Question) Explore the dataset freely and plot one diagram of your choice. Which columns (at least 2) are highly correlated to the sales price? Discuss the steps of your exploration and the results. (No word limit, please keep concise.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your dicsussion here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 RDDs vs DataFrame vs Spark SQL (25%) <a class=\"anchor\" name=\"part-3\"></a>\n",
    "Implement the following complex queries using RDD, DataFrame in SparkSQL separately(choose two). Log the time taken for each query in each approach using the “%%time” built-in magic command in Jupyter Notebook and discuss the performance difference between these 2 approaches of your choice.\n",
    "(notes: You can write a multi-step query or a single complex query, the choice is yours. You can reuse the data frame in Part 2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complex Query:\n",
    "<pre>\n",
    "A property investor wants to understand whether the property price and the settlement date are correlated. Here is the conditions:\n",
    "1)\tThe investor is only interested in the last 2 years of the dataset.\n",
    "2)\tThe investor is looking at houses under $2 million.\n",
    "3)\tPerform a bucketing of the settlement date (settlement – contract date\n",
    "range (15, 30, 45, 60, 90 days).\n",
    "4)\tPerform a bucketing of property prices in $500K(e.g. 0-$500K, $500K-$1M, $1M-$1.5M, $1.5-$2M)\n",
    "5)\tCount the number of transactions in each combination and print the result in the following format\n",
    "(Note: It’s fine to count the same property multiple times in this task, it’s based on sales transactions).\n",
    "(Note: You shall show the full table with 40 rows, 2 years *4 price bucket * 5 settlement bucket; 0 count should be displayed as 0, not omitted.)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\tImplement the above query using two approaches of your choice separately and print the results. (Note: Outputs from both approaches of your choice are required, and the results should be the same.). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Implementation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Implementation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\tWhich one is easier to implement, in your opinion? Log the time taken for each query, and observe the query execution time, among DataFrame and SparkSQL, which is faster and why? Please include proper references. (Maximum 500 words.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some ideas on the comparison\n",
    "\n",
    "Armbrust, M., Huai, Y., Liang, C., Xin, R., & Zaharia, M. (2015). Deep Dive into Spark SQL’s Catalyst Optimizer. Retrieved September 30, 2017, from https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html\n",
    "\n",
    "Damji, J. (2016). A Tale of Three Apache Spark APIs: RDDs, DataFrames, and Datasets. Retrieved September 28, 2017, from https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html\n",
    "\n",
    "Data Flair (2017a). Apache Spark RDD vs DataFrame vs DataSet. Retrieved September 28, 2017, from http://data-flair.training/blogs/apache-spark-rdd-vs-dataframe-vs-dataset\n",
    "\n",
    "Prakash, C. (2016). Apache Spark: RDD vs Dataframe vs Dataset. Retrieved September 28, 2017, from http://why-not-learn-something.blogspot.com.au/2016/07/apache-spark-rdd-vs-dataframe-vs-dataset.html\n",
    "\n",
    "Xin, R., & Rosen, J. (2015). Project Tungsten: Bringing Apache Spark Closer to Bare Metal. Retrieved September 30, 2017, from https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
